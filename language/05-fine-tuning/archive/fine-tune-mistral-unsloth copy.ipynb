{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload our custom .jsonl collection of instructions and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'What are some of the best museums to visit in Paris?', 'output': 'Paris is a city rich in museums, catering to a wide range of interests. Here are some you might want to consider:\\n\\n1. The Louvre: The world\\'s largest art museum and a historic monument in Paris, home to thousands of works of art, including the Mona Lisa.\\n\\n2. Musée d\\'Orsay: Located in a former railway station, this museum houses a large collection of Impressionist and Post-Impressionist masterpieces.\\n\\n3. Centre Pompidou: Known for its high-tech architecture, this museum houses the National Museum of Modern Art.\\n\\n4. Musée de l\\'Orangerie: Located in the Tuileries Gardens, it\\'s famous for Monet\\'s \"Water Lilies\" series.\\n\\n5. Musée Rodin: Dedicated to the works of the French sculptor Auguste Rodin.\\n\\n6. Musée du Quai Branly: Features indigenous art, cultures and civilizations from Africa, Asia, Oceania, and the Americas.\\n\\n7. Musée Picasso: Home to an impressive collection of more than 5,000 works by Pablo Picasso.\\n\\nRemember, many museums offer reduced or free admission on certain days or times, and you can also consider getting the Paris Museum Pass for unlimited access to over 60 museums and monuments.', 'input': ''}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = 'test.jsonl'\n",
    "\n",
    "data = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        json_line = json.loads(line.strip())\n",
    "        data.append(json_line)\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = {}\n",
    "for key in data[0].keys():  # initialize keys\n",
    "    transformed_data[key] = []\n",
    "\n",
    "for item in data:\n",
    "    for key in item:\n",
    "        transformed_data[key].append(item[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': ['What are some of the best museums to visit in Paris?', 'What is the local cuisine like in Paris?', 'What are some popular outdoor activities in Paris?', 'What is the currency used in Paris and where can I exchange my money?', 'What are some of the most famous landmarks in Paris?', 'What is the best time of year to visit Paris?', 'What is the weather like in Paris throughout the year?', 'What are some popular outdoor activities in Paris?', 'What are some popular markets in Paris that I should visit?'], 'output': ['Paris is a city rich in museums, catering to a wide range of interests. Here are some you might want to consider:\\n\\n1. The Louvre: The world\\'s largest art museum and a historic monument in Paris, home to thousands of works of art, including the Mona Lisa.\\n\\n2. Musée d\\'Orsay: Located in a former railway station, this museum houses a large collection of Impressionist and Post-Impressionist masterpieces.\\n\\n3. Centre Pompidou: Known for its high-tech architecture, this museum houses the National Museum of Modern Art.\\n\\n4. Musée de l\\'Orangerie: Located in the Tuileries Gardens, it\\'s famous for Monet\\'s \"Water Lilies\" series.\\n\\n5. Musée Rodin: Dedicated to the works of the French sculptor Auguste Rodin.\\n\\n6. Musée du Quai Branly: Features indigenous art, cultures and civilizations from Africa, Asia, Oceania, and the Americas.\\n\\n7. Musée Picasso: Home to an impressive collection of more than 5,000 works by Pablo Picasso.\\n\\nRemember, many museums offer reduced or free admission on certain days or times, and you can also consider getting the Paris Museum Pass for unlimited access to over 60 museums and monuments.', \"Parisian cuisine is renowned worldwide for its quality and diversity. Here are some dishes and food items you should try:\\n\\n1. Baguette: A long, thin loaf of French bread that is commonly made from basic lean dough.\\n\\n2. Croissant: A buttery, flaky, viennoiserie pastry of Austrian origin, named for its historical crescent shape.\\n\\n3. Escargot: Snails cooked typically in a garlic-butter, chicken soup or wine sauce.\\n\\n4. Coq au Vin: A traditional French dish of chicken slow-cooked in a wine-based sauce with mushrooms and possibly garlic.\\n\\n5. Ratatouille: A stewed vegetable dish consisting of peppers, eggplant, zucchini, and tomatoes—typical components of Provençal cuisine.\\n\\n6. Crêpes: Thin pancakes that can be filled with a variety of fillings, both sweet and savory.\\n\\n7. Cheese: France is famous for its variety of cheeses. Brie, Camembert, Roquefort are just a few to name.\\n\\n8. Pastries: Paris is heaven for pastry lovers. Don't miss trying a Paris-Brest, éclair, or tarte tatin.\\n\\n9. Wine: France is one of the largest wine producers in the world. Whether you prefer red, white, or rosé, there's something for every wine lover.\\n\\nRemember, one of the joys of visiting Paris is discovering the local bistros, cafés, and markets, and trying the wonderful array of food on offer.\", \"Paris offers a variety of outdoor activities for all ages and interests. Here are a few suggestions:\\n\\n1. Boating on the Seine: Rent a boat and enjoy a leisurely trip down the Seine River.\\n\\n2. Picnicking in a Park: Paris has many beautiful parks, such as the Tuileries Garden or the Luxembourg Garden, where you can have a picnic.\\n\\n3. Cycling: Rent a bike from the city's bike-sharing program, Vélib', and explore the city's many bike paths.\\n\\n4. Walking Tours: Join a guided walking tour to learn about the city's history and architecture.\\n\\n5. Visit the Zoos: The Ménagerie, the zoo in the Jardin des Plantes, and the Paris Zoological Park in the Bois de Vincennes, are great for families.\\n\\n6. Outdoor Markets: Visit one of the city's many outdoor markets to shop for food, antiques, art, and more.\\n\\n7. Hot Air Balloon Ride: Take a hot air balloon ride in the Parc André Citroën for a unique view of the city.\\n\\nRemember to check the weather and dress appropriately for your outdoor activities.\", 'The currency used in Paris, and all of France, is the Euro (€). You can exchange your money at various places:\\n\\n1. Banks: Most banks in Paris offer currency exchange services. However, they may charge a service fee and their hours of operation may not be as flexible as other options.\\n\\n2. Currency Exchange Bureaus: These are found throughout the city, especially in tourist areas and near major train stations. They usually offer competitive exchange rates, but it\\'s a good idea to compare rates at a few different places.\\n\\n3. ATMs: You can withdraw Euros directly from ATMs (called \"distributeurs automatiques de billets\" in French) found all over the city. This can be one of the most convenient and cost-effective ways to get cash, depending on your bank\\'s foreign transaction fees.\\n\\n4. Hotels: Some hotels offer currency exchange services, but their rates are usually not as good as banks or currency exchange bureaus.\\n\\nRemember to notify your bank of your travel plans to avoid any issues with your card while abroad. Also, it\\'s a good idea to have some cash on hand, but many places in Paris also accept credit cards.', \"Paris is known for its iconic landmarks. Here are some of the most famous ones:\\n\\n1. Eiffel Tower: This iconic tower is a must-visit. You can either admire it from the ground or climb up for a stunning view of the city.\\n\\n2. Notre-Dame Cathedral: Although it was damaged by a fire in 2019, this Gothic cathedral is still a sight to behold.\\n\\n3. Louvre Museum: Home to thousands of works of art, including the Mona Lisa, the Louvre is the world's largest art museum.\\n\\n4. Montmartre and the Sacré-Cœur: This historic and artistic neighborhood is known for its bohemian past and the white-domed Basilica of the Sacré-Cœur on its summit.\\n\\n5. Champs-Élysées and the Arc de Triomphe: The Champs-Élysées is a famous avenue known for its luxury shops, cafes, and theaters, ending at the Arc de Triomphe.\\n\\n6. Palace of Versailles: Just outside Paris, this opulent palace and garden is a UNESCO World Heritage site.\\n\\n7. Seine River and its bridges: The Seine River is lined with some of Paris's most famous landmarks, and its bridges, like the Pont Alexandre III and Pont Neuf, are attractions in their own right.\\n\\n8. The Panthéon: A neoclassical building in the Latin Quarter, it houses the remains of notable French citizens.\\n\\nRemember, it's best to check the opening times and book tickets in advance to avoid long lines.\", \"The best time to visit Paris really depends on what you're looking for. \\n\\nSpring (April to June) and Fall (September to November) are generally the most pleasant times to visit, with milder weather and fewer crowds. The city is particularly beautiful in the spring when the flowers are in bloom, and in the fall when the leaves are changing colors.\\n\\nSummer (July and August) can be quite hot and crowded, as this is peak tourist season. However, many Parisians leave the city in August for vacation, which can make the city feel less crowded. There are also many outdoor festivals and events during the summer.\\n\\nWinter (December to February) can be cold and rainy, but you'll find fewer tourists and lower prices. Plus, you'll get to see the city's beautiful Christmas decorations and markets.\\n\\nUltimately, there's no bad time to visit Paris. Each season offers its own unique charm and experiences.\", \"Paris has a temperate climate with distinct seasons:\\n\\n1. Spring (March to May): The weather starts to warm up with average temperatures ranging from 11°C to 20°C. It's a great time to see the city's parks and gardens in bloom.\\n\\n2. Summer (June to August): It can get quite hot with temperatures often reaching above 25°C. It's the busiest tourist season, and there are many outdoor festivals and events.\\n\\n3. Autumn (September to November): Temperatures cool down, ranging from 11°C to 20°C. The city is beautiful with fall foliage, and it's less crowded with tourists.\\n\\n4. Winter (December to February): It can get quite cold with temperatures often dropping to around 3°C. Snow is rare but possible. It's a good time to visit museums and enjoy indoor activities.\\n\\nRemember, the weather can be unpredictable, so it's always a good idea to check the forecast before your trip and pack accordingly.\", \"Paris offers a variety of outdoor activities for all ages and interests. Here are a few suggestions:\\n\\n1. Boating on the Seine: You can rent a boat or take a river cruise to see some of the city's most famous landmarks.\\n\\n2. Cycling: Paris is a bike-friendly city with many bike rental services and dedicated cycling paths.\\n\\n3. Picnicking: Parisians love to picnic in the city's many parks and gardens. Some popular spots include the Champ de Mars, Jardin du Luxembourg, and Buttes-Chaumont.\\n\\n4. Walking Tours: Explore the city on foot with a guided tour, or at your own pace. Don't miss the historic neighborhoods of Le Marais and Montmartre.\\n\\n5. Outdoor Markets: Visit one of the city's many outdoor markets to shop for fresh produce, cheese, pastries, and more.\\n\\n6. Street Performances: Enjoy free street performances in areas like the Pompidou Centre or along the Seine.\\n\\n7. Visit the Zoos: The Ménagerie, the zoo of the Jardin des Plantes, and the Paris Zoological Park are great for families.\\n\\nRemember, the best way to experience Paris is often to simply wander and see where the city takes you.\", \"Paris is known for its vibrant markets, each offering a unique shopping experience. Here are a few you should consider visiting:\\n\\n1. Marché des Enfants Rouges: The oldest covered market in Paris, known for its food stalls offering a variety of international cuisines.\\n\\n2. Marché d'Aligre: A daily market known for its fresh produce, cheese, and flowers. It also has a flea market.\\n\\n3. Marché aux Fleurs et aux Oiseaux: A flower and bird market located on Île de la Cité.\\n\\n4. Marché de la Création: An art market where local artists sell their work.\\n\\n5. Marché aux Puces de Saint-Ouen: One of the largest flea markets in the world, perfect for antiques and vintage items.\\n\\n6. Marché Biologique Raspail: A large organic market that takes place on Sundays.\\n\\n7. Marché Bastille: One of the biggest markets in Paris, offering a wide range of goods, from fresh produce to clothing.\\n\\nRemember, markets can be busy places, so keep an eye on your belongings and be prepared to haggle for the best prices.\"], 'input': ['', '', '', '', '', '', '', '', '']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/genaiplayground/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_dict(transformed_data)\n",
    "print(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Mistral patching release 2024.1\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.691 GB\n",
      "O^O/ \\_/ \\    CUDA capability = 8.6. Xformers = 0.0.23.post1. FA = False.\n",
      "\\        /    Pytorch version: 2.1.2. CUDA Toolkit = 11.8\n",
      " \"-____-\"     bfloat16 = TRUE. Platform = Linux\n",
      "\n",
      "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` attribute will be overwritten with the one you passed to `from_pretrained`.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/mistral-7b-bnb-4bit\", # \"unsloth/mistral-7b\" for 16bit loading\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = None, # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "    load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9/9 [00:00<00:00, 4364.52 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'What are some of the best museums to visit in Paris?', 'output': 'Paris is a city rich in museums, catering to a wide range of interests. Here are some you might want to consider:\\n\\n1. The Louvre: The world\\'s largest art museum and a historic monument in Paris, home to thousands of works of art, including the Mona Lisa.\\n\\n2. Musée d\\'Orsay: Located in a former railway station, this museum houses a large collection of Impressionist and Post-Impressionist masterpieces.\\n\\n3. Centre Pompidou: Known for its high-tech architecture, this museum houses the National Museum of Modern Art.\\n\\n4. Musée de l\\'Orangerie: Located in the Tuileries Gardens, it\\'s famous for Monet\\'s \"Water Lilies\" series.\\n\\n5. Musée Rodin: Dedicated to the works of the French sculptor Auguste Rodin.\\n\\n6. Musée du Quai Branly: Features indigenous art, cultures and civilizations from Africa, Asia, Oceania, and the Americas.\\n\\n7. Musée Picasso: Home to an impressive collection of more than 5,000 works by Pablo Picasso.\\n\\nRemember, many museums offer reduced or free admission on certain days or times, and you can also consider getting the Paris Museum Pass for unlimited access to over 60 museums and monuments.', 'input': '', 'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat are some of the best museums to visit in Paris?\\n\\n### Input:\\n\\n\\n### Response:\\nParis is a city rich in museums, catering to a wide range of interests. Here are some you might want to consider:\\n\\n1. The Louvre: The world\\'s largest art museum and a historic monument in Paris, home to thousands of works of art, including the Mona Lisa.\\n\\n2. Musée d\\'Orsay: Located in a former railway station, this museum houses a large collection of Impressionist and Post-Impressionist masterpieces.\\n\\n3. Centre Pompidou: Known for its high-tech architecture, this museum houses the National Museum of Modern Art.\\n\\n4. Musée de l\\'Orangerie: Located in the Tuileries Gardens, it\\'s famous for Monet\\'s \"Water Lilies\" series.\\n\\n5. Musée Rodin: Dedicated to the works of the French sculptor Auguste Rodin.\\n\\n6. Musée du Quai Branly: Features indigenous art, cultures and civilizations from Africa, Asia, Oceania, and the Americas.\\n\\n7. Musée Picasso: Home to an impressive collection of more than 5,000 works by Pablo Picasso.\\n\\nRemember, many museums offer reduced or free admission on certain days or times, and you can also consider getting the Paris Museum Pass for unlimited access to over 60 museums and monuments.</s>'}\n",
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What are some of the best museums to visit in Paris?\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "Paris is a city rich in museums, catering to a wide range of interests. Here are some you might want to consider:\n",
      "\n",
      "1. The Louvre: The world's largest art museum and a historic monument in Paris, home to thousands of works of art, including the Mona Lisa.\n",
      "\n",
      "2. Musée d'Orsay: Located in a former railway station, this museum houses a large collection of Impressionist and Post-Impressionist masterpieces.\n",
      "\n",
      "3. Centre Pompidou: Known for its high-tech architecture, this museum houses the National Museum of Modern Art.\n",
      "\n",
      "4. Musée de l'Orangerie: Located in the Tuileries Gardens, it's famous for Monet's \"Water Lilies\" series.\n",
      "\n",
      "5. Musée Rodin: Dedicated to the works of the French sculptor Auguste Rodin.\n",
      "\n",
      "6. Musée du Quai Branly: Features indigenous art, cultures and civilizations from Africa, Asia, Oceania, and the Americas.\n",
      "\n",
      "7. Musée Picasso: Home to an impressive collection of more than 5,000 works by Pablo Picasso.\n",
      "\n",
      "Remember, many museums offer reduced or free admission on certain days or times, and you can also consider getting the Paris Museum Pass for unlimited access to over 60 museums and monuments.</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN  # add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass\n",
    "\n",
    "new_dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
    "print(new_dataset[0])\n",
    "print(new_dataset[0]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_test_split = new_dataset.train_test_split(test_size=0.1)  # Here, 10% is used for testing\n",
    "\n",
    "# Access the train and test datasets\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.1 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# Do model patching and add fast LoRA weights\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = True,\n",
    "    random_state = 3407,\n",
    "    max_seq_length = max_seq_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "MAX_STEPS=100\n",
    "from transformers import TrainingArguments\n",
    "training_arguments = TrainingArguments(\n",
    "        output_dir=\"./unsloth_results\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        do_eval=True,\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=6,\n",
    "        per_device_eval_batch_size=4,\n",
    "        log_level=\"debug\",\n",
    "        save_steps=100,\n",
    "        logging_steps=25, \n",
    "        learning_rate=2e-4,\n",
    "        eval_steps=50,\n",
    "        optim='adamw_8bit',\n",
    "        fp16 = not torch.cuda.is_bf16_supported(),\n",
    "        bf16 = torch.cuda.is_bf16_supported(),\n",
    "        weight_decay=0.1,\n",
    "        max_steps=MAX_STEPS,\n",
    "        warmup_ratio=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8/8 [00:00<00:00, 2560.43 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 564.28 examples/s]\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    tokenizer = tokenizer,\n",
    "    args = training_arguments,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show current memory stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 3090. Max memory = 23.691 GB.\n",
      "4.625 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently training with a batch size of: 4\n",
      "***** Running training *****\n",
      "  Num examples = 8\n",
      "  Num Epochs = 500\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 6\n",
      "  Total optimization steps = 500\n",
      "  Number of trainable parameters = 41,943,040\n",
      "Unsloth: `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='183' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [183/500 08:32 < 14:58, 0.35 it/s, Epoch 182/500]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>2.322770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>2.475006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>2.430656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./unsloth_results/tmp-checkpoint-100\n",
      "tokenizer config file saved in ./unsloth_results/tmp-checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in ./unsloth_results/tmp-checkpoint-100/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/genaiplayground/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:323\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 323\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m~/.conda/envs/genaiplayground/lib/python3.9/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/genaiplayground/lib/python3.9/site-packages/transformers/trainer.py:1869\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1869\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1872\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1875\u001b[0m ):\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.conda/envs/genaiplayground/lib/python3.9/site-packages/transformers/trainer.py:2777\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2777\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2779\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/.conda/envs/genaiplayground/lib/python3.9/site-packages/accelerate/accelerator.py:1964\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1962\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1964\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/genaiplayground/lib/python3.9/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/genaiplayground/lib/python3.9/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show final memory and time stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "Let's run the model! You can change the instruction and input - leave the output blank!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"Continue the fibonnaci sequence.\", # instruction\n",
    "        \"1, 1, 2, 3, 5, 8\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "]*1, return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 128, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "With text streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpaca_prompt = Copied from above\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"Continue the fibonnaci sequence.\", # instruction\n",
    "        \"1, 1, 2, 3, 5, 8\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "]*1, return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving & loading fine-tuned models\n",
    "To save the final model as LoRA adapters, either use Huggingface's push_to_hub for an online save or save_pretrained for a local save.\n",
    "\n",
    "[NOTE] This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"mistral_lora_model\") # local saving\n",
    "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Huggingface hub Online saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving to float16 for VLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to 16bit\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
    "\n",
    "# Merge to 4bit\n",
    "if True: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
    "\n",
    "# Just LoRA adapters\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GGUF / llama.cpp Conversion\n",
    "To save to GGUF / llama.cpp, we support it natively now! We clone llama.cpp and we default save it to q8_0. We allow all methods like q4_k_m. Use save_pretrained_gguf for local saving and push_to_hub_gguf for uploading to HF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GGUF / llama.cpp Conversion\n",
    "# Save to 8bit Q8_0\n",
    "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
    "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
    "\n",
    "# Save to 16bit GGUF\n",
    "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
    "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
    "\n",
    "# Save to q4_k_m GGUF\n",
    "if True: model.save_pretrained_gguf(\"model_q4_k_m_gguf\", tokenizer, quantization_method = \"q4_k_m\")\n",
    "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, use the model-unsloth.gguf file or model-unsloth-Q4_K_M.gguf file in llama.cpp or a UI based system like GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "model = PeftModel.from_pretrained(model, \"mistral_lora_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def get_response(query:str, input=\"\")->List[str]:\n",
    "  inputs = tokenizer(\n",
    "       [\n",
    "    alpaca_prompt.format(\n",
    "        query, # instruction\n",
    "        input, # input\n",
    "        \"\", # output\n",
    "    )\n",
    "    ]*1, return_tensors = \"pt\").to(\"cuda\")\n",
    "  outputs = model.generate(**inputs, max_new_tokens = 1024, use_cache = True)\n",
    "  return tokenizer.batch_decode(outputs)\n",
    "\n",
    "query = \"Give me some highlights of the following city\"\n",
    "input = \"Paris\"\n",
    "resp = get_response(query, input)\n",
    "def format_msg(message):\n",
    "    split_msg = message.split(\"### \")\n",
    "    final_str = split_msg[1]+split_msg[3]\n",
    "    return final_str\n",
    "print(format_msg(resp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
