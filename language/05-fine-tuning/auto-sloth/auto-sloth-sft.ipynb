{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import Layout\n",
    "import os\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables like HuggingFace token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # take environment variables from .env.\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huggingface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fc9a46bde44c0c89b3f3a00846c2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='CorticalStack', description='HF hub user', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee3c990651a4f9aae667897a1b169eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='mistral-7b-alpaca', description='New model id', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "username = widgets.Text(\n",
    "    value=\"CorticalStack\",\n",
    "    description='HF hub user',\n",
    "    disabled=False\n",
    ")\n",
    "username.style.description_width = 'initial'\n",
    "display(username)\n",
    "\n",
    "new_model_id = widgets.Text(\n",
    "    value=\"mistral-7b-alpaca\",\n",
    "    description='New model id',\n",
    "    disabled=False\n",
    ")\n",
    "new_model_id.style.description_width = 'initial'\n",
    "display(new_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73771b73e16b4fca82c648859966912e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=64, description='r', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6be6a78a2fd40bd90c6ed0ad9243dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=64, description='lora alpha', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1d5ea372494d39b2c263a0226037cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=0, description='lora dropout', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb62389b1c27416aacd3da83f173fcc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=3407, description='random state', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = widgets.IntText(\n",
    "    value=64,\n",
    "    description='r',\n",
    "    disabled=False\n",
    ")\n",
    "r.style.description_width = 'initial'\n",
    "display(r)\n",
    "\n",
    "lora_alpha = widgets.IntText(\n",
    "    value=64,\n",
    "    description='lora alpha',\n",
    "    disabled=False\n",
    ")\n",
    "lora_alpha.style.description_width = 'initial'\n",
    "display(lora_alpha)\n",
    "\n",
    "lora_dropout = widgets.IntText(\n",
    "    value=0,\n",
    "    description='lora dropout',\n",
    "    disabled=False\n",
    ")\n",
    "lora_dropout.style.description_width = 'initial'\n",
    "display(lora_dropout)\n",
    "\n",
    "random_state = widgets.IntText(\n",
    "    value=3407,\n",
    "    description='random state',\n",
    "    disabled=False\n",
    ")\n",
    "random_state.style.description_width = 'initial'\n",
    "display(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063aa6616ae442d3af5f7f59d753629b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='unsloth/mistral-7b-bnb-4bit', description='Model ID', style=TextStyle(description_width='initial')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0315703458e8474cba0fd5b06896b9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='yahma/alpaca-cleaned', description='Train dataset', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0b2c1e24404d9aaac7788068cc432c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=4, description='Per device train batch size', style=DescriptionStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4df8a9a4c544356b5beb972b620749e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=4, description='Gradient accumulation steps', style=DescriptionStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d50734af9f14876a3388dfd4f48950a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=4, description='Dataset num proc', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f8dad174bc4fa7aa4dcd86932bbd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=1, description='Logging steps', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed0ecb59cd94edca2879922c46c4f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=42, description='Seed', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e49b57f81441fea0fd5b0d58c467fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='adamw_8bit', description='Optimizer', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14890bb7cf8a49ae8d99f8ef1aa4c122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=5, description='Warmup steps', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c18b628d23e4e32ab05fc77b71600cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=60, description='Max steps', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c764d804abb64b6d8483f391c2f00299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=5, description='Eval steps', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b36016e2404fa69457952b812849fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=5, description='Save steps', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3511ef5ca3424486ed8b8db65eb390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0002, description='Learning rate', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816de9dcfec84bb68b46ad93fea86861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.01, description='Weight decay', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc81955057e478d95567f430ddb4ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='linear', description='LR schedule type', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8ad9bfb0614e9584142bf86bc5159a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=2048, description='Max seq length', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f525c409ba404ca142cc4d4e96d057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='Four bit bnb', indent=False, style=CheckboxStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = widgets.Text(\n",
    "    value=\"unsloth/mistral-7b-bnb-4bit\",\n",
    "    description='Model ID',\n",
    "    disabled=False\n",
    ")\n",
    "model_id.style.description_width = 'initial'\n",
    "display(model_id)\n",
    "\n",
    "train_dataset = widgets.Text(\n",
    "    value=\"yahma/alpaca-cleaned\",\n",
    "    description='Train dataset',\n",
    "    disabled=False\n",
    ")\n",
    "train_dataset.style.description_width = 'initial'\n",
    "display(train_dataset)\n",
    "\n",
    "per_device_train_batch_size = widgets.IntText(\n",
    "    value=4,\n",
    "    description='Per device train batch size',\n",
    "    disabled=False\n",
    ")\n",
    "per_device_train_batch_size.style.description_width = 'initial'\n",
    "display(per_device_train_batch_size)\n",
    "\n",
    "gradient_accumulation_steps = widgets.IntText(\n",
    "    value=4,\n",
    "    description='Gradient accumulation steps',\n",
    "    disabled=False\n",
    ")\n",
    "gradient_accumulation_steps.style.description_width = 'initial'\n",
    "display(gradient_accumulation_steps)\n",
    "\n",
    "dataset_num_proc = widgets.IntText(\n",
    "    value=4,\n",
    "    description='Dataset num proc',\n",
    "    disabled=False\n",
    ")\n",
    "dataset_num_proc.style.description_width = 'initial'\n",
    "display(dataset_num_proc)\n",
    "\n",
    "logging_steps = widgets.IntText(\n",
    "    value=1,\n",
    "    description='Logging steps',\n",
    "    disabled=False\n",
    ")\n",
    "logging_steps.style.description_width = 'initial'\n",
    "display(logging_steps)\n",
    "\n",
    "seed = widgets.IntText(\n",
    "    value=42,\n",
    "    description='Seed',\n",
    "    disabled=False\n",
    ")\n",
    "seed.style.description_width = 'initial'\n",
    "display(seed)\n",
    "\n",
    "optim = widgets.Text(\n",
    "    value=\"adamw_8bit\",\n",
    "    description='Optimizer',\n",
    "    disabled=False\n",
    ")\n",
    "optim.style.description_width = 'initial'\n",
    "display(optim)\n",
    "\n",
    "warmup_steps = widgets.IntText(\n",
    "    value=5,\n",
    "    description='Warmup steps',\n",
    "    disabled=False\n",
    ")\n",
    "warmup_steps.style.description_width = 'initial'\n",
    "display(warmup_steps)\n",
    "\n",
    "max_steps = widgets.IntText(\n",
    "    value=60,\n",
    "    description='Max steps',\n",
    "    disabled=False\n",
    ")\n",
    "max_steps.style.description_width = 'initial'\n",
    "display(max_steps)\n",
    "\n",
    "eval_steps = widgets.IntText(\n",
    "    value=5,\n",
    "    description='Eval steps',\n",
    "    disabled=False\n",
    ")\n",
    "eval_steps.style.description_width = 'initial'\n",
    "display(eval_steps)\n",
    "\n",
    "save_steps = widgets.IntText(\n",
    "    value=5,\n",
    "    description='Save steps',\n",
    "    disabled=False\n",
    ")\n",
    "save_steps.style.description_width = 'initial'\n",
    "display(save_steps)\n",
    "\n",
    "learning_rate = widgets.FloatText(\n",
    "    value=\"2e-4\",\n",
    "    description='Learning rate',\n",
    "    disabled=False\n",
    ")\n",
    "learning_rate.style.description_width = 'initial'\n",
    "display(learning_rate)\n",
    "\n",
    "weight_decay = widgets.FloatText(\n",
    "    value=\"0.01\",\n",
    "    description='Weight decay',\n",
    "    disabled=False\n",
    ")\n",
    "weight_decay.style.description_width = 'initial'\n",
    "display(weight_decay)\n",
    "\n",
    "lr_scheduler_type = widgets.Text(\n",
    "    value=\"linear\",\n",
    "    description='LR schedule type',\n",
    "    disabled=False\n",
    ")\n",
    "lr_scheduler_type.style.description_width = 'initial'\n",
    "display(lr_scheduler_type)\n",
    "\n",
    "# max_length = widgets.IntText(\n",
    "#     value=1024,\n",
    "#     description='Max length',\n",
    "#     disabled=False\n",
    "# )\n",
    "# max_length.style.description_width = 'initial'\n",
    "# display(max_length)\n",
    "\n",
    "# max_prompt_length = widgets.IntText(\n",
    "#     value=512,\n",
    "#     description='Max prompt length',\n",
    "#     disabled=False\n",
    "# )\n",
    "# max_prompt_length.style.description_width = 'initial'\n",
    "# display(max_prompt_length)\n",
    "\n",
    "max_seq_length = widgets.IntText(\n",
    "    value=2048,  #1024,\n",
    "    description='Max seq length',\n",
    "    disabled=False\n",
    ")\n",
    "max_seq_length.style.description_width = 'initial'\n",
    "display(max_seq_length)\n",
    "\n",
    "four_bit_bnb = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Four bit bnb',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "four_bit_bnb.style.description_width = 'initial'\n",
    "display(four_bit_bnb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking training with weights & biases (wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcorticalstack\u001b[0m (\u001b[33mcorticalstackteam\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "\n",
    "wandb_project = \"ft-\" + new_model_id.value\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset from the HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(train_dataset.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset records: 46584\n",
      "test dataset records: 5176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Generate an essay about the importance of physical education in schools.',\n",
       " 'output': \"Physical education is an integral part of the modern school curriculum, and its importance cannot be overemphasized. Over the years, physical education has been seen as a dispensable subject, with its true purposes and benefits often ignored. But as the world embraces physical fitness, the role of physical education in schools has become even more impactful, particularly in shaping the habits and behaviors that promote a healthy lifestyle.\\n\\nOne of the most obvious reasons why physical education should be an essential part of the school curriculum is the positive impact it has on students' health. With the alarming rates of childhood obesity and related diseases, it is particularly necessary for children to engage in physical activities that promote healthy body weight and cardiovascular fitness. Physical education classes provide students with the opportunity to participate in various sporting and recreational activities that expose them to a healthy lifestyle, equipping them with the knowledge and skills necessary to engage in regular physical activity.\\n\\nApart from the physical benefits, physical education also plays an essential role in the psycho-social development of students. Physical activity has been linked to reduced anxiety and depression, improved cognitive function, and enhanced self-esteem. As such, participation in physical education classes provides students with the opportunity to relieve stress and promote mental wellness, leading to better academic performance and improved overall wellbeing.\\n\\nThe skills learned and developed through physical education go beyond the physical. The subject promotes the development of life skills such as communication, teamwork, and problem-solving. Students learn to work together to achieve a common goal, to respect and appreciate the diversity of talents and abilities, and to develop leadership and decision-making skills. These lifetime skills are essential for success in all areas of life, and physical education provides a platform for their development.\\n\\nFurthermore, physical education serves as an avenue to introduce students to a variety of sports and physical activities, promoting a culture of lifelong physical activity. Students who participate in school-based physical education programs are more likely to continue with physical activity in adulthood, reducing their risk of chronic diseases, such as cardiovascular disease, diabetes, and obesity.\\n\\nIn conclusion, the importance of physical education in schools cannot be overstated. It plays an essential role in promoting students' physical, psychological, and social wellbeing. The lifelong skills and habits acquired through participation in physical education translate to healthier, more productive members of society. It is therefore imperative that physical education be given its due recognition as an essential part of the school curriculum.\",\n",
       " 'input': ''}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_test_split = dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "\n",
    "# Extract the training and testing datasets\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]\n",
    "\n",
    "print(f\"train dataset records: {len(train_dataset)}\")\n",
    "print(f\"test dataset records: {len(test_dataset)}\")\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Mistral patching release 2024.2\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.691 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.1.2.post301. CUDA = 8.6. CUDA Toolkit = 11.8.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.21. FA = True.\n",
      " \"-____-\"     Apache 2 free license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` attribute will be overwritten with the one you passed to `from_pretrained`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_id.value,\n",
    "    max_seq_length = max_seq_length.value,\n",
    "    dtype = None, # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "    load_in_4bit = four_bit_bnb.value, # Use 4bit quantization to reduce memory usage. Can be False\n",
    "    token=HF_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def format_prompts(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f112628378b54828ad2a2a34bd535ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46584 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d419e4fccff415785da71398a0d8552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Generate an essay about the importance of physical education in schools.\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "Physical education is an integral part of the modern school curriculum, and its importance cannot be overemphasized. Over the years, physical education has been seen as a dispensable subject, with its true purposes and benefits often ignored. But as the world embraces physical fitness, the role of physical education in schools has become even more impactful, particularly in shaping the habits and behaviors that promote a healthy lifestyle.\n",
      "\n",
      "One of the most obvious reasons why physical education should be an essential part of the school curriculum is the positive impact it has on students' health. With the alarming rates of childhood obesity and related diseases, it is particularly necessary for children to engage in physical activities that promote healthy body weight and cardiovascular fitness. Physical education classes provide students with the opportunity to participate in various sporting and recreational activities that expose them to a healthy lifestyle, equipping them with the knowledge and skills necessary to engage in regular physical activity.\n",
      "\n",
      "Apart from the physical benefits, physical education also plays an essential role in the psycho-social development of students. Physical activity has been linked to reduced anxiety and depression, improved cognitive function, and enhanced self-esteem. As such, participation in physical education classes provides students with the opportunity to relieve stress and promote mental wellness, leading to better academic performance and improved overall wellbeing.\n",
      "\n",
      "The skills learned and developed through physical education go beyond the physical. The subject promotes the development of life skills such as communication, teamwork, and problem-solving. Students learn to work together to achieve a common goal, to respect and appreciate the diversity of talents and abilities, and to develop leadership and decision-making skills. These lifetime skills are essential for success in all areas of life, and physical education provides a platform for their development.\n",
      "\n",
      "Furthermore, physical education serves as an avenue to introduce students to a variety of sports and physical activities, promoting a culture of lifelong physical activity. Students who participate in school-based physical education programs are more likely to continue with physical activity in adulthood, reducing their risk of chronic diseases, such as cardiovascular disease, diabetes, and obesity.\n",
      "\n",
      "In conclusion, the importance of physical education in schools cannot be overstated. It plays an essential role in promoting students' physical, psychological, and social wellbeing. The lifelong skills and habits acquired through participation in physical education translate to healthier, more productive members of society. It is therefore imperative that physical education be given its due recognition as an essential part of the school curriculum.</s>\n"
     ]
    }
   ],
   "source": [
    "train_dataset_in_prompt_format = train_dataset.map(format_prompts, batched = True,)\n",
    "test_dataset_in_prompt_format = test_dataset.map(format_prompts, batched = True,)\n",
    "print(train_dataset_in_prompt_format[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do model patching and add fast LoRA weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.2 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,  #r.value,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,  #32,  #lora_alpha.value,\n",
    "    lora_dropout = 0,  #lora_dropout.value, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = True,\n",
    "    random_state = 3407,  #random_state.value,\n",
    "    #max_seq_length = max_seq_length.value,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the model trainer\n",
    "- Will train the model with TRL (Transformer Reinforcement Learning), with the SFT (Supervised Fine Tuning) trainer\n",
    "- Use the text column of the dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7fabbcb3683415d86b7ed0b42d46032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/46584 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15032a8219149c0ac0314f5b1fb1c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/5176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = \"./\" + new_model_id.value + \"/output\"\n",
    "logging_dir =  \"./\" + new_model_id.value + \"/logs\"\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset_in_prompt_format,\n",
    "    eval_dataset = test_dataset_in_prompt_format,\n",
    "    max_seq_length = max_seq_length.value,\n",
    "    dataset_num_proc = 2,  #dataset_num_proc.value,\n",
    "    dataset_text_field = \"text\",\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,  #per_device_train_batch_size.value,\n",
    "        gradient_accumulation_steps = 4,  #gradient_accumulation_steps.value,\n",
    "        warmup_steps = warmup_steps.value,\n",
    "        max_steps = max_steps.value,\n",
    "        learning_rate = 2e-4,  #learning_rate.value,\n",
    "        fp16 = not torch.cuda.is_bf16_supported(),\n",
    "        bf16 = torch.cuda.is_bf16_supported(),\n",
    "        logging_steps = 1,  #logging_steps.value,\n",
    "        logging_dir = logging_dir,   \n",
    "        optim = \"adamw_8bit\",  #optim.value,\n",
    "        weight_decay = 0.01,  ##weight_decay.value,\n",
    "        lr_scheduler_type = \"linear\",  #lr_scheduler_type.value,\n",
    "        seed = 3407,  #seed.value,\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps = eval_steps.value,  \n",
    "        save_steps = save_steps.value,                \n",
    "        report_to = \"wandb\", \n",
    "        run_name = f\"{wandb_project}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\",\n",
    "        output_dir = output_dir,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/samssd/developments/genai-playground/language/05-fine-tuning/auto-sloth/wandb/run-20240214_221655-5nti3xr2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/corticalstackteam/ft-mistral-7b-alpaca/runs/5nti3xr2' target=\"_blank\">ft-mistral-7b-alpaca-2024-02-14-22-16</a></strong> to <a href='https://wandb.ai/corticalstackteam/ft-mistral-7b-alpaca' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/corticalstackteam/ft-mistral-7b-alpaca' target=\"_blank\">https://wandb.ai/corticalstackteam/ft-mistral-7b-alpaca</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/corticalstackteam/ft-mistral-7b-alpaca/runs/5nti3xr2' target=\"_blank\">https://wandb.ai/corticalstackteam/ft-mistral-7b-alpaca/runs/5nti3xr2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8/60 10:47 < 1:33:35, 0.01 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.905400</td>\n",
       "      <td>0.982301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./mistral-7b-alpaca/output/checkpoint-5 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/genaiplayground_tune/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:323\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 323\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m~/.conda/envs/genaiplayground_tune/lib/python3.11/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/genaiplayground_tune/lib/python3.11/site-packages/transformers/trainer.py:1869\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1869\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1872\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1875\u001b[0m ):\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.conda/envs/genaiplayground_tune/lib/python3.11/site-packages/transformers/trainer.py:2781\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2779\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2780\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2781\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/.conda/envs/genaiplayground_tune/lib/python3.11/site-packages/accelerate/accelerator.py:1966\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1964\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1965\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1966\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/genaiplayground_tune/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/genaiplayground_tune/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaiplayground_tune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
