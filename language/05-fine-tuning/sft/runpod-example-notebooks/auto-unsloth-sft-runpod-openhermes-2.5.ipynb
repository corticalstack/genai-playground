{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2b47e0-6e21-40a8-a08c-30fe0998bd3d",
   "metadata": {},
   "source": [
    "### Import dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f2602c0-fa4b-458f-97f4-46376938fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608a1d0f-cefa-4eff-86d0-e7f9df031369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-k6p9qyd_/unsloth_3fe817de0591408ea9573403272bed68\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-k6p9qyd_/unsloth_3fe817de0591408ea9573403272bed68\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit a030e802030d4619ba247d45c5819fb59e9addb3\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (0.42.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (1.12.0)\n",
      "Collecting xformers@ https://download.pytorch.org/whl/cu118/xformers-0.0.22.post7%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl (from unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Using cached https://download.pytorch.org/whl/cu118/xformers-0.0.22.post7%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Requirement already satisfied: transformers>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (4.37.2)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (2.17.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (0.1.99)\n",
      "Requirement already satisfied: accelerate>=0.26.1 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (0.27.2)\n",
      "Requirement already satisfied: trl>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (0.7.11)\n",
      "Requirement already satisfied: peft>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (0.8.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (4.66.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (5.9.6)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (0.42.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (23.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (2.1.0+cu118)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (0.4.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.0->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.0->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.0->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.0->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (0.15.2)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl>=0.7.9->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (0.7.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (2.2.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (3.9.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.1->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.1->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.1->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.1->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.1->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (2.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.37.0->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.37.0->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.37.0->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.37.0->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (2022.12.7)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl>=0.7.9->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (0.15)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl>=0.7.9->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (13.7.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl>=0.7.9->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (1.6.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl>=0.7.9->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl>=0.7.9->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate>=0.26.1->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate>=0.26.1->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl>=0.7.9->unsloth[cu118]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"unsloth[cu118] @ git+https://github.com/unslothai/unsloth.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e709d3a-5941-4783-a65d-f58c287c81d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.3)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.42)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.6)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.40.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (68.2.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3d69c93-0f87-42f4-abcc-b00aaddf504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import Layout\n",
    "import os\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from jinja2 import Template\n",
    "from huggingface_hub import ModelCard, HfApi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25b649-2b1c-4376-bbd6-d99c991a32eb",
   "metadata": {},
   "source": [
    "### Huggingface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49a82b31-10ef-42f4-8ed4-0ab00468cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bf78e0f3c84a51be45cd769732f276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='CorticalStack', description='HF hub user', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bfade360f747f2a12cd2fa2a0d80ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='mistral-7b-alpaca-sft', description='New model id', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03851bd60b8847f2ae6137b3065cb8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='apache-2.0', description='License', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "username = widgets.Text(\n",
    "    value=\"CorticalStack\",\n",
    "    description='HF hub user',\n",
    "    disabled=False\n",
    ")\n",
    "username.style.description_width = 'initial'\n",
    "display(username)\n",
    "\n",
    "new_model_id = widgets.Text(\n",
    "    value=\"mistral-7b-alpaca-sft\",\n",
    "    description='New model id',\n",
    "    disabled=False\n",
    ")\n",
    "new_model_id.style.description_width = 'initial'\n",
    "display(new_model_id)\n",
    "\n",
    "license = widgets.Text(\n",
    "    value=\"apache-2.0\",\n",
    "    description='License',\n",
    "    disabled=False\n",
    ")\n",
    "license.style.description_width = 'initial'\n",
    "display(license)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849a081-a145-45ae-95e3-9e3b7d518992",
   "metadata": {},
   "source": [
    "### LoRA parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ff6442d-fc82-45cd-b895-3cbcdeb6a84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874f665abff44de882081379ab806e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=256, description='r', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a726efb6d584da2bcca0dd5aea6e953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=128, description='lora alpha', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a734075cb24e6fb27f9dea6d36b166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0, description='lora dropout', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d861fe2ca9c3425398e170601066a847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=3407, description='random state', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = widgets.IntText(\n",
    "    value=256,\n",
    "    description='r',\n",
    "    disabled=False\n",
    ")\n",
    "r.style.description_width = 'initial'\n",
    "display(r)\n",
    "\n",
    "lora_alpha = widgets.IntText(\n",
    "    value=128,\n",
    "    description='lora alpha',\n",
    "    disabled=False\n",
    ")\n",
    "lora_alpha.style.description_width = 'initial'\n",
    "display(lora_alpha)\n",
    "\n",
    "lora_dropout = widgets.FloatText(\n",
    "    value=0,\n",
    "    description='lora dropout',\n",
    "    disabled=False\n",
    ")\n",
    "lora_dropout.style.description_width = 'initial'\n",
    "display(lora_dropout)\n",
    "\n",
    "random_state = widgets.IntText(\n",
    "    value=3407,\n",
    "    description='random state',\n",
    "    disabled=False\n",
    ")\n",
    "random_state.style.description_width = 'initial'\n",
    "display(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e4fb52-d75f-406b-9b41-e3d9be59922c",
   "metadata": {},
   "source": [
    "### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f069fddb-dfcc-4211-9fec-323ab9333b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46d622d3cec4038989dc3c8b679b4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='unsloth/mistral-7b-bnb-4bit', description='Model ID', style=TextStyle(description_width='initial')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a936b46157248c2b5f5eb125f52530e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='yahma/alpaca-cleaned', description='Train dataset', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158a25f359ea4c1abd027e3bed8e5e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=1, description='Number epochs', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9700e5b2badf41019769bdd327ab944e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=4, description='Per device train batch size', style=DescriptionStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44952c9c2254e5f8da9a1ad133a986b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=6, description='Gradient accumulation steps', style=DescriptionStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595954f4479d475ca8c9519309e063af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=4, description='Dataset num proc', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09355a22636240ca852bf0c1f24630ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=1, description='Logging steps', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e39735763eb44e1bd26d9a31fcd7b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='adamw_torch_fused', description='Optimizer', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9ea1cebb5d49ae8e6b137a7eb2e91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.01, description='Warmup ratios', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d36a6440c944ab9c5d2282bb97b932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=100, description='Max steps', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a265991bff4d3d86fd33c809cd081b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=10, description='Eval steps', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b5713a39274c2d8391cf851bf020ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=50, description='Save steps', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decc46cd69f14b91a8a111e8fafc9155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0002, description='Learning rate', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7648cd1a3af24f119d16bd60a3773bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.1, description='Weight decay', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b928620b6c4c78a63e533fbb59d56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='linear', description='LR schedule type', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba4719bf854441aaa21e56005c819cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=2048, description='Max seq length', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16de9d61211b416aaaea4fb3c290239c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='Four bit bnb', indent=False, style=CheckboxStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = widgets.Text(\n",
    "    value=\"unsloth/mistral-7b-bnb-4bit\",\n",
    "    description='Model ID',\n",
    "    disabled=False\n",
    ")\n",
    "model_id.style.description_width = 'initial'\n",
    "display(model_id)\n",
    "\n",
    "train_dataset_name = widgets.Text(\n",
    "    value=\"yahma/alpaca-cleaned\",\n",
    "    description='Train dataset',\n",
    "    disabled=False\n",
    ")\n",
    "train_dataset_name.style.description_width = 'initial'\n",
    "display(train_dataset_name)\n",
    "\n",
    "num_epochs = widgets.IntText(\n",
    "    value=1,\n",
    "    description='Number epochs',\n",
    "    disabled=False\n",
    ")\n",
    "num_epochs.style.description_width = 'initial'\n",
    "display(num_epochs)\n",
    "\n",
    "per_device_train_batch_size = widgets.IntText(\n",
    "    value=4,\n",
    "    description='Per device train batch size',\n",
    "    disabled=False\n",
    ")\n",
    "per_device_train_batch_size.style.description_width = 'initial'\n",
    "display(per_device_train_batch_size)\n",
    "\n",
    "gradient_accumulation_steps = widgets.IntText(\n",
    "    value=6,\n",
    "    description='Gradient accumulation steps',\n",
    "    disabled=False\n",
    ")\n",
    "gradient_accumulation_steps.style.description_width = 'initial'\n",
    "display(gradient_accumulation_steps)\n",
    "\n",
    "dataset_num_proc = widgets.IntText(\n",
    "    value=4,\n",
    "    description='Dataset num proc',\n",
    "    disabled=False\n",
    ")\n",
    "dataset_num_proc.style.description_width = 'initial'\n",
    "display(dataset_num_proc)\n",
    "\n",
    "logging_steps = widgets.IntText(\n",
    "    value=1,\n",
    "    description='Logging steps',\n",
    "    disabled=False\n",
    ")\n",
    "logging_steps.style.description_width = 'initial'\n",
    "display(logging_steps)\n",
    "\n",
    "optim = widgets.Text(\n",
    "    value=\"adamw_torch_fused\",\n",
    "    description='Optimizer',\n",
    "    disabled=False\n",
    ")\n",
    "optim.style.description_width = 'initial'\n",
    "display(optim)\n",
    "\n",
    "warmup_ratio = widgets.FloatText(\n",
    "    value=0.01,\n",
    "    description='Warmup ratios',\n",
    "    disabled=False\n",
    ")\n",
    "warmup_ratio.style.description_width = 'initial'\n",
    "display(warmup_ratio)\n",
    "\n",
    "max_steps = widgets.IntText(\n",
    "    value=100,\n",
    "    description='Max steps',\n",
    "    disabled=False\n",
    ")\n",
    "max_steps.style.description_width = 'initial'\n",
    "display(max_steps)\n",
    "\n",
    "eval_steps = widgets.IntText(\n",
    "    value=10,\n",
    "    description='Eval steps',\n",
    "    disabled=False\n",
    ")\n",
    "eval_steps.style.description_width = 'initial'\n",
    "display(eval_steps)\n",
    "\n",
    "save_steps = widgets.IntText(\n",
    "    value=50,\n",
    "    description='Save steps',\n",
    "    disabled=False\n",
    ")\n",
    "save_steps.style.description_width = 'initial'\n",
    "display(save_steps)\n",
    "\n",
    "learning_rate = widgets.FloatText(\n",
    "    value=\"2e-4\",\n",
    "    description='Learning rate',\n",
    "    disabled=False\n",
    ")\n",
    "learning_rate.style.description_width = 'initial'\n",
    "display(learning_rate)\n",
    "\n",
    "weight_decay = widgets.FloatText(\n",
    "    value=\"0.1\",\n",
    "    description='Weight decay',\n",
    "    disabled=False\n",
    ")\n",
    "weight_decay.style.description_width = 'initial'\n",
    "display(weight_decay)\n",
    "\n",
    "lr_scheduler_type = widgets.Text(\n",
    "    value=\"linear\",\n",
    "    description='LR schedule type',\n",
    "    disabled=False\n",
    ")\n",
    "lr_scheduler_type.style.description_width = 'initial'\n",
    "display(lr_scheduler_type)\n",
    "\n",
    "max_seq_length = widgets.IntText(\n",
    "    value=2048,  #1024,\n",
    "    description='Max seq length',\n",
    "    disabled=False\n",
    ")\n",
    "max_seq_length.style.description_width = 'initial'\n",
    "display(max_seq_length)\n",
    "\n",
    "four_bit_bnb = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Four bit bnb',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "four_bit_bnb.style.description_width = 'initial'\n",
    "display(four_bit_bnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89765192-9e73-4d7e-a6f6-741f69d1441f",
   "metadata": {},
   "source": [
    "### Tracking training with weights & biases (wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "768d597b-2237-49e2-84b0-a646fd34fa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcorticalstack\u001b[0m (\u001b[33mcorticalstackteam\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "\n",
    "wandb_project = \"ft-\" + new_model_id.value\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a1d3d-4ed6-4672-975f-dbde5da15106",
   "metadata": {},
   "source": [
    "### Load dataset from the HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "574cabc4-28f7-4558-b76c-a28d58bd0cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd747c5bac824ea78af304cccca1b450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ed23af96af43d19b7340658ea3ed1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c81ceed26849eab4a796bce0c0dfd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(train_dataset_name.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec853667-f3d6-47bd-9956-1c4d896e5136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset records: 1000549\n",
      "test dataset records: 1002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'views': None,\n",
       " 'system_prompt': None,\n",
       " 'avatarUrl': None,\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': 'Can you provide a formula or code snippet in Excel to calculate the monthly payment for a loan amount of $30,000 with an annual interest rate of 8.0% and a monthly payment period of 5 years?',\n",
       "   'weight': None},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Yes, here is the formula you can use in Excel to calculate the monthly payment for a loan:\\n= -PMT(rate/12, nper, pv)\\nWhere:\\n- rate/12 is the monthly interest rate (8.0%/12)\\n- nper is the total number of payments (5 years x 12 months per year = 60 months)\\n- pv is the present value or loan amount ($30,000)\\nTo apply this formula to your scenario, you can enter the following formula in a cell in Excel:\\n= -PMT(8.0%/12, 5*12, 30000)\\nThis will give you the monthly payment for the loan, which is $608.02.',\n",
       "   'weight': None}],\n",
       " 'hash': None,\n",
       " 'title': None,\n",
       " 'custom_instruction': None,\n",
       " 'topic': None,\n",
       " 'idx': None,\n",
       " 'skip_prompt_formatting': None,\n",
       " 'category': None,\n",
       " 'language': None,\n",
       " 'source': 'EvolInstruct_70k',\n",
       " 'model': None,\n",
       " 'id': 'ed8e2eed-70ae-4293-8a35-215ddb7a95ec',\n",
       " 'model_name': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_test_split = dataset[\"train\"].train_test_split(test_size=0.001)\n",
    "\n",
    "# Extract the training and testing datasets\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]\n",
    "\n",
    "print(f\"train dataset records: {len(train_dataset)}\")\n",
    "print(f\"test dataset records: {len(test_dataset)}\")\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db8280-2ed9-46f9-9411-6d4b7cd5c804",
   "metadata": {},
   "source": [
    "### Load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "852051a2-6688-47d6-abe1-b07d0c9bfe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Mistral patching release 2024.2\n",
      "   \\\\   /|    GPU: NVIDIA A100 80GB PCIe. Max memory: 79.15 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.1.0+cu118. CUDA = 8.0. CUDA Toolkit = 11.8.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.22.post7+cu118. FA = False.\n",
      " \"-____-\"     Apache 2 free license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` attribute will be overwritten with the one you passed to `from_pretrained`.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_id.value,\n",
    "    max_seq_length = max_seq_length.value,\n",
    "    dtype = None, # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "    load_in_4bit = four_bit_bnb.value, # Use 4bit quantization to reduce memory usage. Can be False\n",
    "    token=HF_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65171318-13b7-48cb-997e-79cf9dff8d68",
   "metadata": {},
   "source": [
    "### Set prompt - Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5f62436-0757-4dd1-9267-d36a951e7bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12f5f57b-5413-4a11-9b60-f6f13d64f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompts(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = []\n",
    "    for convo in convos:\n",
    "        human_dict = convo[0]\n",
    "        gpt_dict = convo[1]\n",
    "        instruction = human_dict['value']\n",
    "        response = gpt_dict['value']\n",
    "        text = alpaca_prompt.format(instruction, response) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4b68d53-4ff8-4834-820e-e052df11c60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28fcc17232d4d4383665a311766bd6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000549 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7fcb903db04e7daf341dedc2386bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Can you provide a formula or code snippet in Excel to calculate the monthly payment for a loan amount of $30,000 with an annual interest rate of 8.0% and a monthly payment period of 5 years?\n",
      "\n",
      "### Response:\n",
      "Yes, here is the formula you can use in Excel to calculate the monthly payment for a loan:\n",
      "= -PMT(rate/12, nper, pv)\n",
      "Where:\n",
      "- rate/12 is the monthly interest rate (8.0%/12)\n",
      "- nper is the total number of payments (5 years x 12 months per year = 60 months)\n",
      "- pv is the present value or loan amount ($30,000)\n",
      "To apply this formula to your scenario, you can enter the following formula in a cell in Excel:\n",
      "= -PMT(8.0%/12, 5*12, 30000)\n",
      "This will give you the monthly payment for the loan, which is $608.02.</s>\n"
     ]
    }
   ],
   "source": [
    "train_dataset_in_prompt_format = train_dataset.map(format_prompts, batched = True,)\n",
    "test_dataset_in_prompt_format = test_dataset.map(format_prompts, batched = True,)\n",
    "print(train_dataset_in_prompt_format[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3735d644-2969-4779-a91a-d787972b9055",
   "metadata": {},
   "source": [
    "### Do model patching and add fast LoRA weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e42a681c-85b0-4d92-a19f-146787c0a5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "I have the following inline assembly in C:\n",
      "\n",
      "```c\n",
      "unsigned long long result;\n",
      "asm volatile(\".byte 15;.byte 49;shlq $32,%%rdx;orq %%rdx,%%rax\"\n",
      "    : \"=a\" (result) ::  \"%rdx\");\n",
      "return result;\n",
      "```\n",
      "\n",
      "I tried to rewrite it in Rust:\n",
      "\n",
      "```rust\n",
      "let result: u64;\n",
      "unsafe {\n",
      "    asm!(\".byte 15\\n\\t\n",
      "          .byte 49\\n\\t\n",
      "          shlq 32, rdx\\n\\t\n",
      "          orq  rdx, rax\"\n",
      "         : \"=a\"(result)\n",
      "         :\n",
      "         : \"rdx\"\n",
      "         : \"volatile\"\n",
      "         );\n",
      "}\n",
      "result\n",
      "```\n",
      "\n",
      "It doesn't recognize the `=a` constraint and it gives me an invalid operand error for `rdx` and `rax` at `shlq` and `orq` instructions. What is the proper way to rewrite the above C inline assembly in Rust?\n",
      "\n",
      "### Response:\n",
      "To properly rewrite the above C inline assembly in Rust, you need to make a few changes. \n",
      "\n",
      "1. If you want to specify a specific register, you should use the register name as the constraint. In this case, the `=a` constraint is the \"a\" register, as mentioned in the GCC documentation. So, you should change `=a` to `\"={rax}\"(result)`.\n",
      "\n",
      "2. Literals must be prefaced with `$$`. Therefore, you should change `shlq 32, rdx` to `shlq $$32, %rdx`.\n",
      "\n",
      "3. Registers must be prefaced with `%`. So, you should change `orq  rdx, rax` to `orq %rdx, %rax`.\n",
      "\n",
      "Here is the modified Rust code:\n",
      "\n",
      "```rust\n",
      "let result: u64;\n",
      "unsafe {\n",
      "    asm!(\".byte 15\n",
      "          .byte 49\n",
      "          shlq $$32, %rdx\n",
      "          orq  %rdx, %rax\"\n",
      "         : \"={rax}\"(result)\n",
      "         :\n",
      "         : \"rdx\"\n",
      "         : \"volatile\"\n",
      "    );\n",
      "}\n",
      "result\n",
      "```\n",
      "\n",
      "Additionally, it is advised to avoid using inline assembly as much as possible and switch to a more idiomatic Rust solution.</s>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset_in_prompt_format[4]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98c258db-c052-429d-b916-eff522e2e8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.2 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = r.value,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = lora_alpha.value,\n",
    "    lora_dropout = lora_dropout.value, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = True,\n",
    "    random_state = random_state.value,\n",
    "    max_seq_length = max_seq_length.value,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f6d52e-4766-4d47-8756-d6edace3a54d",
   "metadata": {},
   "source": [
    "#### Construct the model trainer\r\n",
    "- Will train the model with TRL (Transformer Reinforcement Learning), with the SFT (Supervised Fine Tuning) trainer\r\n",
    "- Use the text column of the dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa17ea7f-ad00-43cb-af3d-c3a6ac62e1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13685cef59e4c958578c91a7aeb68c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1000549 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecc3ce196a54672addb9bb063520291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = \"./\" + new_model_id.value + \"/output\"\n",
    "logging_dir =  \"./\" + new_model_id.value + \"/logs\"\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset_in_prompt_format,\n",
    "    eval_dataset = test_dataset_in_prompt_format,\n",
    "    max_seq_length = max_seq_length.value,\n",
    "    dataset_num_proc = dataset_num_proc.value,\n",
    "    dataset_text_field = \"text\",\n",
    "    args = TrainingArguments(\n",
    "        num_train_epochs = num_epochs.value,\n",
    "        per_device_train_batch_size = per_device_train_batch_size.value,\n",
    "        gradient_accumulation_steps = gradient_accumulation_steps.value,\n",
    "        warmup_ratio = warmup_ratio.value,\n",
    "        max_steps = max_steps.value,\n",
    "        learning_rate = learning_rate.value,\n",
    "        fp16 = not torch.cuda.is_bf16_supported(),\n",
    "        bf16 = torch.cuda.is_bf16_supported(),\n",
    "        logging_steps = logging_steps.value,\n",
    "        logging_dir = logging_dir,   \n",
    "        optim = optim.value,\n",
    "        weight_decay = weight_decay.value,\n",
    "        lr_scheduler_type = lr_scheduler_type.value,\n",
    "        seed = random_state.value,\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps = eval_steps.value,  \n",
    "        save_steps = save_steps.value,                \n",
    "        report_to = \"wandb\", \n",
    "        run_name = f\"{wandb_project}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\",\n",
    "        output_dir = output_dir,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28015df2-bcaf-4488-a2dd-eb39d4f31357",
   "metadata": {},
   "source": [
    "#### Show current memory stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f115b176-71dc-4c49-84ce-544e087eac34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA A100 80GB PCIe. Max memory = 79.15 GB.\n",
      "6.898 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5651201f-0257-4eae-97b1-6cbee450b2c9",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5e40a1c-2cb4-48d0-9374-25a321cb85e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20240217_211355-6adbubef</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/corticalstackteam/ft-mistral-7b-openhermes-2.5-sft/runs/6adbubef' target=\"_blank\">ft-mistral-7b-openhermes-2.5-sft-2024-02-17-21-10</a></strong> to <a href='https://wandb.ai/corticalstackteam/ft-mistral-7b-openhermes-2.5-sft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/corticalstackteam/ft-mistral-7b-openhermes-2.5-sft' target=\"_blank\">https://wandb.ai/corticalstackteam/ft-mistral-7b-openhermes-2.5-sft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/corticalstackteam/ft-mistral-7b-openhermes-2.5-sft/runs/6adbubef' target=\"_blank\">https://wandb.ai/corticalstackteam/ft-mistral-7b-openhermes-2.5-sft/runs/6adbubef</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 25:24, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.097000</td>\n",
       "      <td>0.984691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.744900</td>\n",
       "      <td>0.944377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.864700</td>\n",
       "      <td>0.928093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.041100</td>\n",
       "      <td>0.917363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.940500</td>\n",
       "      <td>0.907430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.703300</td>\n",
       "      <td>0.900957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.036000</td>\n",
       "      <td>0.894823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.810200</td>\n",
       "      <td>0.888954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.746600</td>\n",
       "      <td>0.885128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.964100</td>\n",
       "      <td>0.883431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282e3e54-0e69-4997-8ac8-3919aab05f08",
   "metadata": {},
   "source": [
    "### Show memory stats after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "587549e8-e914-415c-801d-24115a175df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1531.4728 seconds used for training.\n",
      "25.52 minutes used for training.\n",
      "Peak reserved memory = 24.137 GB.\n",
      "Peak reserved memory for training = 17.239 GB.\n",
      "Peak reserved memory % of max memory = 30.495 %.\n",
      "Peak reserved memory for training % of max memory = 21.78 %.\n"
     ]
    }
   ],
   "source": [
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d152f778-8e93-4a8d-b6d3-8de4fd750188",
   "metadata": {},
   "source": [
    "### Get last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18a57094-0ae1-43f4-9051-0ba567b7f7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./mistral-7b-openhermes-2.5-sft/output/checkpoint-100'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "last_checkpoint = get_last_checkpoint(output_dir)\n",
    "last_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5140f476-6759-4469-855a-f11ddf5c9644",
   "metadata": {},
   "source": [
    "### Create HF model card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72c773ad-0ccf-41ef-b0c3-ba9591bf6044",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_text = \"\"\"\n",
    "---\n",
    "license: {{ license }}\n",
    "---\n",
    "\n",
    "# {{ new_model_id }}\n",
    "\n",
    "{{ new_model_id }} is an SFT fine-tuned version of [{{ model_id }}](https://huggingface.co/{{ model_id }}) using the [{{ train_dataset_name }}](https://huggingface.co/datasets/{{ train_dataset_name }}) dataset.\n",
    "\n",
    "## Fine-tuning configuration\n",
    "### LoRA\n",
    "- r: {{ r }}\n",
    "- LoRA alpha: {{ lora_alpha }}\n",
    "- LoRA dropout: {{ lora_dropout }}\n",
    "\n",
    "### Training arguments\n",
    "- Epochs: {{ num_epochs }}\n",
    "- Batch size: {{ per_device_train_batch_size }}\n",
    "- Gradient accumulation steps: {{ gradient_accumulation_steps }}\n",
    "- Optimizer: {{ optim }}\n",
    "- Max steps: {{ max_steps }}\n",
    "- Learning rate: {{ learning_rate }}\n",
    "- Weight decay: {{ weight_decay }}\n",
    "- Learning rate scheduler type: {{ lr_scheduler_type }}\n",
    "- Max seq length: {{ max_seq_length }}\n",
    "- 4-bit bnb: {{ four_bit_bnb }}\n",
    "\n",
    "Trained with [Unsloth](https://github.com/unslothai/unsloth) and Huggingface's TRL library.\n",
    "\n",
    "[<img src=\"https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20made%20with%20love.png\" width=\"200\"/>](https://github.com/unslothai/unsloth)\n",
    "\"\"\"\n",
    "\n",
    "    # Create a Jinja template object\n",
    "jinja_template = Template(template_text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8800504e-e7fe-4976-9b3d-6ad712288d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the template\n",
    "content = jinja_template.render(\n",
    "          license = license.value,\n",
    "          new_model_id = new_model_id.value,\n",
    "          model_id = model_id.value,\n",
    "          train_dataset_name = train_dataset_name.value,\n",
    "          r = r.value,\n",
    "          lora_alpha = lora_alpha.value,\n",
    "          lora_dropout = lora_dropout.value,\n",
    "          num_epochs = num_epochs.value,\n",
    "          per_device_train_batch_size = per_device_train_batch_size.value,\n",
    "          gradient_accumulation_steps = gradient_accumulation_steps.value,\n",
    "          optim = optim.value,\n",
    "          max_steps = max_steps.value,\n",
    "          learning_rate = learning_rate.value,\n",
    "          weight_decay = weight_decay.value,\n",
    "          lr_scheduler_type = lr_scheduler_type.value,\n",
    "          max_seq_length = max_seq_length.value,\n",
    "          four_bit_bnb = four_bit_bnb.value\n",
    "          )\n",
    "\n",
    "# Save the model card\n",
    "card = ModelCard(content)\n",
    "card.save(f\"{new_model_id.value}/README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e86dbf0b-b2e1-4fb7-86c8-9920ad98ba8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 707.12 out of 944.45 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 53.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "if True: model.save_pretrained_merged(f\"{new_model_id.value}\", tokenizer, save_method = \"merged_16bit\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc548dc4-589d-4f86-b396-ae1af271244c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoUrl('https://huggingface.co/CorticalStack/mistral-7b-openhermes-2.5-sft', endpoint='https://huggingface.co', repo_type='model', repo_id='CorticalStack/mistral-7b-openhermes-2.5-sft')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = HfApi(token=HF_TOKEN)\n",
    "api.create_repo(\n",
    "    repo_id=f\"{username.value}/{new_model_id.value}\",\n",
    "    repo_type=\"model\",\n",
    "    exist_ok=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae968039-d45a-41c9-91fc-16660748afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {new_model_id.value}/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bf6912f-e2f7-413c-9a43-30ebf470f779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b1d95a1bea4a96a878c50523ca5ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d980f1510aa431ba3f073512fc28dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae72a3b37d84edc8795e260757f8fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776b6bf6e76c49718ba0eaf773d2f76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b02074859244758590ef0bcd25f3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/CorticalStack/mistral-7b-openhermes-2.5-sft/commit/3fa4dfd0f915897f6ec559e6095cdcc064ec04df', commit_message='Upload folder using huggingface_hub', commit_description='', oid='3fa4dfd0f915897f6ec559e6095cdcc064ec04df', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.upload_folder(\n",
    "    repo_id=f\"{username.value}/{new_model_id.value}\",\n",
    "    folder_path=new_model_id.value,\n",
    "    token=HF_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab65649-302a-4b40-a489-4ddce2554ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_id.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74316257-6deb-42b4-b569-2620f068c6df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
