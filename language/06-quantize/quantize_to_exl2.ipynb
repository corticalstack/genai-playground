{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from huggingface_hub import HfApi, create_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables like HuggingFace token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # take environment variables from .env.\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify HuggingFace Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69e8302e9094465acb20483645b54ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='CorticalStack/mistral-7b-alpaca-sft', description='Model ID', style=TextStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df721fa442a24c289dca389b60dec5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='CorticalStack/mistral-7b-alpaca', description='New model ID', style=TextStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = widgets.Text(\n",
    "    value='CorticalStack/mistral-7b-alpaca-sft',\n",
    "    description='Model ID',\n",
    "    disabled=False\n",
    ")\n",
    "model_id.style.description_width = 'initial'\n",
    "display(model_id)\n",
    "\n",
    "new_model_id = widgets.Text(\n",
    "    value='CorticalStack/mistral-7b-alpaca',\n",
    "    description='New model ID',\n",
    "    disabled=False\n",
    ")\n",
    "new_model_id.style.description_width = 'initial'\n",
    "display(new_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXL2 quant parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a7b74dc12d417097882d011bb13040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=6.5, description='BPW', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bpw = widgets.FloatText(\n",
    "    value=6.5,\n",
    "    description='BPW',\n",
    "    disabled=False\n",
    ")\n",
    "bpw.style.description_width = 'initial'\n",
    "display(bpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the source model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = str(model_id.value).split('/')\n",
    "if not os.path.isdir(model_name[1]):\n",
    "    !git clone https://huggingface.co/{model_id.value}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the EXL2 quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-21 09:26:39--  https://huggingface.co/datasets/wikitext/resolve/9a9e482b5987f9d25b3a9b2883fc6cc9fd8071b3/wikitext-103-v1/wikitext-test.parquet\n",
      "Resolving huggingface.co (huggingface.co)... 18.165.183.98, 18.165.183.110, 18.165.183.117, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.165.183.98|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 721735 (705K)\n",
      "Saving to: ‘wikitext-test.parquet.44’\n",
      "\n",
      "wikitext-test.parqu 100%[===================>] 704.82K  1.90MB/s    in 0.4s    \n",
      "\n",
      "2024-02-21 09:26:39 (1.90 MB/s) - ‘wikitext-test.parquet.44’ saved [721735/721735]\n",
      "\n",
      " -- Beginning new job\n",
      " -- Input: pastiche-crown-clown-7b-dare\n",
      " -- Output: pastiche-crown-clown-7b-dare-6.5bpw-exl2\n",
      " -- Calibration dataset: wikitext-test.parquet, 100 / 16 rows, 2048 tokens per sample\n",
      " -- Target bits per weight: 6.5 (decoder), 6 (head)\n",
      " -- Max shard size: 8192 MB\n",
      " -- Tokenizing samples (measurement)...\n",
      " -- First 50 tokens of dataset:\n",
      "    ' = Robert Boulter = \\n  Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed'\n",
      " -- Last 50 tokens of dataset:\n",
      "    'Changnyong @-@ Yongsan road and cut the division in two ; the 38th and 23d Infantry Regiments with the bulk of the division artillery in the north were separated from the division headquarters and the'\n",
      " -- Token embeddings (measurement)...\n",
      " -- Measuring quantization impact...\n",
      " -- Layer: model.layers.0 (Attention)\n",
      " -- model.layers.0.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.90297558\n",
      " -- 2.1987 bpw  accuracy: 0.92061050\n",
      " -- 2.2831 bpw  accuracy: 0.92467726\n",
      " -- 2.6768 bpw  accuracy: 0.95627106\n",
      " -- 3.1689 bpw  accuracy: 0.95686254\n",
      " -- 3.1705 bpw  accuracy: 0.95750630\n",
      " -- 4.0439 bpw  accuracy: 0.96943874\n",
      " -- 4.0471 bpw  accuracy: 0.97075009\n",
      " -- 4.0816 bpw  accuracy: 0.97394018\n",
      " -- 4.1381 bpw  accuracy: 0.97559285\n",
      " -- 4.1705 bpw  accuracy: 0.97844207\n",
      " -- 4.1902 bpw  accuracy: 0.97996397\n",
      " -- 4.2737 bpw  accuracy: 0.98069774\n",
      " -- 4.3295 bpw  accuracy: 0.98259549\n",
      " -- 5.2564 bpw  accuracy: 0.98937445\n",
      " -- 5.3295 bpw  accuracy: 0.99128011\n",
      " -- 6.0439 bpw  accuracy: 0.99196377\n",
      " -- 6.3381 bpw  accuracy: 0.99477335\n",
      " -- 8.0439 bpw  accuracy: 0.99785416\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.0 (Attention)    |\n",
      "| Duration: 6.83 seconds                  |\n",
      "| Completed step: 1/67                    |\n",
      "| Avg time / step (rolling): 6.83 seconds |\n",
      "| Estimated remaining time: 7min 31sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.0 (MLP)\n",
      " -- model.layers.0.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.0.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.0.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.0.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.0.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91212205\n",
      " -- 2.3230 bpw  accuracy: 0.91793514\n",
      " -- 2.5958 bpw  accuracy: 0.93299460\n",
      " -- 2.9120 bpw  accuracy: 0.93754802\n",
      " -- 3.2833 bpw  accuracy: 0.96452868\n",
      " -- 3.3655 bpw  accuracy: 0.96755076\n",
      " -- 3.6186 bpw  accuracy: 0.97444370\n",
      " -- 4.1368 bpw  accuracy: 0.98127873\n",
      " -- 4.1977 bpw  accuracy: 0.98318225\n",
      " -- 4.2662 bpw  accuracy: 0.98229339\n",
      " -- 4.3484 bpw  accuracy: 0.98440254\n",
      " -- 5.2491 bpw  accuracy: 0.99094487\n",
      " -- 5.3313 bpw  accuracy: 0.99229359\n",
      " -- 6.0713 bpw  accuracy: 0.99498935\n",
      " -- 6.3032 bpw  accuracy: 0.99538955\n",
      " -- 6.8687 bpw  accuracy: 0.99689787\n",
      " -- 8.0354 bpw  accuracy: 0.99855281\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.0 (MLP)          |\n",
      "| Duration: 12.45 seconds                 |\n",
      "| Completed step: 2/67                    |\n",
      "| Avg time / step (rolling): 9.64 seconds |\n",
      "| Estimated remaining time: 10min 26sec   |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.1 (Attention)\n",
      " -- model.layers.1.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.87931279\n",
      " -- 2.1987 bpw  accuracy: 0.88825783\n",
      " -- 2.2831 bpw  accuracy: 0.90797994\n",
      " -- 2.6768 bpw  accuracy: 0.93049224\n",
      " -- 3.1689 bpw  accuracy: 0.93213076\n",
      " -- 3.1705 bpw  accuracy: 0.93631891\n",
      " -- 4.0439 bpw  accuracy: 0.93977425\n",
      " -- 4.0471 bpw  accuracy: 0.94500983\n",
      " -- 4.0816 bpw  accuracy: 0.95950073\n",
      " -- 4.1381 bpw  accuracy: 0.96080988\n",
      " -- 4.1705 bpw  accuracy: 0.96763901\n",
      " -- 4.1902 bpw  accuracy: 0.97305983\n",
      " -- 4.2737 bpw  accuracy: 0.96920943\n",
      " -- 4.3295 bpw  accuracy: 0.97491567\n",
      " -- 5.2564 bpw  accuracy: 0.98266341\n",
      " -- 5.3295 bpw  accuracy: 0.98787688\n",
      " -- 6.0439 bpw  accuracy: 0.98431779\n",
      " -- 6.3381 bpw  accuracy: 0.99474398\n",
      " -- 8.0439 bpw  accuracy: 0.99578972\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.1 (Attention)    |\n",
      "| Duration: 5.90 seconds                  |\n",
      "| Completed step: 3/67                    |\n",
      "| Avg time / step (rolling): 8.40 seconds |\n",
      "| Estimated remaining time: 8min 57sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.1 (MLP)\n",
      " -- model.layers.1.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.1.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.1.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.1.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.1.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.96608414\n",
      " -- 2.3230 bpw  accuracy: 0.96938401\n",
      " -- 2.5958 bpw  accuracy: 0.96992985\n",
      " -- 2.9120 bpw  accuracy: 0.97001565\n",
      " -- 3.2833 bpw  accuracy: 0.99304748\n",
      " -- 3.3655 bpw  accuracy: 0.99434515\n",
      " -- 3.6186 bpw  accuracy: 0.99465657\n",
      " -- 4.1368 bpw  accuracy: 0.99801330\n",
      " -- 4.1977 bpw  accuracy: 0.99810995\n",
      " -- 4.2662 bpw  accuracy: 0.99793945\n",
      " -- 4.3484 bpw  accuracy: 0.99788170\n",
      " -- 5.2491 bpw  accuracy: 0.99838430\n",
      " -- 5.3313 bpw  accuracy: 0.99897450\n",
      " -- 6.0713 bpw  accuracy: 0.99923848\n",
      " -- 6.3032 bpw  accuracy: 0.99932434\n",
      " -- 6.8687 bpw  accuracy: 0.99940951\n",
      " -- 8.0354 bpw  accuracy: 0.99947565\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.1 (MLP)          |\n",
      "| Duration: 12.42 seconds                 |\n",
      "| Completed step: 4/67                    |\n",
      "| Avg time / step (rolling): 9.40 seconds |\n",
      "| Estimated remaining time: 9min 52sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.2 (Attention)\n",
      " -- model.layers.2.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.99359356\n",
      " -- 2.1987 bpw  accuracy: 0.99421120\n",
      " -- 2.2831 bpw  accuracy: 0.99472415\n",
      " -- 2.6768 bpw  accuracy: 0.99566290\n",
      " -- 3.1689 bpw  accuracy: 0.99651476\n",
      " -- 3.1705 bpw  accuracy: 0.99635336\n",
      " -- 4.0439 bpw  accuracy: 0.99770281\n",
      " -- 4.0471 bpw  accuracy: 0.99772179\n",
      " -- 4.0816 bpw  accuracy: 0.99785853\n",
      " -- 4.1381 bpw  accuracy: 0.99793575\n",
      " -- 4.1705 bpw  accuracy: 0.99795375\n",
      " -- 4.1902 bpw  accuracy: 0.99817918\n",
      " -- 4.2737 bpw  accuracy: 0.99854779\n",
      " -- 4.3295 bpw  accuracy: 0.99872973\n",
      " -- 5.2564 bpw  accuracy: 0.99924571\n",
      " -- 5.3295 bpw  accuracy: 0.99936718\n",
      " -- 6.0439 bpw  accuracy: 0.99937061\n",
      " -- 6.3381 bpw  accuracy: 0.99971614\n",
      " -- 8.0439 bpw  accuracy: 0.99982528\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.2 (Attention)    |\n",
      "| Duration: 5.65 seconds                  |\n",
      "| Completed step: 5/67                    |\n",
      "| Avg time / step (rolling): 8.65 seconds |\n",
      "| Estimated remaining time: 8min 56sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.2 (MLP)\n",
      " -- model.layers.2.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.2.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.2.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.2.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.2.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.99243315\n",
      " -- 2.3230 bpw  accuracy: 0.99262640\n",
      " -- 2.5958 bpw  accuracy: 0.99378867\n",
      " -- 2.9120 bpw  accuracy: 0.99415083\n",
      " -- 3.2833 bpw  accuracy: 0.99627709\n",
      " -- 3.3655 bpw  accuracy: 0.99657315\n",
      " -- 3.6186 bpw  accuracy: 0.99706229\n",
      " -- 4.1368 bpw  accuracy: 0.99808241\n",
      " -- 4.1977 bpw  accuracy: 0.99825755\n",
      " -- 4.2662 bpw  accuracy: 0.99811450\n",
      " -- 4.3484 bpw  accuracy: 0.99834868\n",
      " -- 5.2491 bpw  accuracy: 0.99903993\n",
      " -- 5.3313 bpw  accuracy: 0.99917806\n",
      " -- 6.0713 bpw  accuracy: 0.99948300\n",
      " -- 6.3032 bpw  accuracy: 0.99951126\n",
      " -- 6.8687 bpw  accuracy: 0.99960904\n",
      " -- 8.0354 bpw  accuracy: 0.99986214\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.2 (MLP)          |\n",
      "| Duration: 12.43 seconds                 |\n",
      "| Completed step: 6/67                    |\n",
      "| Avg time / step (rolling): 9.28 seconds |\n",
      "| Estimated remaining time: 9min 26sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.3 (Attention)\n",
      " -- model.layers.3.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.99258306\n",
      " -- 2.1987 bpw  accuracy: 0.99288685\n",
      " -- 2.2831 bpw  accuracy: 0.99387727\n",
      " -- 2.6768 bpw  accuracy: 0.99532979\n",
      " -- 3.1689 bpw  accuracy: 0.99569674\n",
      " -- 3.1705 bpw  accuracy: 0.99594202\n",
      " -- 4.0439 bpw  accuracy: 0.99641024\n",
      " -- 4.0471 bpw  accuracy: 0.99670388\n",
      " -- 4.0816 bpw  accuracy: 0.99695250\n",
      " -- 4.1381 bpw  accuracy: 0.99704013\n",
      " -- 4.1705 bpw  accuracy: 0.99789026\n",
      " -- 4.1902 bpw  accuracy: 0.99810381\n",
      " -- 4.2737 bpw  accuracy: 0.99803150\n",
      " -- 4.3295 bpw  accuracy: 0.99825230\n",
      " -- 5.2564 bpw  accuracy: 0.99887031\n",
      " -- 5.3295 bpw  accuracy: 0.99914836\n",
      " -- 6.0439 bpw  accuracy: 0.99899333\n",
      " -- 6.3381 bpw  accuracy: 0.99964147\n",
      " -- 8.0439 bpw  accuracy: 0.99974809\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.3 (Attention)    |\n",
      "| Duration: 5.68 seconds                  |\n",
      "| Completed step: 7/67                    |\n",
      "| Avg time / step (rolling): 8.77 seconds |\n",
      "| Estimated remaining time: 8min 45sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.3 (MLP)\n",
      " -- model.layers.3.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.3.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.3.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.3.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.3.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.98870050\n",
      " -- 2.3230 bpw  accuracy: 0.98898448\n",
      " -- 2.5958 bpw  accuracy: 0.99069135\n",
      " -- 2.9120 bpw  accuracy: 0.99122993\n",
      " -- 3.2833 bpw  accuracy: 0.99436136\n",
      " -- 3.3655 bpw  accuracy: 0.99481220\n",
      " -- 3.6186 bpw  accuracy: 0.99553311\n",
      " -- 4.1368 bpw  accuracy: 0.99709401\n",
      " -- 4.1977 bpw  accuracy: 0.99736074\n",
      " -- 4.2662 bpw  accuracy: 0.99714101\n",
      " -- 4.3484 bpw  accuracy: 0.99749703\n",
      " -- 5.2491 bpw  accuracy: 0.99854471\n",
      " -- 5.3313 bpw  accuracy: 0.99875471\n",
      " -- 6.0713 bpw  accuracy: 0.99921664\n",
      " -- 6.3032 bpw  accuracy: 0.99925905\n",
      " -- 6.8687 bpw  accuracy: 0.99940325\n",
      " -- 8.0354 bpw  accuracy: 0.99979226\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.3 (MLP)          |\n",
      "| Duration: 12.51 seconds                 |\n",
      "| Completed step: 8/67                    |\n",
      "| Avg time / step (rolling): 9.23 seconds |\n",
      "| Estimated remaining time: 9min 4sec     |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.4 (Attention)\n",
      " -- model.layers.4.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.99119081\n",
      " -- 2.1987 bpw  accuracy: 0.99171674\n",
      " -- 2.2831 bpw  accuracy: 0.99280545\n",
      " -- 2.6768 bpw  accuracy: 0.99450364\n",
      " -- 3.1689 bpw  accuracy: 0.99514581\n",
      " -- 3.1705 bpw  accuracy: 0.99511726\n",
      " -- 4.0439 bpw  accuracy: 0.99611307\n",
      " -- 4.0471 bpw  accuracy: 0.99608983\n",
      " -- 4.0816 bpw  accuracy: 0.99654584\n",
      " -- 4.1381 bpw  accuracy: 0.99662537\n",
      " -- 4.1705 bpw  accuracy: 0.99750439\n",
      " -- 4.1902 bpw  accuracy: 0.99769832\n",
      " -- 4.2737 bpw  accuracy: 0.99769078\n",
      " -- 4.3295 bpw  accuracy: 0.99789948\n",
      " -- 5.2564 bpw  accuracy: 0.99862475\n",
      " -- 5.3295 bpw  accuracy: 0.99895203\n",
      " -- 6.0439 bpw  accuracy: 0.99877950\n",
      " -- 6.3381 bpw  accuracy: 0.99955133\n",
      " -- 8.0439 bpw  accuracy: 0.99971604\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.4 (Attention)    |\n",
      "| Duration: 5.87 seconds                  |\n",
      "| Completed step: 9/67                    |\n",
      "| Avg time / step (rolling): 8.86 seconds |\n",
      "| Estimated remaining time: 8min 33sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.4 (MLP)\n",
      " -- model.layers.4.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.4.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.4.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.4.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.4.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.98433968\n",
      " -- 2.3230 bpw  accuracy: 0.98478074\n",
      " -- 2.5958 bpw  accuracy: 0.98727266\n",
      " -- 2.9120 bpw  accuracy: 0.98801788\n",
      " -- 3.2833 bpw  accuracy: 0.99220231\n",
      " -- 3.3655 bpw  accuracy: 0.99285298\n",
      " -- 3.6186 bpw  accuracy: 0.99385501\n",
      " -- 4.1368 bpw  accuracy: 0.99597492\n",
      " -- 4.1977 bpw  accuracy: 0.99634128\n",
      " -- 4.2662 bpw  accuracy: 0.99603837\n",
      " -- 4.3484 bpw  accuracy: 0.99654748\n",
      " -- 5.2491 bpw  accuracy: 0.99797937\n",
      " -- 5.3313 bpw  accuracy: 0.99827993\n",
      " -- 6.0713 bpw  accuracy: 0.99890538\n",
      " -- 6.3032 bpw  accuracy: 0.99896961\n",
      " -- 6.8687 bpw  accuracy: 0.99917432\n",
      " -- 8.0354 bpw  accuracy: 0.99970934\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.4 (MLP)          |\n",
      "| Duration: 12.54 seconds                 |\n",
      "| Completed step: 10/67                   |\n",
      "| Avg time / step (rolling): 9.23 seconds |\n",
      "| Estimated remaining time: 8min 46sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.5 (Attention)\n",
      " -- model.layers.5.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.98742578\n",
      " -- 2.1987 bpw  accuracy: 0.98777220\n",
      " -- 2.2831 bpw  accuracy: 0.98923704\n",
      " -- 2.6768 bpw  accuracy: 0.99154794\n",
      " -- 3.1689 bpw  accuracy: 0.99360904\n",
      " -- 3.1705 bpw  accuracy: 0.99394420\n",
      " -- 4.0439 bpw  accuracy: 0.99518259\n",
      " -- 4.0471 bpw  accuracy: 0.99564792\n",
      " -- 4.0816 bpw  accuracy: 0.99602585\n",
      " -- 4.1381 bpw  accuracy: 0.99612439\n",
      " -- 4.1705 bpw  accuracy: 0.99696751\n",
      " -- 4.1902 bpw  accuracy: 0.99716303\n",
      " -- 4.2737 bpw  accuracy: 0.99725349\n",
      " -- 4.3295 bpw  accuracy: 0.99749166\n",
      " -- 5.2564 bpw  accuracy: 0.99848565\n",
      " -- 5.3295 bpw  accuracy: 0.99878319\n",
      " -- 6.0439 bpw  accuracy: 0.99878414\n",
      " -- 6.3381 bpw  accuracy: 0.99941139\n",
      " -- 8.0439 bpw  accuracy: 0.99967507\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.5 (Attention)        |\n",
      "| Duration: 5.97 seconds                      |\n",
      "| Completed step: 11/67                       |\n",
      "| Avg time / step (rolling): 9.14 seconds     |\n",
      "| Estimated remaining time: 8min 31sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.5 (MLP)\n",
      " -- model.layers.5.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.5.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.5.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.5.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.5.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.97943368\n",
      " -- 2.3230 bpw  accuracy: 0.98000287\n",
      " -- 2.5958 bpw  accuracy: 0.98324850\n",
      " -- 2.9120 bpw  accuracy: 0.98419845\n",
      " -- 3.2833 bpw  accuracy: 0.98976409\n",
      " -- 3.3655 bpw  accuracy: 0.99059691\n",
      " -- 3.6186 bpw  accuracy: 0.99189836\n",
      " -- 4.1368 bpw  accuracy: 0.99472744\n",
      " -- 4.1977 bpw  accuracy: 0.99519181\n",
      " -- 4.2662 bpw  accuracy: 0.99480462\n",
      " -- 4.3484 bpw  accuracy: 0.99546309\n",
      " -- 5.2491 bpw  accuracy: 0.99735872\n",
      " -- 5.3313 bpw  accuracy: 0.99774203\n",
      " -- 6.0713 bpw  accuracy: 0.99857390\n",
      " -- 6.3032 bpw  accuracy: 0.99865517\n",
      " -- 6.8687 bpw  accuracy: 0.99892001\n",
      " -- 8.0354 bpw  accuracy: 0.99961672\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.5 (MLP)              |\n",
      "| Duration: 12.56 seconds                     |\n",
      "| Completed step: 12/67                       |\n",
      "| Avg time / step (rolling): 9.15 seconds     |\n",
      "| Estimated remaining time: 8min 23sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.6 (Attention)\n",
      " -- model.layers.6.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.98602252\n",
      " -- 2.1987 bpw  accuracy: 0.98666951\n",
      " -- 2.2831 bpw  accuracy: 0.98815132\n",
      " -- 2.6768 bpw  accuracy: 0.99104597\n",
      " -- 3.1689 bpw  accuracy: 0.99278365\n",
      " -- 3.1705 bpw  accuracy: 0.99295273\n",
      " -- 4.0439 bpw  accuracy: 0.99462166\n",
      " -- 4.0471 bpw  accuracy: 0.99477944\n",
      " -- 4.0816 bpw  accuracy: 0.99544638\n",
      " -- 4.1381 bpw  accuracy: 0.99567141\n",
      " -- 4.1705 bpw  accuracy: 0.99652906\n",
      " -- 4.1902 bpw  accuracy: 0.99681748\n",
      " -- 4.2737 bpw  accuracy: 0.99687286\n",
      " -- 4.3295 bpw  accuracy: 0.99720920\n",
      " -- 5.2564 bpw  accuracy: 0.99831414\n",
      " -- 5.3295 bpw  accuracy: 0.99861937\n",
      " -- 6.0439 bpw  accuracy: 0.99868104\n",
      " -- 6.3381 bpw  accuracy: 0.99929887\n",
      " -- 8.0439 bpw  accuracy: 0.99964854\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.6 (Attention)        |\n",
      "| Duration: 5.90 seconds                      |\n",
      "| Completed step: 13/67                       |\n",
      "| Avg time / step (rolling): 9.15 seconds     |\n",
      "| Estimated remaining time: 8min 14sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.6 (MLP)\n",
      " -- model.layers.6.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.6.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.6.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.6.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.6.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.97522566\n",
      " -- 2.3230 bpw  accuracy: 0.97588204\n",
      " -- 2.5958 bpw  accuracy: 0.97999872\n",
      " -- 2.9120 bpw  accuracy: 0.98120103\n",
      " -- 3.2833 bpw  accuracy: 0.98764048\n",
      " -- 3.3655 bpw  accuracy: 0.98866805\n",
      " -- 3.6186 bpw  accuracy: 0.99031908\n",
      " -- 4.1368 bpw  accuracy: 0.99361881\n",
      " -- 4.1977 bpw  accuracy: 0.99420246\n",
      " -- 4.2662 bpw  accuracy: 0.99372014\n",
      " -- 4.3484 bpw  accuracy: 0.99452585\n",
      " -- 5.2491 bpw  accuracy: 0.99680247\n",
      " -- 5.3313 bpw  accuracy: 0.99727331\n",
      " -- 6.0713 bpw  accuracy: 0.99827127\n",
      " -- 6.3032 bpw  accuracy: 0.99837239\n",
      " -- 6.8687 bpw  accuracy: 0.99871692\n",
      " -- 8.0354 bpw  accuracy: 0.99953986\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.6 (MLP)              |\n",
      "| Duration: 12.58 seconds                     |\n",
      "| Completed step: 14/67                       |\n",
      "| Avg time / step (rolling): 9.17 seconds     |\n",
      "| Estimated remaining time: 8min 5sec         |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.7 (Attention)\n",
      " -- model.layers.7.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.98201832\n",
      " -- 2.1987 bpw  accuracy: 0.98279462\n",
      " -- 2.2831 bpw  accuracy: 0.98450594\n",
      " -- 2.6768 bpw  accuracy: 0.98861564\n",
      " -- 3.1689 bpw  accuracy: 0.99035540\n",
      " -- 3.1705 bpw  accuracy: 0.99062601\n",
      " -- 4.0439 bpw  accuracy: 0.99304594\n",
      " -- 4.0471 bpw  accuracy: 0.99335960\n",
      " -- 4.0816 bpw  accuracy: 0.99423760\n",
      " -- 4.1381 bpw  accuracy: 0.99454967\n",
      " -- 4.1705 bpw  accuracy: 0.99533481\n",
      " -- 4.1902 bpw  accuracy: 0.99572081\n",
      " -- 4.2737 bpw  accuracy: 0.99588785\n",
      " -- 4.3295 bpw  accuracy: 0.99626581\n",
      " -- 5.2564 bpw  accuracy: 0.99767528\n",
      " -- 5.3295 bpw  accuracy: 0.99813829\n",
      " -- 6.0439 bpw  accuracy: 0.99821939\n",
      " -- 6.3381 bpw  accuracy: 0.99898865\n",
      " -- 8.0439 bpw  accuracy: 0.99953420\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.7 (Attention)        |\n",
      "| Duration: 5.89 seconds                      |\n",
      "| Completed step: 15/67                       |\n",
      "| Avg time / step (rolling): 9.19 seconds     |\n",
      "| Estimated remaining time: 7min 58sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.7 (MLP)\n",
      " -- model.layers.7.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.7.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.7.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.7.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.7.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.97086309\n",
      " -- 2.3230 bpw  accuracy: 0.97167503\n",
      " -- 2.5958 bpw  accuracy: 0.97627536\n",
      " -- 2.9120 bpw  accuracy: 0.97760823\n",
      " -- 3.2833 bpw  accuracy: 0.98546926\n",
      " -- 3.3655 bpw  accuracy: 0.98668658\n",
      " -- 3.6186 bpw  accuracy: 0.98850733\n",
      " -- 4.1368 bpw  accuracy: 0.99250820\n",
      " -- 4.1977 bpw  accuracy: 0.99317459\n",
      " -- 4.2662 bpw  accuracy: 0.99260453\n",
      " -- 4.3484 bpw  accuracy: 0.99355475\n",
      " -- 5.2491 bpw  accuracy: 0.99622716\n",
      " -- 5.3313 bpw  accuracy: 0.99678799\n",
      " -- 6.0713 bpw  accuracy: 0.99795865\n",
      " -- 6.3032 bpw  accuracy: 0.99807368\n",
      " -- 6.8687 bpw  accuracy: 0.99844762\n",
      " -- 8.0354 bpw  accuracy: 0.99945865\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.7 (MLP)              |\n",
      "| Duration: 12.63 seconds                     |\n",
      "| Completed step: 16/67                       |\n",
      "| Avg time / step (rolling): 9.21 seconds     |\n",
      "| Estimated remaining time: 7min 49sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.8 (Attention)\n",
      " -- model.layers.8.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.98092440\n",
      " -- 2.1987 bpw  accuracy: 0.98157018\n",
      " -- 2.2831 bpw  accuracy: 0.98333620\n",
      " -- 2.6768 bpw  accuracy: 0.98787190\n",
      " -- 3.1689 bpw  accuracy: 0.98984485\n",
      " -- 3.1705 bpw  accuracy: 0.99017935\n",
      " -- 4.0439 bpw  accuracy: 0.99262377\n",
      " -- 4.0471 bpw  accuracy: 0.99309656\n",
      " -- 4.0816 bpw  accuracy: 0.99392060\n",
      " -- 4.1381 bpw  accuracy: 0.99416359\n",
      " -- 4.1705 bpw  accuracy: 0.99488895\n",
      " -- 4.1902 bpw  accuracy: 0.99541865\n",
      " -- 4.2737 bpw  accuracy: 0.99542704\n",
      " -- 4.3295 bpw  accuracy: 0.99594475\n",
      " -- 5.2564 bpw  accuracy: 0.99749842\n",
      " -- 5.3295 bpw  accuracy: 0.99796798\n",
      " -- 6.0439 bpw  accuracy: 0.99808698\n",
      " -- 6.3381 bpw  accuracy: 0.99892050\n",
      " -- 8.0439 bpw  accuracy: 0.99949642\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.8 (Attention)        |\n",
      "| Duration: 5.90 seconds                      |\n",
      "| Completed step: 17/67                       |\n",
      "| Avg time / step (rolling): 9.24 seconds     |\n",
      "| Estimated remaining time: 7min 41sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.8 (MLP)\n",
      " -- model.layers.8.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.8.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.8.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.8.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.8.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.96765061\n",
      " -- 2.3230 bpw  accuracy: 0.96853651\n",
      " -- 2.5958 bpw  accuracy: 0.97371658\n",
      " -- 2.9120 bpw  accuracy: 0.97521787\n",
      " -- 3.2833 bpw  accuracy: 0.98383767\n",
      " -- 3.3655 bpw  accuracy: 0.98518425\n",
      " -- 3.6186 bpw  accuracy: 0.98725567\n",
      " -- 4.1368 bpw  accuracy: 0.99166454\n",
      " -- 4.1977 bpw  accuracy: 0.99241497\n",
      " -- 4.2662 bpw  accuracy: 0.99177468\n",
      " -- 4.3484 bpw  accuracy: 0.99283187\n",
      " -- 5.2491 bpw  accuracy: 0.99580324\n",
      " -- 5.3313 bpw  accuracy: 0.99642643\n",
      " -- 6.0713 bpw  accuracy: 0.99773138\n",
      " -- 6.3032 bpw  accuracy: 0.99785979\n",
      " -- 6.8687 bpw  accuracy: 0.99828769\n",
      " -- 8.0354 bpw  accuracy: 0.99939479\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.8 (MLP)              |\n",
      "| Duration: 12.64 seconds                     |\n",
      "| Completed step: 18/67                       |\n",
      "| Avg time / step (rolling): 9.25 seconds     |\n",
      "| Estimated remaining time: 7min 33sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.9 (Attention)\n",
      " -- model.layers.9.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.97773362\n",
      " -- 2.1987 bpw  accuracy: 0.97839233\n",
      " -- 2.2831 bpw  accuracy: 0.97996488\n",
      " -- 2.6768 bpw  accuracy: 0.98460095\n",
      " -- 3.1689 bpw  accuracy: 0.98871484\n",
      " -- 3.1705 bpw  accuracy: 0.98889130\n",
      " -- 4.0439 bpw  accuracy: 0.99218673\n",
      " -- 4.0471 bpw  accuracy: 0.99240020\n",
      " -- 4.0816 bpw  accuracy: 0.99313541\n",
      " -- 4.1381 bpw  accuracy: 0.99359721\n",
      " -- 4.1705 bpw  accuracy: 0.99452015\n",
      " -- 4.1902 bpw  accuracy: 0.99486737\n",
      " -- 4.2737 bpw  accuracy: 0.99512869\n",
      " -- 4.3295 bpw  accuracy: 0.99534841\n",
      " -- 5.2564 bpw  accuracy: 0.99735400\n",
      " -- 5.3295 bpw  accuracy: 0.99776469\n",
      " -- 6.0439 bpw  accuracy: 0.99812584\n",
      " -- 6.3381 bpw  accuracy: 0.99881933\n",
      " -- 8.0439 bpw  accuracy: 0.99949754\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.9 (Attention)        |\n",
      "| Duration: 5.94 seconds                      |\n",
      "| Completed step: 19/67                       |\n",
      "| Avg time / step (rolling): 9.26 seconds     |\n",
      "| Estimated remaining time: 7min 24sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.9 (MLP)\n",
      " -- model.layers.9.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.9.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.9.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.9.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.9.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.96416393\n",
      " -- 2.3230 bpw  accuracy: 0.96519330\n",
      " -- 2.5958 bpw  accuracy: 0.97099707\n",
      " -- 2.9120 bpw  accuracy: 0.97271190\n",
      " -- 3.2833 bpw  accuracy: 0.98202739\n",
      " -- 3.3655 bpw  accuracy: 0.98352379\n",
      " -- 3.6186 bpw  accuracy: 0.98589917\n",
      " -- 4.1368 bpw  accuracy: 0.99070473\n",
      " -- 4.1977 bpw  accuracy: 0.99151905\n",
      " -- 4.2662 bpw  accuracy: 0.99083120\n",
      " -- 4.3484 bpw  accuracy: 0.99201371\n",
      " -- 5.2491 bpw  accuracy: 0.99531132\n",
      " -- 5.3313 bpw  accuracy: 0.99602055\n",
      " -- 6.0713 bpw  accuracy: 0.99744245\n",
      " -- 6.3032 bpw  accuracy: 0.99761483\n",
      " -- 6.8687 bpw  accuracy: 0.99809115\n",
      " -- 8.0354 bpw  accuracy: 0.99932483\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.9 (MLP)              |\n",
      "| Duration: 12.70 seconds                     |\n",
      "| Completed step: 20/67                       |\n",
      "| Avg time / step (rolling): 9.27 seconds     |\n",
      "| Estimated remaining time: 7min 15sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.10 (Attention)\n",
      " -- model.layers.10.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.97415582\n",
      " -- 2.1987 bpw  accuracy: 0.97512094\n",
      " -- 2.2831 bpw  accuracy: 0.97722694\n",
      " -- 2.6768 bpw  accuracy: 0.98297258\n",
      " -- 3.1689 bpw  accuracy: 0.98666592\n",
      " -- 3.1705 bpw  accuracy: 0.98714912\n",
      " -- 4.0439 bpw  accuracy: 0.99099831\n",
      " -- 4.0471 bpw  accuracy: 0.99166279\n",
      " -- 4.0816 bpw  accuracy: 0.99237671\n",
      " -- 4.1381 bpw  accuracy: 0.99245045\n",
      " -- 4.1705 bpw  accuracy: 0.99342258\n",
      " -- 4.1902 bpw  accuracy: 0.99389777\n",
      " -- 4.2737 bpw  accuracy: 0.99416747\n",
      " -- 4.3295 bpw  accuracy: 0.99475431\n",
      " -- 5.2564 bpw  accuracy: 0.99674480\n",
      " -- 5.3295 bpw  accuracy: 0.99735861\n",
      " -- 6.0439 bpw  accuracy: 0.99763569\n",
      " -- 6.3381 bpw  accuracy: 0.99854354\n",
      " -- 8.0439 bpw  accuracy: 0.99937535\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.10 (Attention)       |\n",
      "| Duration: 5.92 seconds                      |\n",
      "| Completed step: 21/67                       |\n",
      "| Avg time / step (rolling): 9.27 seconds     |\n",
      "| Estimated remaining time: 7min 6sec         |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.10 (MLP)\n",
      " -- model.layers.10.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.10.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.10.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.10.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.10.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.96166861\n",
      " -- 2.3230 bpw  accuracy: 0.96281800\n",
      " -- 2.5958 bpw  accuracy: 0.96937947\n",
      " -- 2.9120 bpw  accuracy: 0.97132351\n",
      " -- 3.2833 bpw  accuracy: 0.98074048\n",
      " -- 3.3655 bpw  accuracy: 0.98237925\n",
      " -- 3.6186 bpw  accuracy: 0.98505668\n",
      " -- 4.1368 bpw  accuracy: 0.98993992\n",
      " -- 4.1977 bpw  accuracy: 0.99090032\n",
      " -- 4.2662 bpw  accuracy: 0.99018009\n",
      " -- 4.3484 bpw  accuracy: 0.99145387\n",
      " -- 5.2491 bpw  accuracy: 0.99498855\n",
      " -- 5.3313 bpw  accuracy: 0.99573408\n",
      " -- 6.0713 bpw  accuracy: 0.99726801\n",
      " -- 6.3032 bpw  accuracy: 0.99744720\n",
      " -- 6.8687 bpw  accuracy: 0.99800836\n",
      " -- 8.0354 bpw  accuracy: 0.99927501\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.10 (MLP)             |\n",
      "| Duration: 12.65 seconds                     |\n",
      "| Completed step: 22/67                       |\n",
      "| Avg time / step (rolling): 9.27 seconds     |\n",
      "| Estimated remaining time: 6min 57sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.11 (Attention)\n",
      " -- model.layers.11.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96966793\n",
      " -- 2.1987 bpw  accuracy: 0.97082006\n",
      " -- 2.2831 bpw  accuracy: 0.97332919\n",
      " -- 2.6768 bpw  accuracy: 0.97998372\n",
      " -- 3.1689 bpw  accuracy: 0.98427980\n",
      " -- 3.1705 bpw  accuracy: 0.98483744\n",
      " -- 4.0439 bpw  accuracy: 0.98891956\n",
      " -- 4.0471 bpw  accuracy: 0.98967845\n",
      " -- 4.0816 bpw  accuracy: 0.99022513\n",
      " -- 4.1381 bpw  accuracy: 0.99083030\n",
      " -- 4.1705 bpw  accuracy: 0.99226923\n",
      " -- 4.1902 bpw  accuracy: 0.99287366\n",
      " -- 4.2737 bpw  accuracy: 0.99307966\n",
      " -- 4.3295 bpw  accuracy: 0.99371705\n",
      " -- 5.2564 bpw  accuracy: 0.99616907\n",
      " -- 5.3295 bpw  accuracy: 0.99681480\n",
      " -- 6.0439 bpw  accuracy: 0.99711870\n",
      " -- 6.3381 bpw  accuracy: 0.99817833\n",
      " -- 8.0439 bpw  accuracy: 0.99922016\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.11 (Attention)       |\n",
      "| Duration: 5.94 seconds                      |\n",
      "| Completed step: 23/67                       |\n",
      "| Avg time / step (rolling): 9.28 seconds     |\n",
      "| Estimated remaining time: 6min 48sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.11 (MLP)\n",
      " -- model.layers.11.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.11.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.11.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.11.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.11.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.95922042\n",
      " -- 2.3230 bpw  accuracy: 0.96047180\n",
      " -- 2.5958 bpw  accuracy: 0.96743669\n",
      " -- 2.9120 bpw  accuracy: 0.96952408\n",
      " -- 3.2833 bpw  accuracy: 0.97946534\n",
      " -- 3.3655 bpw  accuracy: 0.98121787\n",
      " -- 3.6186 bpw  accuracy: 0.98408496\n",
      " -- 4.1368 bpw  accuracy: 0.98924080\n",
      " -- 4.1977 bpw  accuracy: 0.99027689\n",
      " -- 4.2662 bpw  accuracy: 0.98953768\n",
      " -- 4.3484 bpw  accuracy: 0.99088544\n",
      " -- 5.2491 bpw  accuracy: 0.99465997\n",
      " -- 5.3313 bpw  accuracy: 0.99545180\n",
      " -- 6.0713 bpw  accuracy: 0.99707477\n",
      " -- 6.3032 bpw  accuracy: 0.99728418\n",
      " -- 6.8687 bpw  accuracy: 0.99788740\n",
      " -- 8.0354 bpw  accuracy: 0.99922166\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.11 (MLP)             |\n",
      "| Duration: 12.69 seconds                     |\n",
      "| Completed step: 24/67                       |\n",
      "| Avg time / step (rolling): 9.29 seconds     |\n",
      "| Estimated remaining time: 6min 39sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.12 (Attention)\n",
      " -- model.layers.12.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96475370\n",
      " -- 2.1987 bpw  accuracy: 0.96595431\n",
      " -- 2.2831 bpw  accuracy: 0.96905509\n",
      " -- 2.6768 bpw  accuracy: 0.97555340\n",
      " -- 3.1689 bpw  accuracy: 0.98084436\n",
      " -- 3.1705 bpw  accuracy: 0.98217187\n",
      " -- 4.0439 bpw  accuracy: 0.98580078\n",
      " -- 4.0471 bpw  accuracy: 0.98744639\n",
      " -- 4.0816 bpw  accuracy: 0.98854786\n",
      " -- 4.1381 bpw  accuracy: 0.98909831\n",
      " -- 4.1705 bpw  accuracy: 0.99054189\n",
      " -- 4.1902 bpw  accuracy: 0.99125083\n",
      " -- 4.2737 bpw  accuracy: 0.99118320\n",
      " -- 4.3295 bpw  accuracy: 0.99223797\n",
      " -- 5.2564 bpw  accuracy: 0.99528250\n",
      " -- 5.3295 bpw  accuracy: 0.99598712\n",
      " -- 6.0439 bpw  accuracy: 0.99633139\n",
      " -- 6.3381 bpw  accuracy: 0.99798870\n",
      " -- 8.0439 bpw  accuracy: 0.99900348\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.12 (Attention)       |\n",
      "| Duration: 5.92 seconds                      |\n",
      "| Completed step: 25/67                       |\n",
      "| Avg time / step (rolling): 9.29 seconds     |\n",
      "| Estimated remaining time: 6min 30sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.12 (MLP)\n",
      " -- model.layers.12.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.12.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.12.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.12.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.12.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.95472549\n",
      " -- 2.3230 bpw  accuracy: 0.95618195\n",
      " -- 2.5958 bpw  accuracy: 0.96355141\n",
      " -- 2.9120 bpw  accuracy: 0.96574847\n",
      " -- 3.2833 bpw  accuracy: 0.97717699\n",
      " -- 3.3655 bpw  accuracy: 0.97916263\n",
      " -- 3.6186 bpw  accuracy: 0.98220581\n",
      " -- 4.1368 bpw  accuracy: 0.98806036\n",
      " -- 4.1977 bpw  accuracy: 0.98919219\n",
      " -- 4.2662 bpw  accuracy: 0.98834977\n",
      " -- 4.3484 bpw  accuracy: 0.98987861\n",
      " -- 5.2491 bpw  accuracy: 0.99404765\n",
      " -- 5.3313 bpw  accuracy: 0.99494200\n",
      " -- 6.0713 bpw  accuracy: 0.99672822\n",
      " -- 6.3032 bpw  accuracy: 0.99695939\n",
      " -- 6.8687 bpw  accuracy: 0.99757533\n",
      " -- 8.0354 bpw  accuracy: 0.99911839\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.12 (MLP)             |\n",
      "| Duration: 12.71 seconds                     |\n",
      "| Completed step: 26/67                       |\n",
      "| Avg time / step (rolling): 9.30 seconds     |\n",
      "| Estimated remaining time: 6min 21sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.13 (Attention)\n",
      " -- model.layers.13.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96367423\n",
      " -- 2.1987 bpw  accuracy: 0.96503918\n",
      " -- 2.2831 bpw  accuracy: 0.96821579\n",
      " -- 2.6768 bpw  accuracy: 0.97687760\n",
      " -- 3.1689 bpw  accuracy: 0.98125775\n",
      " -- 3.1705 bpw  accuracy: 0.98180613\n",
      " -- 4.0439 bpw  accuracy: 0.98797292\n",
      " -- 4.0471 bpw  accuracy: 0.98878535\n",
      " -- 4.0816 bpw  accuracy: 0.98980206\n",
      " -- 4.1381 bpw  accuracy: 0.99057937\n",
      " -- 4.1705 bpw  accuracy: 0.99078687\n",
      " -- 4.1902 bpw  accuracy: 0.99145320\n",
      " -- 4.2737 bpw  accuracy: 0.99202228\n",
      " -- 4.3295 bpw  accuracy: 0.99256864\n",
      " -- 5.2564 bpw  accuracy: 0.99547151\n",
      " -- 5.3295 bpw  accuracy: 0.99633410\n",
      " -- 6.0439 bpw  accuracy: 0.99683450\n",
      " -- 6.3381 bpw  accuracy: 0.99803554\n",
      " -- 8.0439 bpw  accuracy: 0.99917263\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.13 (Attention)       |\n",
      "| Duration: 5.92 seconds                      |\n",
      "| Completed step: 27/67                       |\n",
      "| Avg time / step (rolling): 9.30 seconds     |\n",
      "| Estimated remaining time: 6min 12sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.13 (MLP)\n",
      " -- model.layers.13.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.13.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.13.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.13.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.13.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.95027610\n",
      " -- 2.3230 bpw  accuracy: 0.95181435\n",
      " -- 2.5958 bpw  accuracy: 0.96004384\n",
      " -- 2.9120 bpw  accuracy: 0.96255915\n",
      " -- 3.2833 bpw  accuracy: 0.97486080\n",
      " -- 3.3655 bpw  accuracy: 0.97702852\n",
      " -- 3.6186 bpw  accuracy: 0.98043407\n",
      " -- 4.1368 bpw  accuracy: 0.98679206\n",
      " -- 4.1977 bpw  accuracy: 0.98805719\n",
      " -- 4.2662 bpw  accuracy: 0.98717600\n",
      " -- 4.3484 bpw  accuracy: 0.98884102\n",
      " -- 5.2491 bpw  accuracy: 0.99345785\n",
      " -- 5.3313 bpw  accuracy: 0.99443372\n",
      " -- 6.0713 bpw  accuracy: 0.99640583\n",
      " -- 6.3032 bpw  accuracy: 0.99666765\n",
      " -- 6.8687 bpw  accuracy: 0.99737730\n",
      " -- 8.0354 bpw  accuracy: 0.99904303\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.13 (MLP)             |\n",
      "| Duration: 12.67 seconds                     |\n",
      "| Completed step: 28/67                       |\n",
      "| Avg time / step (rolling): 9.31 seconds     |\n",
      "| Estimated remaining time: 6min 2sec         |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.14 (Attention)\n",
      " -- model.layers.14.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95779067\n",
      " -- 2.1987 bpw  accuracy: 0.95987860\n",
      " -- 2.2831 bpw  accuracy: 0.96351241\n",
      " -- 2.6768 bpw  accuracy: 0.97279913\n",
      " -- 3.1689 bpw  accuracy: 0.97762018\n",
      " -- 3.1705 bpw  accuracy: 0.97878460\n",
      " -- 4.0439 bpw  accuracy: 0.98460035\n",
      " -- 4.0471 bpw  accuracy: 0.98634363\n",
      " -- 4.0816 bpw  accuracy: 0.98764495\n",
      " -- 4.1381 bpw  accuracy: 0.98819556\n",
      " -- 4.1705 bpw  accuracy: 0.98931155\n",
      " -- 4.1902 bpw  accuracy: 0.98989624\n",
      " -- 4.2737 bpw  accuracy: 0.99061134\n",
      " -- 4.3295 bpw  accuracy: 0.99132489\n",
      " -- 5.2564 bpw  accuracy: 0.99446279\n",
      " -- 5.3295 bpw  accuracy: 0.99568203\n",
      " -- 6.0439 bpw  accuracy: 0.99579683\n",
      " -- 6.3381 bpw  accuracy: 0.99759410\n",
      " -- 8.0439 bpw  accuracy: 0.99886613\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.14 (Attention)       |\n",
      "| Duration: 5.93 seconds                      |\n",
      "| Completed step: 29/67                       |\n",
      "| Avg time / step (rolling): 9.31 seconds     |\n",
      "| Estimated remaining time: 5min 53sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.14 (MLP)\n",
      " -- model.layers.14.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.14.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.14.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.14.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.14.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.94679444\n",
      " -- 2.3230 bpw  accuracy: 0.94842617\n",
      " -- 2.5958 bpw  accuracy: 0.95697451\n",
      " -- 2.9120 bpw  accuracy: 0.95956098\n",
      " -- 3.2833 bpw  accuracy: 0.97320012\n",
      " -- 3.3655 bpw  accuracy: 0.97550080\n",
      " -- 3.6186 bpw  accuracy: 0.97901203\n",
      " -- 4.1368 bpw  accuracy: 0.98587665\n",
      " -- 4.1977 bpw  accuracy: 0.98719912\n",
      " -- 4.2662 bpw  accuracy: 0.98630889\n",
      " -- 4.3484 bpw  accuracy: 0.98806254\n",
      " -- 5.2491 bpw  accuracy: 0.99300523\n",
      " -- 5.3313 bpw  accuracy: 0.99402675\n",
      " -- 6.0713 bpw  accuracy: 0.99612347\n",
      " -- 6.3032 bpw  accuracy: 0.99641738\n",
      " -- 6.8687 bpw  accuracy: 0.99714602\n",
      " -- 8.0354 bpw  accuracy: 0.99887060\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.14 (MLP)             |\n",
      "| Duration: 12.71 seconds                     |\n",
      "| Completed step: 30/67                       |\n",
      "| Avg time / step (rolling): 9.31 seconds     |\n",
      "| Estimated remaining time: 5min 44sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.15 (Attention)\n",
      " -- model.layers.15.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95432426\n",
      " -- 2.1987 bpw  accuracy: 0.95562495\n",
      " -- 2.2831 bpw  accuracy: 0.95999078\n",
      " -- 2.6768 bpw  accuracy: 0.96780597\n",
      " -- 3.1689 bpw  accuracy: 0.97481550\n",
      " -- 3.1705 bpw  accuracy: 0.97619820\n",
      " -- 4.0439 bpw  accuracy: 0.98123466\n",
      " -- 4.0471 bpw  accuracy: 0.98304335\n",
      " -- 4.0816 bpw  accuracy: 0.98505501\n",
      " -- 4.1381 bpw  accuracy: 0.98561319\n",
      " -- 4.1705 bpw  accuracy: 0.98796154\n",
      " -- 4.1902 bpw  accuracy: 0.98893136\n",
      " -- 4.2737 bpw  accuracy: 0.98939892\n",
      " -- 4.3295 bpw  accuracy: 0.99031456\n",
      " -- 5.2564 bpw  accuracy: 0.99376402\n",
      " -- 5.3295 bpw  accuracy: 0.99496443\n",
      " -- 6.0439 bpw  accuracy: 0.99498840\n",
      " -- 6.3381 bpw  accuracy: 0.99745911\n",
      " -- 8.0439 bpw  accuracy: 0.99864582\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.15 (Attention)        |\n",
      "| Duration: 5.95 seconds                       |\n",
      "| Completed step: 31/67                        |\n",
      "| Avg time / step (rolling): 9.31 seconds      |\n",
      "| Estimated remaining time: 5min 35sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.15 (MLP)\n",
      " -- model.layers.15.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.15.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.15.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.15.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.15.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.94184416\n",
      " -- 2.3230 bpw  accuracy: 0.94355496\n",
      " -- 2.5958 bpw  accuracy: 0.95283236\n",
      " -- 2.9120 bpw  accuracy: 0.95563020\n",
      " -- 3.2833 bpw  accuracy: 0.97074209\n",
      " -- 3.3655 bpw  accuracy: 0.97319063\n",
      " -- 3.6186 bpw  accuracy: 0.97699091\n",
      " -- 4.1368 bpw  accuracy: 0.98470105\n",
      " -- 4.1977 bpw  accuracy: 0.98609719\n",
      " -- 4.2662 bpw  accuracy: 0.98508900\n",
      " -- 4.3484 bpw  accuracy: 0.98698847\n",
      " -- 5.2491 bpw  accuracy: 0.99239083\n",
      " -- 5.3313 bpw  accuracy: 0.99350955\n",
      " -- 6.0713 bpw  accuracy: 0.99583659\n",
      " -- 6.3032 bpw  accuracy: 0.99612838\n",
      " -- 6.8687 bpw  accuracy: 0.99691346\n",
      " -- 8.0354 bpw  accuracy: 0.99888651\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.15 (MLP)              |\n",
      "| Duration: 12.72 seconds                      |\n",
      "| Completed step: 32/67                        |\n",
      "| Avg time / step (rolling): 9.32 seconds      |\n",
      "| Estimated remaining time: 5min 26sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.16 (Attention)\n",
      " -- model.layers.16.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95644463\n",
      " -- 2.1987 bpw  accuracy: 0.95794426\n",
      " -- 2.2831 bpw  accuracy: 0.96205081\n",
      " -- 2.6768 bpw  accuracy: 0.97116039\n",
      " -- 3.1689 bpw  accuracy: 0.97687967\n",
      " -- 3.1705 bpw  accuracy: 0.97787331\n",
      " -- 4.0439 bpw  accuracy: 0.98456659\n",
      " -- 4.0471 bpw  accuracy: 0.98593625\n",
      " -- 4.0816 bpw  accuracy: 0.98716171\n",
      " -- 4.1381 bpw  accuracy: 0.98759863\n",
      " -- 4.1705 bpw  accuracy: 0.98882029\n",
      " -- 4.1902 bpw  accuracy: 0.98939838\n",
      " -- 4.2737 bpw  accuracy: 0.99012185\n",
      " -- 4.3295 bpw  accuracy: 0.99098191\n",
      " -- 5.2564 bpw  accuracy: 0.99439071\n",
      " -- 5.3295 bpw  accuracy: 0.99548889\n",
      " -- 6.0439 bpw  accuracy: 0.99586066\n",
      " -- 6.3381 bpw  accuracy: 0.99752604\n",
      " -- 8.0439 bpw  accuracy: 0.99887844\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.16 (Attention)        |\n",
      "| Duration: 5.92 seconds                       |\n",
      "| Completed step: 33/67                        |\n",
      "| Avg time / step (rolling): 9.32 seconds      |\n",
      "| Estimated remaining time: 5min 16sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.16 (MLP)\n",
      " -- model.layers.16.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.16.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.16.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.16.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.16.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.93459552\n",
      " -- 2.3230 bpw  accuracy: 0.93651121\n",
      " -- 2.5958 bpw  accuracy: 0.94688100\n",
      " -- 2.9120 bpw  accuracy: 0.95003766\n",
      " -- 3.2833 bpw  accuracy: 0.96715373\n",
      " -- 3.3655 bpw  accuracy: 0.96988981\n",
      " -- 3.6186 bpw  accuracy: 0.97413832\n",
      " -- 4.1368 bpw  accuracy: 0.98278001\n",
      " -- 4.1977 bpw  accuracy: 0.98433880\n",
      " -- 4.2662 bpw  accuracy: 0.98327616\n",
      " -- 4.3484 bpw  accuracy: 0.98540465\n",
      " -- 5.2491 bpw  accuracy: 0.99147589\n",
      " -- 5.3313 bpw  accuracy: 0.99272085\n",
      " -- 6.0713 bpw  accuracy: 0.99530533\n",
      " -- 6.3032 bpw  accuracy: 0.99567356\n",
      " -- 6.8687 bpw  accuracy: 0.99653814\n",
      " -- 8.0354 bpw  accuracy: 0.99873777\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.16 (MLP)              |\n",
      "| Duration: 12.75 seconds                      |\n",
      "| Completed step: 34/67                        |\n",
      "| Avg time / step (rolling): 9.32 seconds      |\n",
      "| Estimated remaining time: 5min 7sec          |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.17 (Attention)\n",
      " -- model.layers.17.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95228611\n",
      " -- 2.1987 bpw  accuracy: 0.95401570\n",
      " -- 2.2831 bpw  accuracy: 0.95858480\n",
      " -- 2.6768 bpw  accuracy: 0.96887368\n",
      " -- 3.1689 bpw  accuracy: 0.97451819\n",
      " -- 3.1705 bpw  accuracy: 0.97598284\n",
      " -- 4.0439 bpw  accuracy: 0.98178941\n",
      " -- 4.0471 bpw  accuracy: 0.98378768\n",
      " -- 4.0816 bpw  accuracy: 0.98521393\n",
      " -- 4.1381 bpw  accuracy: 0.98551639\n",
      " -- 4.1705 bpw  accuracy: 0.98785317\n",
      " -- 4.1902 bpw  accuracy: 0.98845764\n",
      " -- 4.2737 bpw  accuracy: 0.98901957\n",
      " -- 4.3295 bpw  accuracy: 0.98994909\n",
      " -- 5.2564 bpw  accuracy: 0.99360136\n",
      " -- 5.3295 bpw  accuracy: 0.99487555\n",
      " -- 6.0439 bpw  accuracy: 0.99503036\n",
      " -- 6.3381 bpw  accuracy: 0.99725484\n",
      " -- 8.0439 bpw  accuracy: 0.99866535\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.17 (Attention)        |\n",
      "| Duration: 5.94 seconds                       |\n",
      "| Completed step: 35/67                        |\n",
      "| Avg time / step (rolling): 9.32 seconds      |\n",
      "| Estimated remaining time: 4min 58sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.17 (MLP)\n",
      " -- model.layers.17.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.17.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.17.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.17.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.17.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92684644\n",
      " -- 2.3230 bpw  accuracy: 0.92897165\n",
      " -- 2.5958 bpw  accuracy: 0.94076066\n",
      " -- 2.9120 bpw  accuracy: 0.94445423\n",
      " -- 3.2833 bpw  accuracy: 0.96311042\n",
      " -- 3.3655 bpw  accuracy: 0.96621262\n",
      " -- 3.6186 bpw  accuracy: 0.97110012\n",
      " -- 4.1368 bpw  accuracy: 0.98057830\n",
      " -- 4.1977 bpw  accuracy: 0.98239433\n",
      " -- 4.2662 bpw  accuracy: 0.98119236\n",
      " -- 4.3484 bpw  accuracy: 0.98360457\n",
      " -- 5.2491 bpw  accuracy: 0.99040043\n",
      " -- 5.3313 bpw  accuracy: 0.99181314\n",
      " -- 6.0713 bpw  accuracy: 0.99470549\n",
      " -- 6.3032 bpw  accuracy: 0.99511197\n",
      " -- 6.8687 bpw  accuracy: 0.99613405\n",
      " -- 8.0354 bpw  accuracy: 0.99856491\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.17 (MLP)              |\n",
      "| Duration: 12.77 seconds                      |\n",
      "| Completed step: 36/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 4min 49sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.18 (Attention)\n",
      " -- model.layers.18.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95202761\n",
      " -- 2.1987 bpw  accuracy: 0.95361867\n",
      " -- 2.2831 bpw  accuracy: 0.95759109\n",
      " -- 2.6768 bpw  accuracy: 0.96542164\n",
      " -- 3.1689 bpw  accuracy: 0.97324115\n",
      " -- 3.1705 bpw  accuracy: 0.97453198\n",
      " -- 4.0439 bpw  accuracy: 0.97906616\n",
      " -- 4.0471 bpw  accuracy: 0.98072624\n",
      " -- 4.0816 bpw  accuracy: 0.98345481\n",
      " -- 4.1381 bpw  accuracy: 0.98440678\n",
      " -- 4.1705 bpw  accuracy: 0.98707757\n",
      " -- 4.1902 bpw  accuracy: 0.98797169\n",
      " -- 4.2737 bpw  accuracy: 0.98814364\n",
      " -- 4.3295 bpw  accuracy: 0.98934286\n",
      " -- 5.2564 bpw  accuracy: 0.99182337\n",
      " -- 5.3295 bpw  accuracy: 0.99462787\n",
      " -- 6.0439 bpw  accuracy: 0.99273444\n",
      " -- 6.3381 bpw  accuracy: 0.99727986\n",
      " -- 8.0439 bpw  accuracy: 0.99792545\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.18 (Attention)        |\n",
      "| Duration: 5.92 seconds                       |\n",
      "| Completed step: 37/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 4min 39sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.18 (MLP)\n",
      " -- model.layers.18.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.18.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.18.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.18.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.18.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92116436\n",
      " -- 2.3230 bpw  accuracy: 0.92345467\n",
      " -- 2.5958 bpw  accuracy: 0.93614855\n",
      " -- 2.9120 bpw  accuracy: 0.94016690\n",
      " -- 3.2833 bpw  accuracy: 0.96030014\n",
      " -- 3.3655 bpw  accuracy: 0.96360613\n",
      " -- 3.6186 bpw  accuracy: 0.96887799\n",
      " -- 4.1368 bpw  accuracy: 0.97902316\n",
      " -- 4.1977 bpw  accuracy: 0.98097977\n",
      " -- 4.2662 bpw  accuracy: 0.97975295\n",
      " -- 4.3484 bpw  accuracy: 0.98234711\n",
      " -- 5.2491 bpw  accuracy: 0.98966947\n",
      " -- 5.3313 bpw  accuracy: 0.99118277\n",
      " -- 6.0713 bpw  accuracy: 0.99427651\n",
      " -- 6.3032 bpw  accuracy: 0.99475604\n",
      " -- 6.8687 bpw  accuracy: 0.99587210\n",
      " -- 8.0354 bpw  accuracy: 0.99843175\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.18 (MLP)              |\n",
      "| Duration: 12.74 seconds                      |\n",
      "| Completed step: 38/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 4min 30sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.19 (Attention)\n",
      " -- model.layers.19.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95075124\n",
      " -- 2.1987 bpw  accuracy: 0.95200775\n",
      " -- 2.2831 bpw  accuracy: 0.95643209\n",
      " -- 2.6768 bpw  accuracy: 0.96581477\n",
      " -- 3.1689 bpw  accuracy: 0.97332850\n",
      " -- 3.1705 bpw  accuracy: 0.97486040\n",
      " -- 4.0439 bpw  accuracy: 0.98085764\n",
      " -- 4.0471 bpw  accuracy: 0.98294097\n",
      " -- 4.0816 bpw  accuracy: 0.98407497\n",
      " -- 4.1381 bpw  accuracy: 0.98467343\n",
      " -- 4.1705 bpw  accuracy: 0.98731262\n",
      " -- 4.1902 bpw  accuracy: 0.98818631\n",
      " -- 4.2737 bpw  accuracy: 0.98875682\n",
      " -- 4.3295 bpw  accuracy: 0.98973031\n",
      " -- 5.2564 bpw  accuracy: 0.99333034\n",
      " -- 5.3295 bpw  accuracy: 0.99489429\n",
      " -- 6.0439 bpw  accuracy: 0.99476881\n",
      " -- 6.3381 bpw  accuracy: 0.99718623\n",
      " -- 8.0439 bpw  accuracy: 0.99863210\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.19 (Attention)        |\n",
      "| Duration: 5.93 seconds                       |\n",
      "| Completed step: 39/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 4min 21sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.19 (MLP)\n",
      " -- model.layers.19.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.19.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.19.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.19.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.19.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91867526\n",
      " -- 2.3230 bpw  accuracy: 0.92106681\n",
      " -- 2.5958 bpw  accuracy: 0.93384505\n",
      " -- 2.9120 bpw  accuracy: 0.93793394\n",
      " -- 3.2833 bpw  accuracy: 0.95909830\n",
      " -- 3.3655 bpw  accuracy: 0.96255113\n",
      " -- 3.6186 bpw  accuracy: 0.96788517\n",
      " -- 4.1368 bpw  accuracy: 0.97837400\n",
      " -- 4.1977 bpw  accuracy: 0.98037340\n",
      " -- 4.2662 bpw  accuracy: 0.97912094\n",
      " -- 4.3484 bpw  accuracy: 0.98184130\n",
      " -- 5.2491 bpw  accuracy: 0.98931995\n",
      " -- 5.3313 bpw  accuracy: 0.99091425\n",
      " -- 6.0713 bpw  accuracy: 0.99406801\n",
      " -- 6.3032 bpw  accuracy: 0.99456208\n",
      " -- 6.8687 bpw  accuracy: 0.99566976\n",
      " -- 8.0354 bpw  accuracy: 0.99835028\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.19 (MLP)              |\n",
      "| Duration: 12.70 seconds                      |\n",
      "| Completed step: 40/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 4min 12sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.20 (Attention)\n",
      " -- model.layers.20.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95864972\n",
      " -- 2.1987 bpw  accuracy: 0.96024353\n",
      " -- 2.2831 bpw  accuracy: 0.96286971\n",
      " -- 2.6768 bpw  accuracy: 0.97053128\n",
      " -- 3.1689 bpw  accuracy: 0.97648990\n",
      " -- 3.1705 bpw  accuracy: 0.97778272\n",
      " -- 4.0439 bpw  accuracy: 0.98197751\n",
      " -- 4.0471 bpw  accuracy: 0.98360134\n",
      " -- 4.0816 bpw  accuracy: 0.98546567\n",
      " -- 4.1381 bpw  accuracy: 0.98637403\n",
      " -- 4.1705 bpw  accuracy: 0.98838282\n",
      " -- 4.1902 bpw  accuracy: 0.98962847\n",
      " -- 4.2737 bpw  accuracy: 0.98945120\n",
      " -- 4.3295 bpw  accuracy: 0.99036229\n",
      " -- 5.2564 bpw  accuracy: 0.99385196\n",
      " -- 5.3295 bpw  accuracy: 0.99518388\n",
      " -- 6.0439 bpw  accuracy: 0.99480474\n",
      " -- 6.3381 bpw  accuracy: 0.99755255\n",
      " -- 8.0439 bpw  accuracy: 0.99860405\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.20 (Attention)        |\n",
      "| Duration: 5.93 seconds                       |\n",
      "| Completed step: 41/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 4min 2sec          |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.20 (MLP)\n",
      " -- model.layers.20.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.20.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.20.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.20.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.20.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91774950\n",
      " -- 2.3230 bpw  accuracy: 0.92006630\n",
      " -- 2.5958 bpw  accuracy: 0.93254881\n",
      " -- 2.9120 bpw  accuracy: 0.93645064\n",
      " -- 3.2833 bpw  accuracy: 0.95870846\n",
      " -- 3.3655 bpw  accuracy: 0.96209310\n",
      " -- 3.6186 bpw  accuracy: 0.96727901\n",
      " -- 4.1368 bpw  accuracy: 0.97839959\n",
      " -- 4.1977 bpw  accuracy: 0.98033201\n",
      " -- 4.2662 bpw  accuracy: 0.97899083\n",
      " -- 4.3484 bpw  accuracy: 0.98164852\n",
      " -- 5.2491 bpw  accuracy: 0.98929256\n",
      " -- 5.3313 bpw  accuracy: 0.99084603\n",
      " -- 6.0713 bpw  accuracy: 0.99412309\n",
      " -- 6.3032 bpw  accuracy: 0.99456254\n",
      " -- 6.8687 bpw  accuracy: 0.99561850\n",
      " -- 8.0354 bpw  accuracy: 0.99839274\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.20 (MLP)              |\n",
      "| Duration: 12.76 seconds                      |\n",
      "| Completed step: 42/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 3min 53sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.21 (Attention)\n",
      " -- model.layers.21.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96173114\n",
      " -- 2.1987 bpw  accuracy: 0.96311745\n",
      " -- 2.2831 bpw  accuracy: 0.96596058\n",
      " -- 2.6768 bpw  accuracy: 0.97291412\n",
      " -- 3.1689 bpw  accuracy: 0.97880751\n",
      " -- 3.1705 bpw  accuracy: 0.98040999\n",
      " -- 4.0439 bpw  accuracy: 0.98353478\n",
      " -- 4.0471 bpw  accuracy: 0.98575781\n",
      " -- 4.0816 bpw  accuracy: 0.98712469\n",
      " -- 4.1381 bpw  accuracy: 0.98793867\n",
      " -- 4.1705 bpw  accuracy: 0.98896883\n",
      " -- 4.1902 bpw  accuracy: 0.99054370\n",
      " -- 4.2737 bpw  accuracy: 0.99025041\n",
      " -- 4.3295 bpw  accuracy: 0.99148770\n",
      " -- 5.2564 bpw  accuracy: 0.99424054\n",
      " -- 5.3295 bpw  accuracy: 0.99563929\n",
      " -- 6.0439 bpw  accuracy: 0.99504195\n",
      " -- 6.3381 bpw  accuracy: 0.99778893\n",
      " -- 8.0439 bpw  accuracy: 0.99870432\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.21 (Attention)        |\n",
      "| Duration: 5.92 seconds                       |\n",
      "| Completed step: 43/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 3min 44sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.21 (MLP)\n",
      " -- model.layers.21.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.21.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.21.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.21.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.21.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91743396\n",
      " -- 2.3230 bpw  accuracy: 0.91979057\n",
      " -- 2.5958 bpw  accuracy: 0.93180929\n",
      " -- 2.9120 bpw  accuracy: 0.93552106\n",
      " -- 3.2833 bpw  accuracy: 0.95871188\n",
      " -- 3.3655 bpw  accuracy: 0.96200310\n",
      " -- 3.6186 bpw  accuracy: 0.96692264\n",
      " -- 4.1368 bpw  accuracy: 0.97849119\n",
      " -- 4.1977 bpw  accuracy: 0.98035304\n",
      " -- 4.2662 bpw  accuracy: 0.97901689\n",
      " -- 4.3484 bpw  accuracy: 0.98163355\n",
      " -- 5.2491 bpw  accuracy: 0.98931669\n",
      " -- 5.3313 bpw  accuracy: 0.99084621\n",
      " -- 6.0713 bpw  accuracy: 0.99414699\n",
      " -- 6.3032 bpw  accuracy: 0.99456597\n",
      " -- 6.8687 bpw  accuracy: 0.99553881\n",
      " -- 8.0354 bpw  accuracy: 0.99839766\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.21 (MLP)              |\n",
      "| Duration: 12.73 seconds                      |\n",
      "| Completed step: 44/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 3min 34sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.22 (Attention)\n",
      " -- model.layers.22.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96838669\n",
      " -- 2.1987 bpw  accuracy: 0.96988753\n",
      " -- 2.2831 bpw  accuracy: 0.96993846\n",
      " -- 2.6768 bpw  accuracy: 0.97413742\n",
      " -- 3.1689 bpw  accuracy: 0.97872255\n",
      " -- 3.1705 bpw  accuracy: 0.98177917\n",
      " -- 4.0439 bpw  accuracy: 0.98140499\n",
      " -- 4.0471 bpw  accuracy: 0.98492122\n",
      " -- 4.0816 bpw  accuracy: 0.98661811\n",
      " -- 4.1381 bpw  accuracy: 0.98713781\n",
      " -- 4.1705 bpw  accuracy: 0.98969849\n",
      " -- 4.1902 bpw  accuracy: 0.99121142\n",
      " -- 4.2737 bpw  accuracy: 0.99034113\n",
      " -- 4.3295 bpw  accuracy: 0.99182458\n",
      " -- 5.2564 bpw  accuracy: 0.99438404\n",
      " -- 5.3295 bpw  accuracy: 0.99590721\n",
      " -- 6.0439 bpw  accuracy: 0.99484692\n",
      " -- 6.3381 bpw  accuracy: 0.99814600\n",
      " -- 8.0439 bpw  accuracy: 0.99861489\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.22 (Attention)        |\n",
      "| Duration: 5.94 seconds                       |\n",
      "| Completed step: 45/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 3min 25sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.22 (MLP)\n",
      " -- model.layers.22.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.22.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.22.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.22.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.22.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91568508\n",
      " -- 2.3230 bpw  accuracy: 0.91793962\n",
      " -- 2.5958 bpw  accuracy: 0.92992507\n",
      " -- 2.9120 bpw  accuracy: 0.93360258\n",
      " -- 3.2833 bpw  accuracy: 0.95761807\n",
      " -- 3.3655 bpw  accuracy: 0.96098585\n",
      " -- 3.6186 bpw  accuracy: 0.96595532\n",
      " -- 4.1368 bpw  accuracy: 0.97797053\n",
      " -- 4.1977 bpw  accuracy: 0.97988504\n",
      " -- 4.2662 bpw  accuracy: 0.97846384\n",
      " -- 4.3484 bpw  accuracy: 0.98112877\n",
      " -- 5.2491 bpw  accuracy: 0.98904186\n",
      " -- 5.3313 bpw  accuracy: 0.99060057\n",
      " -- 6.0713 bpw  accuracy: 0.99403351\n",
      " -- 6.3032 bpw  accuracy: 0.99443330\n",
      " -- 6.8687 bpw  accuracy: 0.99542613\n",
      " -- 8.0354 bpw  accuracy: 0.99836687\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.22 (MLP)              |\n",
      "| Duration: 12.72 seconds                      |\n",
      "| Completed step: 46/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 3min 15sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.23 (Attention)\n",
      " -- model.layers.23.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96308220\n",
      " -- 2.1987 bpw  accuracy: 0.96464994\n",
      " -- 2.2831 bpw  accuracy: 0.96857622\n",
      " -- 2.6768 bpw  accuracy: 0.97426332\n",
      " -- 3.1689 bpw  accuracy: 0.97979469\n",
      " -- 3.1705 bpw  accuracy: 0.98124980\n",
      " -- 4.0439 bpw  accuracy: 0.98392620\n",
      " -- 4.0471 bpw  accuracy: 0.98576214\n",
      " -- 4.0816 bpw  accuracy: 0.98712805\n",
      " -- 4.1381 bpw  accuracy: 0.98728430\n",
      " -- 4.1705 bpw  accuracy: 0.99063033\n",
      " -- 4.1902 bpw  accuracy: 0.99133685\n",
      " -- 4.2737 bpw  accuracy: 0.99159582\n",
      " -- 4.3295 bpw  accuracy: 0.99223894\n",
      " -- 5.2564 bpw  accuracy: 0.99473978\n",
      " -- 5.3295 bpw  accuracy: 0.99614254\n",
      " -- 6.0439 bpw  accuracy: 0.99542526\n",
      " -- 6.3381 bpw  accuracy: 0.99810128\n",
      " -- 8.0439 bpw  accuracy: 0.99876725\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.23 (Attention)        |\n",
      "| Duration: 5.95 seconds                       |\n",
      "| Completed step: 47/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 3min 6sec          |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.23 (MLP)\n",
      " -- model.layers.23.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.23.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.23.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.23.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.23.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91390200\n",
      " -- 2.3230 bpw  accuracy: 0.91621845\n",
      " -- 2.5958 bpw  accuracy: 0.92813699\n",
      " -- 2.9120 bpw  accuracy: 0.93182266\n",
      " -- 3.2833 bpw  accuracy: 0.95662741\n",
      " -- 3.3655 bpw  accuracy: 0.96009217\n",
      " -- 3.6186 bpw  accuracy: 0.96507237\n",
      " -- 4.1368 bpw  accuracy: 0.97743259\n",
      " -- 4.1977 bpw  accuracy: 0.97943124\n",
      " -- 4.2662 bpw  accuracy: 0.97796268\n",
      " -- 4.3484 bpw  accuracy: 0.98069505\n",
      " -- 5.2491 bpw  accuracy: 0.98877276\n",
      " -- 5.3313 bpw  accuracy: 0.99037580\n",
      " -- 6.0713 bpw  accuracy: 0.99388581\n",
      " -- 6.3032 bpw  accuracy: 0.99428986\n",
      " -- 6.8687 bpw  accuracy: 0.99526901\n",
      " -- 8.0354 bpw  accuracy: 0.99834087\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.23 (MLP)              |\n",
      "| Duration: 12.75 seconds                      |\n",
      "| Completed step: 48/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 2min 57sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.24 (Attention)\n",
      " -- model.layers.24.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96434842\n",
      " -- 2.1987 bpw  accuracy: 0.96543389\n",
      " -- 2.2831 bpw  accuracy: 0.96869033\n",
      " -- 2.6768 bpw  accuracy: 0.97431377\n",
      " -- 3.1689 bpw  accuracy: 0.97936181\n",
      " -- 3.1705 bpw  accuracy: 0.98093670\n",
      " -- 4.0439 bpw  accuracy: 0.98395386\n",
      " -- 4.0471 bpw  accuracy: 0.98582289\n",
      " -- 4.0816 bpw  accuracy: 0.98726444\n",
      " -- 4.1381 bpw  accuracy: 0.98805122\n",
      " -- 4.1705 bpw  accuracy: 0.99043186\n",
      " -- 4.1902 bpw  accuracy: 0.99084105\n",
      " -- 4.2737 bpw  accuracy: 0.99146297\n",
      " -- 4.3295 bpw  accuracy: 0.99204443\n",
      " -- 5.2564 bpw  accuracy: 0.99473991\n",
      " -- 5.3295 bpw  accuracy: 0.99620528\n",
      " -- 6.0439 bpw  accuracy: 0.99546638\n",
      " -- 6.3381 bpw  accuracy: 0.99797762\n",
      " -- 8.0439 bpw  accuracy: 0.99885809\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.24 (Attention)        |\n",
      "| Duration: 5.94 seconds                       |\n",
      "| Completed step: 49/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 2min 48sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.24 (MLP)\n",
      " -- model.layers.24.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.24.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.24.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.24.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.24.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91190560\n",
      " -- 2.3230 bpw  accuracy: 0.91426398\n",
      " -- 2.5958 bpw  accuracy: 0.92626384\n",
      " -- 2.9120 bpw  accuracy: 0.92995346\n",
      " -- 3.2833 bpw  accuracy: 0.95560094\n",
      " -- 3.3655 bpw  accuracy: 0.95917734\n",
      " -- 3.6186 bpw  accuracy: 0.96417092\n",
      " -- 4.1368 bpw  accuracy: 0.97694168\n",
      " -- 4.1977 bpw  accuracy: 0.97895401\n",
      " -- 4.2662 bpw  accuracy: 0.97741818\n",
      " -- 4.3484 bpw  accuracy: 0.98024768\n",
      " -- 5.2491 bpw  accuracy: 0.98851657\n",
      " -- 5.3313 bpw  accuracy: 0.99015908\n",
      " -- 6.0713 bpw  accuracy: 0.99373793\n",
      " -- 6.3032 bpw  accuracy: 0.99416146\n",
      " -- 6.8687 bpw  accuracy: 0.99513421\n",
      " -- 8.0354 bpw  accuracy: 0.99829828\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.24 (MLP)              |\n",
      "| Duration: 12.78 seconds                      |\n",
      "| Completed step: 50/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 2min 38sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.25 (Attention)\n",
      " -- model.layers.25.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95926388\n",
      " -- 2.1987 bpw  accuracy: 0.96060569\n",
      " -- 2.2831 bpw  accuracy: 0.96378547\n",
      " -- 2.6768 bpw  accuracy: 0.97029021\n",
      " -- 3.1689 bpw  accuracy: 0.97734794\n",
      " -- 3.1705 bpw  accuracy: 0.97940122\n",
      " -- 4.0439 bpw  accuracy: 0.98266172\n",
      " -- 4.0471 bpw  accuracy: 0.98522828\n",
      " -- 4.0816 bpw  accuracy: 0.98704142\n",
      " -- 4.1381 bpw  accuracy: 0.98737503\n",
      " -- 4.1705 bpw  accuracy: 0.98964822\n",
      " -- 4.1902 bpw  accuracy: 0.99055244\n",
      " -- 4.2737 bpw  accuracy: 0.99106622\n",
      " -- 4.3295 bpw  accuracy: 0.99164657\n",
      " -- 5.2564 bpw  accuracy: 0.99462175\n",
      " -- 5.3295 bpw  accuracy: 0.99594130\n",
      " -- 6.0439 bpw  accuracy: 0.99553833\n",
      " -- 6.3381 bpw  accuracy: 0.99782340\n",
      " -- 8.0439 bpw  accuracy: 0.99880864\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.25 (Attention)        |\n",
      "| Duration: 5.92 seconds                       |\n",
      "| Completed step: 51/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 2min 29sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.25 (MLP)\n",
      " -- model.layers.25.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.25.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.25.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.25.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.25.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.90941153\n",
      " -- 2.3230 bpw  accuracy: 0.91185446\n",
      " -- 2.5958 bpw  accuracy: 0.92393924\n",
      " -- 2.9120 bpw  accuracy: 0.92768928\n",
      " -- 3.2833 bpw  accuracy: 0.95433942\n",
      " -- 3.3655 bpw  accuracy: 0.95795159\n",
      " -- 3.6186 bpw  accuracy: 0.96300318\n",
      " -- 4.1368 bpw  accuracy: 0.97620395\n",
      " -- 4.1977 bpw  accuracy: 0.97831777\n",
      " -- 4.2662 bpw  accuracy: 0.97680087\n",
      " -- 4.3484 bpw  accuracy: 0.97965260\n",
      " -- 5.2491 bpw  accuracy: 0.98820779\n",
      " -- 5.3313 bpw  accuracy: 0.98986917\n",
      " -- 6.0713 bpw  accuracy: 0.99357920\n",
      " -- 6.3032 bpw  accuracy: 0.99401650\n",
      " -- 6.8687 bpw  accuracy: 0.99501655\n",
      " -- 8.0354 bpw  accuracy: 0.99827717\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.25 (MLP)              |\n",
      "| Duration: 12.72 seconds                      |\n",
      "| Completed step: 52/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 2min 20sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.26 (Attention)\n",
      " -- model.layers.26.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96105823\n",
      " -- 2.1987 bpw  accuracy: 0.96222350\n",
      " -- 2.2831 bpw  accuracy: 0.96540819\n",
      " -- 2.6768 bpw  accuracy: 0.97163326\n",
      " -- 3.1689 bpw  accuracy: 0.97947233\n",
      " -- 3.1705 bpw  accuracy: 0.98026135\n",
      " -- 4.0439 bpw  accuracy: 0.98491051\n",
      " -- 4.0471 bpw  accuracy: 0.98587443\n",
      " -- 4.0816 bpw  accuracy: 0.98792602\n",
      " -- 4.1381 bpw  accuracy: 0.98789488\n",
      " -- 4.1705 bpw  accuracy: 0.99011431\n",
      " -- 4.1902 bpw  accuracy: 0.99087137\n",
      " -- 4.2737 bpw  accuracy: 0.99110346\n",
      " -- 4.3295 bpw  accuracy: 0.99190429\n",
      " -- 5.2564 bpw  accuracy: 0.99454044\n",
      " -- 5.3295 bpw  accuracy: 0.99592678\n",
      " -- 6.0439 bpw  accuracy: 0.99539694\n",
      " -- 6.3381 bpw  accuracy: 0.99787600\n",
      " -- 8.0439 bpw  accuracy: 0.99873082\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.26 (Attention)        |\n",
      "| Duration: 5.94 seconds                       |\n",
      "| Completed step: 53/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 2min 10sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.26 (MLP)\n",
      " -- model.layers.26.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.26.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.26.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.26.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.26.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.90736182\n",
      " -- 2.3230 bpw  accuracy: 0.90980508\n",
      " -- 2.5958 bpw  accuracy: 0.92198429\n",
      " -- 2.9120 bpw  accuracy: 0.92576915\n",
      " -- 3.2833 bpw  accuracy: 0.95319138\n",
      " -- 3.3655 bpw  accuracy: 0.95691877\n",
      " -- 3.6186 bpw  accuracy: 0.96207530\n",
      " -- 4.1368 bpw  accuracy: 0.97565365\n",
      " -- 4.1977 bpw  accuracy: 0.97780406\n",
      " -- 4.2662 bpw  accuracy: 0.97619532\n",
      " -- 4.3484 bpw  accuracy: 0.97915181\n",
      " -- 5.2491 bpw  accuracy: 0.98790021\n",
      " -- 5.3313 bpw  accuracy: 0.98961963\n",
      " -- 6.0713 bpw  accuracy: 0.99341071\n",
      " -- 6.3032 bpw  accuracy: 0.99384956\n",
      " -- 6.8687 bpw  accuracy: 0.99485843\n",
      " -- 8.0354 bpw  accuracy: 0.99819663\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.26 (MLP)              |\n",
      "| Duration: 12.75 seconds                      |\n",
      "| Completed step: 54/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 2min 1sec          |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.27 (Attention)\n",
      " -- model.layers.27.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96248732\n",
      " -- 2.1987 bpw  accuracy: 0.96394894\n",
      " -- 2.2831 bpw  accuracy: 0.96813077\n",
      " -- 2.6768 bpw  accuracy: 0.97466326\n",
      " -- 3.1689 bpw  accuracy: 0.97973883\n",
      " -- 3.1705 bpw  accuracy: 0.98083004\n",
      " -- 4.0439 bpw  accuracy: 0.98487983\n",
      " -- 4.0471 bpw  accuracy: 0.98626944\n",
      " -- 4.0816 bpw  accuracy: 0.98696382\n",
      " -- 4.1381 bpw  accuracy: 0.98777279\n",
      " -- 4.1705 bpw  accuracy: 0.99021494\n",
      " -- 4.1902 bpw  accuracy: 0.99062994\n",
      " -- 4.2737 bpw  accuracy: 0.99130869\n",
      " -- 4.3295 bpw  accuracy: 0.99177561\n",
      " -- 5.2564 bpw  accuracy: 0.99495050\n",
      " -- 5.3295 bpw  accuracy: 0.99596759\n",
      " -- 6.0439 bpw  accuracy: 0.99588619\n",
      " -- 6.3381 bpw  accuracy: 0.99798233\n",
      " -- 8.0439 bpw  accuracy: 0.99892341\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.27 (Attention)        |\n",
      "| Duration: 5.93 seconds                       |\n",
      "| Completed step: 55/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 1min 52sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.27 (MLP)\n",
      " -- model.layers.27.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.27.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.27.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.27.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.27.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.90567669\n",
      " -- 2.3230 bpw  accuracy: 0.90823371\n",
      " -- 2.5958 bpw  accuracy: 0.92039231\n",
      " -- 2.9120 bpw  accuracy: 0.92421258\n",
      " -- 3.2833 bpw  accuracy: 0.95224163\n",
      " -- 3.3655 bpw  accuracy: 0.95605419\n",
      " -- 3.6186 bpw  accuracy: 0.96119515\n",
      " -- 4.1368 bpw  accuracy: 0.97503234\n",
      " -- 4.1977 bpw  accuracy: 0.97725822\n",
      " -- 4.2662 bpw  accuracy: 0.97570160\n",
      " -- 4.3484 bpw  accuracy: 0.97871635\n",
      " -- 5.2491 bpw  accuracy: 0.98764361\n",
      " -- 5.3313 bpw  accuracy: 0.98940111\n",
      " -- 6.0713 bpw  accuracy: 0.99324068\n",
      " -- 6.3032 bpw  accuracy: 0.99372184\n",
      " -- 6.8687 bpw  accuracy: 0.99473052\n",
      " -- 8.0354 bpw  accuracy: 0.99815256\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.27 (MLP)              |\n",
      "| Duration: 12.76 seconds                      |\n",
      "| Completed step: 56/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 1min 42sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.28 (Attention)\n",
      " -- model.layers.28.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95527238\n",
      " -- 2.1987 bpw  accuracy: 0.95723811\n",
      " -- 2.2831 bpw  accuracy: 0.96217376\n",
      " -- 2.6768 bpw  accuracy: 0.97075739\n",
      " -- 3.1689 bpw  accuracy: 0.97640295\n",
      " -- 3.1705 bpw  accuracy: 0.97727757\n",
      " -- 4.0439 bpw  accuracy: 0.98290769\n",
      " -- 4.0471 bpw  accuracy: 0.98413610\n",
      " -- 4.0816 bpw  accuracy: 0.98507144\n",
      " -- 4.1381 bpw  accuracy: 0.98618419\n",
      " -- 4.1705 bpw  accuracy: 0.98850784\n",
      " -- 4.1902 bpw  accuracy: 0.98896167\n",
      " -- 4.2737 bpw  accuracy: 0.98967908\n",
      " -- 4.3295 bpw  accuracy: 0.99057956\n",
      " -- 5.2564 bpw  accuracy: 0.99385496\n",
      " -- 5.3295 bpw  accuracy: 0.99521063\n",
      " -- 6.0439 bpw  accuracy: 0.99491299\n",
      " -- 6.3381 bpw  accuracy: 0.99738279\n",
      " -- 8.0439 bpw  accuracy: 0.99870136\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.28 (Attention)        |\n",
      "| Duration: 5.96 seconds                       |\n",
      "| Completed step: 57/67                        |\n",
      "| Avg time / step (rolling): 9.35 seconds      |\n",
      "| Estimated remaining time: 1min 33sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.28 (MLP)\n",
      " -- model.layers.28.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.28.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.28.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.28.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.28.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.90148365\n",
      " -- 2.3230 bpw  accuracy: 0.90428024\n",
      " -- 2.5958 bpw  accuracy: 0.91690211\n",
      " -- 2.9120 bpw  accuracy: 0.92094562\n",
      " -- 3.2833 bpw  accuracy: 0.95010371\n",
      " -- 3.3655 bpw  accuracy: 0.95408595\n",
      " -- 3.6186 bpw  accuracy: 0.95948444\n",
      " -- 4.1368 bpw  accuracy: 0.97375611\n",
      " -- 4.1977 bpw  accuracy: 0.97609135\n",
      " -- 4.2662 bpw  accuracy: 0.97460077\n",
      " -- 4.3484 bpw  accuracy: 0.97773838\n",
      " -- 5.2491 bpw  accuracy: 0.98707119\n",
      " -- 5.3313 bpw  accuracy: 0.98890184\n",
      " -- 6.0713 bpw  accuracy: 0.99286679\n",
      " -- 6.3032 bpw  accuracy: 0.99342830\n",
      " -- 6.8687 bpw  accuracy: 0.99450017\n",
      " -- 8.0354 bpw  accuracy: 0.99800002\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.28 (MLP)              |\n",
      "| Duration: 12.73 seconds                      |\n",
      "| Completed step: 58/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 1min 24sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.29 (Attention)\n",
      " -- model.layers.29.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.94058170\n",
      " -- 2.1987 bpw  accuracy: 0.94322645\n",
      " -- 2.2831 bpw  accuracy: 0.95111666\n",
      " -- 2.6768 bpw  accuracy: 0.96178639\n",
      " -- 3.1689 bpw  accuracy: 0.96956644\n",
      " -- 3.1705 bpw  accuracy: 0.97037783\n",
      " -- 4.0439 bpw  accuracy: 0.97894679\n",
      " -- 4.0471 bpw  accuracy: 0.97984847\n",
      " -- 4.0816 bpw  accuracy: 0.98106751\n",
      " -- 4.1381 bpw  accuracy: 0.98263366\n",
      " -- 4.1705 bpw  accuracy: 0.98458632\n",
      " -- 4.1902 bpw  accuracy: 0.98570732\n",
      " -- 4.2737 bpw  accuracy: 0.98660860\n",
      " -- 4.3295 bpw  accuracy: 0.98789834\n",
      " -- 5.2564 bpw  accuracy: 0.99259250\n",
      " -- 5.3295 bpw  accuracy: 0.99386103\n",
      " -- 6.0439 bpw  accuracy: 0.99408782\n",
      " -- 6.3381 bpw  accuracy: 0.99690041\n",
      " -- 8.0439 bpw  accuracy: 0.99841441\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.29 (Attention)        |\n",
      "| Duration: 5.95 seconds                       |\n",
      "| Completed step: 59/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 1min 14sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.29 (MLP)\n",
      " -- model.layers.29.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.29.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.29.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.29.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.29.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.90064086\n",
      " -- 2.3230 bpw  accuracy: 0.90338043\n",
      " -- 2.5958 bpw  accuracy: 0.91641731\n",
      " -- 2.9120 bpw  accuracy: 0.92055122\n",
      " -- 3.2833 bpw  accuracy: 0.94937060\n",
      " -- 3.3655 bpw  accuracy: 0.95340473\n",
      " -- 3.6186 bpw  accuracy: 0.95907041\n",
      " -- 4.1368 bpw  accuracy: 0.97320193\n",
      " -- 4.1977 bpw  accuracy: 0.97555916\n",
      " -- 4.2662 bpw  accuracy: 0.97407850\n",
      " -- 4.3484 bpw  accuracy: 0.97717418\n",
      " -- 5.2491 bpw  accuracy: 0.98673209\n",
      " -- 5.3313 bpw  accuracy: 0.98857973\n",
      " -- 6.0713 bpw  accuracy: 0.99269977\n",
      " -- 6.3032 bpw  accuracy: 0.99323994\n",
      " -- 6.8687 bpw  accuracy: 0.99435314\n",
      " -- 8.0354 bpw  accuracy: 0.99802440\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.29 (MLP)              |\n",
      "| Duration: 12.76 seconds                      |\n",
      "| Completed step: 60/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 1min 5sec          |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.30 (Attention)\n",
      " -- model.layers.30.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.93755213\n",
      " -- 2.1987 bpw  accuracy: 0.94092959\n",
      " -- 2.2831 bpw  accuracy: 0.95027716\n",
      " -- 2.6768 bpw  accuracy: 0.96016888\n",
      " -- 3.1689 bpw  accuracy: 0.96736901\n",
      " -- 3.1705 bpw  accuracy: 0.96861183\n",
      " -- 4.0439 bpw  accuracy: 0.97586156\n",
      " -- 4.0471 bpw  accuracy: 0.97674798\n",
      " -- 4.0816 bpw  accuracy: 0.97996806\n",
      " -- 4.1381 bpw  accuracy: 0.98088710\n",
      " -- 4.1705 bpw  accuracy: 0.98464414\n",
      " -- 4.1902 bpw  accuracy: 0.98584130\n",
      " -- 4.2737 bpw  accuracy: 0.98620750\n",
      " -- 4.3295 bpw  accuracy: 0.98783886\n",
      " -- 5.2564 bpw  accuracy: 0.99239423\n",
      " -- 5.3295 bpw  accuracy: 0.99336925\n",
      " -- 6.0439 bpw  accuracy: 0.99375308\n",
      " -- 6.3381 bpw  accuracy: 0.99669925\n",
      " -- 8.0439 bpw  accuracy: 0.99831548\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.30 (Attention)        |\n",
      "| Duration: 5.97 seconds                       |\n",
      "| Completed step: 61/67                        |\n",
      "| Avg time / step (rolling): 9.35 seconds      |\n",
      "| Estimated remaining time: 0min 56sec         |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.30 (MLP)\n",
      " -- model.layers.30.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.30.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.30.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.30.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.30.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.88688174\n",
      " -- 2.3230 bpw  accuracy: 0.88998595\n",
      " -- 2.5958 bpw  accuracy: 0.90513942\n",
      " -- 2.9120 bpw  accuracy: 0.90970523\n",
      " -- 3.2833 bpw  accuracy: 0.94225753\n",
      " -- 3.3655 bpw  accuracy: 0.94692932\n",
      " -- 3.6186 bpw  accuracy: 0.95331524\n",
      " -- 4.1368 bpw  accuracy: 0.96885961\n",
      " -- 4.1977 bpw  accuracy: 0.97164643\n",
      " -- 4.2662 bpw  accuracy: 0.97018442\n",
      " -- 4.3484 bpw  accuracy: 0.97380514\n",
      " -- 5.2491 bpw  accuracy: 0.98456820\n",
      " -- 5.3313 bpw  accuracy: 0.98685565\n",
      " -- 6.0713 bpw  accuracy: 0.99138321\n",
      " -- 6.3032 bpw  accuracy: 0.99215319\n",
      " -- 6.8687 bpw  accuracy: 0.99354308\n",
      " -- 8.0354 bpw  accuracy: 0.99770129\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.30 (MLP)              |\n",
      "| Duration: 12.76 seconds                      |\n",
      "| Completed step: 62/67                        |\n",
      "| Avg time / step (rolling): 9.35 seconds      |\n",
      "| Estimated remaining time: 0min 46sec         |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.31 (Attention)\n",
      " -- model.layers.31.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.93324865\n",
      " -- 2.1987 bpw  accuracy: 0.93702556\n",
      " -- 2.2831 bpw  accuracy: 0.94736263\n",
      " -- 2.6768 bpw  accuracy: 0.96280648\n",
      " -- 3.1689 bpw  accuracy: 0.96864998\n",
      " -- 3.1705 bpw  accuracy: 0.96903240\n",
      " -- 4.0439 bpw  accuracy: 0.98029867\n",
      " -- 4.0471 bpw  accuracy: 0.98065986\n",
      " -- 4.0816 bpw  accuracy: 0.98225822\n",
      " -- 4.1381 bpw  accuracy: 0.98298924\n",
      " -- 4.1705 bpw  accuracy: 0.98455486\n",
      " -- 4.1902 bpw  accuracy: 0.98559182\n",
      " -- 4.2737 bpw  accuracy: 0.98697985\n",
      " -- 4.3295 bpw  accuracy: 0.98785833\n",
      " -- 5.2564 bpw  accuracy: 0.99269293\n",
      " -- 5.3295 bpw  accuracy: 0.99378132\n",
      " -- 6.0439 bpw  accuracy: 0.99458820\n",
      " -- 6.3381 bpw  accuracy: 0.99663396\n",
      " -- 8.0439 bpw  accuracy: 0.99846847\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.31 (Attention)        |\n",
      "| Duration: 5.94 seconds                       |\n",
      "| Completed step: 63/67                        |\n",
      "| Avg time / step (rolling): 9.35 seconds      |\n",
      "| Estimated remaining time: 0min 37sec         |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.31 (MLP)\n",
      " -- model.layers.31.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.31.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.31.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.31.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.31.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.87402687\n",
      " -- 2.3230 bpw  accuracy: 0.87723587\n",
      " -- 2.5958 bpw  accuracy: 0.89375928\n",
      " -- 2.9120 bpw  accuracy: 0.89847133\n",
      " -- 3.2833 bpw  accuracy: 0.93532912\n",
      " -- 3.3655 bpw  accuracy: 0.94125592\n",
      " -- 3.6186 bpw  accuracy: 0.94810183\n",
      " -- 4.1368 bpw  accuracy: 0.96603019\n",
      " -- 4.1977 bpw  accuracy: 0.96946275\n",
      " -- 4.2662 bpw  accuracy: 0.96670654\n",
      " -- 4.3484 bpw  accuracy: 0.97123879\n",
      " -- 5.2491 bpw  accuracy: 0.98283437\n",
      " -- 5.3313 bpw  accuracy: 0.98554725\n",
      " -- 6.0713 bpw  accuracy: 0.99038905\n",
      " -- 6.3032 bpw  accuracy: 0.99125103\n",
      " -- 6.8687 bpw  accuracy: 0.99275757\n",
      " -- 8.0354 bpw  accuracy: 0.99724326\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.31 (MLP)              |\n",
      "| Duration: 12.71 seconds                      |\n",
      "| Completed step: 64/67                        |\n",
      "| Avg time / step (rolling): 9.35 seconds      |\n",
      "| Estimated remaining time: 0min 28sec         |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.norm (RMSNorm)\n",
      "------------------------------------------------\n",
      "| Measured: model.norm (RMSNorm)               |\n",
      "| Duration: 0.06 seconds                       |\n",
      "| Completed step: 65/67                        |\n",
      "| Avg time / step (rolling): 8.76 seconds      |\n",
      "| Estimated remaining time: 0min 17sec         |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: lm_head (Linear)\n",
      "------------------------------------------------\n",
      "| Measured: lm_head (Linear)                   |\n",
      "| Duration: 1.23 seconds                       |\n",
      "| Completed step: 66/67                        |\n",
      "| Avg time / step (rolling): 7.61 seconds      |\n",
      "| Estimated remaining time: 0min 7sec          |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Optimizing...\n",
      " -- Pruning...\n",
      " -- Solving...\n",
      " -- Score: 0.99994906  bpw: 6.5000\n",
      " -- Score: 0.99994948  bpw: 6.4999\n",
      " -- Score: 0.99995000  bpw: 6.4986\n",
      " -- Score: 0.99995115  bpw: 6.4976\n",
      " -- Score: 0.99995125  bpw: 6.4983\n",
      " -- Score: 0.99995126  bpw: 6.4994\n",
      " -- Score: 0.99995131  bpw: 6.4991\n",
      " -- Score: 0.99995132  bpw: 6.4996\n",
      " -- Score: 0.99995151  bpw: 6.4998\n",
      " -- Quantization strategy:\n",
      " --   model.layers.0.self_attn                           6.3381 bpw - exp. error: 0.00522665\n",
      " --   model.layers.0.mlp                                 6.0713 bpw - exp. error: 0.00501065\n",
      " --   model.layers.1.self_attn                           6.3381 bpw - exp. error: 0.00525602\n",
      " --   model.layers.1.mlp                                 4.1368 bpw - exp. error: 0.00198670\n",
      " --   model.layers.2.self_attn                           4.2737 bpw - exp. error: 0.00145221\n",
      " --   model.layers.2.mlp                                 3.3655 bpw - exp. error: 0.00342685\n",
      " --   model.layers.3.self_attn                           4.3295 bpw - exp. error: 0.00174770\n",
      " --   model.layers.3.mlp                                 4.3484 bpw - exp. error: 0.00250297\n",
      " --   model.layers.4.self_attn                           4.3295 bpw - exp. error: 0.00210052\n",
      " --   model.layers.4.mlp                                 4.3484 bpw - exp. error: 0.00345252\n",
      " --   model.layers.5.self_attn                           5.3295 bpw - exp. error: 0.00121681\n",
      " --   model.layers.5.mlp                                 5.3313 bpw - exp. error: 0.00225797\n",
      " --   model.layers.6.self_attn                           6.3381 bpw - exp. error: 0.00070113\n",
      " --   model.layers.6.mlp                                 5.3313 bpw - exp. error: 0.00272669\n",
      " --   model.layers.7.self_attn                           6.3381 bpw - exp. error: 0.00101135\n",
      " --   model.layers.7.mlp                                 5.3313 bpw - exp. error: 0.00321201\n",
      " --   model.layers.8.self_attn                           6.3381 bpw - exp. error: 0.00107950\n",
      " --   model.layers.8.mlp                                 5.3313 bpw - exp. error: 0.00357357\n",
      " --   model.layers.9.self_attn                           6.3381 bpw - exp. error: 0.00118067\n",
      " --   model.layers.9.mlp                                 6.0713 bpw - exp. error: 0.00255755\n",
      " --   model.layers.10.self_attn                          6.3381 bpw - exp. error: 0.00145646\n",
      " --   model.layers.10.mlp                                6.0713 bpw - exp. error: 0.00273199\n",
      " --   model.layers.11.self_attn                          6.3381 bpw - exp. error: 0.00182167\n",
      " --   model.layers.11.mlp                                6.0713 bpw - exp. error: 0.00292523\n",
      " --   model.layers.12.self_attn                          6.3381 bpw - exp. error: 0.00201130\n",
      " --   model.layers.12.mlp                                6.0713 bpw - exp. error: 0.00327178\n",
      " --   model.layers.13.self_attn                          6.3381 bpw - exp. error: 0.00196446\n",
      " --   model.layers.13.mlp                                6.0713 bpw - exp. error: 0.00359417\n",
      " --   model.layers.14.self_attn                          6.3381 bpw - exp. error: 0.00240590\n",
      " --   model.layers.14.mlp                                6.0713 bpw - exp. error: 0.00387653\n",
      " --   model.layers.15.self_attn                          6.3381 bpw - exp. error: 0.00254089\n",
      " --   model.layers.15.mlp                                6.3032 bpw - exp. error: 0.00387162\n",
      " --   model.layers.16.self_attn                          6.3381 bpw - exp. error: 0.00247396\n",
      " --   model.layers.16.mlp                                6.8687 bpw - exp. error: 0.00346186\n",
      " --   model.layers.17.self_attn                          6.3381 bpw - exp. error: 0.00274516\n",
      " --   model.layers.17.mlp                                6.8687 bpw - exp. error: 0.00386595\n",
      " --   model.layers.18.self_attn                          6.3381 bpw - exp. error: 0.00272014\n",
      " --   model.layers.18.mlp                                6.8687 bpw - exp. error: 0.00412790\n",
      " --   model.layers.19.self_attn                          6.3381 bpw - exp. error: 0.00281377\n",
      " --   model.layers.19.mlp                                8.0354 bpw - exp. error: 0.00164972\n",
      " --   model.layers.20.self_attn                          6.3381 bpw - exp. error: 0.00244745\n",
      " --   model.layers.20.mlp                                8.0354 bpw - exp. error: 0.00160726\n",
      " --   model.layers.21.self_attn                          6.3381 bpw - exp. error: 0.00221107\n",
      " --   model.layers.21.mlp                                8.0354 bpw - exp. error: 0.00160234\n",
      " --   model.layers.22.self_attn                          6.3381 bpw - exp. error: 0.00185400\n",
      " --   model.layers.22.mlp                                8.0354 bpw - exp. error: 0.00163313\n",
      " --   model.layers.23.self_attn                          5.3295 bpw - exp. error: 0.00385746\n",
      " --   model.layers.23.mlp                                8.0354 bpw - exp. error: 0.00165913\n",
      " --   model.layers.24.self_attn                          5.3295 bpw - exp. error: 0.00379472\n",
      " --   model.layers.24.mlp                                8.0354 bpw - exp. error: 0.00170172\n",
      " --   model.layers.25.self_attn                          6.3381 bpw - exp. error: 0.00217660\n",
      " --   model.layers.25.mlp                                8.0354 bpw - exp. error: 0.00172283\n",
      " --   model.layers.26.self_attn                          6.3381 bpw - exp. error: 0.00212400\n",
      " --   model.layers.26.mlp                                8.0354 bpw - exp. error: 0.00180337\n",
      " --   model.layers.27.self_attn                          6.3381 bpw - exp. error: 0.00201767\n",
      " --   model.layers.27.mlp                                8.0354 bpw - exp. error: 0.00184744\n",
      " --   model.layers.28.self_attn                          6.3381 bpw - exp. error: 0.00261721\n",
      " --   model.layers.28.mlp                                8.0354 bpw - exp. error: 0.00199998\n",
      " --   model.layers.29.self_attn                          6.3381 bpw - exp. error: 0.00309959\n",
      " --   model.layers.29.mlp                                8.0354 bpw - exp. error: 0.00197560\n",
      " --   model.layers.30.self_attn                          6.3381 bpw - exp. error: 0.00330075\n",
      " --   model.layers.30.mlp                                8.0354 bpw - exp. error: 0.00229871\n",
      " --   model.layers.31.self_attn                          6.3381 bpw - exp. error: 0.00336604\n",
      " --   model.layers.31.mlp                                8.0354 bpw - exp. error: 0.00275674\n",
      " -- Tokenizing samples...\n",
      " -- First 50 tokens of dataset:\n",
      "    ' = Robert Boulter = \\n  Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed'\n",
      " -- Last 50 tokens of dataset:\n",
      "    '] more meaningful lives \" . The film argues the case against conformity , but does not deny that people need and want it ; even the gay characters just want to fit in . Jim and Jim , the Burnhams \\' other neighbors , are'\n",
      " -- Token embeddings again...\n",
      " -- Quantizing...\n",
      " -- Layer: model.layers.0 (Attention)\n",
      " -- Linear: model.layers.0.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.0.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.0.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.0.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.016333\n",
      " -- Layer: model.layers.0 (MLP)\n",
      " -- Linear: model.layers.0.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.0.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.0.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.009244\n",
      " -- Layer: model.layers.1 (Attention)\n",
      " -- Linear: model.layers.1.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.1.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.1.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.1.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.014327\n",
      " -- Layer: model.layers.1 (MLP)\n",
      " -- Linear: model.layers.1.mlp.gate_proj -> 1:4b_128g s4, 4.03 bpw\n",
      " -- Linear: model.layers.1.mlp.up_proj -> 1:4b_32g s4, 4.13 bpw\n",
      " -- Linear: model.layers.1.mlp.down_proj -> 0.05:8b_32g/0.95:4b_128g s4, 4.25 bpw\n",
      " -- Module quantized, rfn_error: 0.002398\n",
      " -- Layer: model.layers.2 (Attention)\n",
      " -- Linear: model.layers.2.self_attn.q_proj -> 0.1:5b_64g/0.9:4b_64g s4, 4.18 bpw\n",
      " -- Linear: model.layers.2.self_attn.k_proj -> 0.1:5b_64g/0.9:4b_64g s4, 4.20 bpw\n",
      " -- Linear: model.layers.2.self_attn.v_proj -> 1:5b_64g s4, 5.09 bpw\n",
      " -- Linear: model.layers.2.self_attn.o_proj -> 0.1:5b_64g/0.9:4b_64g s4, 4.18 bpw\n",
      " -- Module quantized, rfn_error: 0.001572\n",
      " -- Layer: model.layers.2 (MLP)\n",
      " -- Linear: model.layers.2.mlp.gate_proj -> 0.1:4b_32g/0.9:3b_32g s4, 3.23 bpw\n",
      " -- Linear: model.layers.2.mlp.up_proj -> 0.25:4b_32g/0.75:3b_32g s4, 3.38 bpw\n",
      " -- Linear: model.layers.2.mlp.down_proj -> 0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4, 3.49 bpw\n",
      " -- Module quantized, rfn_error: 0.004103\n",
      " -- Layer: model.layers.3 (Attention)\n",
      " -- Linear: model.layers.3.self_attn.q_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.3.self_attn.k_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.3.self_attn.v_proj -> 1:5b_32g s4, 5.16 bpw\n",
      " -- Linear: model.layers.3.self_attn.o_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Module quantized, rfn_error: 0.001937\n",
      " -- Layer: model.layers.3 (MLP)\n",
      " -- Linear: model.layers.3.mlp.gate_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.3.mlp.up_proj -> 0.25:5b_32g/0.75:4b_32g s4, 4.38 bpw\n",
      " -- Linear: model.layers.3.mlp.down_proj -> 0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4, 4.44 bpw\n",
      " -- Module quantized, rfn_error: 0.002981\n",
      " -- Layer: model.layers.4 (Attention)\n",
      " -- Linear: model.layers.4.self_attn.q_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.4.self_attn.k_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.4.self_attn.v_proj -> 1:5b_32g s4, 5.16 bpw\n",
      " -- Linear: model.layers.4.self_attn.o_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Module quantized, rfn_error: 0.002201\n",
      " -- Layer: model.layers.4 (MLP)\n",
      " -- Linear: model.layers.4.mlp.gate_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.4.mlp.up_proj -> 0.25:5b_32g/0.75:4b_32g s4, 4.38 bpw\n",
      " -- Linear: model.layers.4.mlp.down_proj -> 0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4, 4.44 bpw\n",
      " -- Module quantized, rfn_error: 0.004033\n",
      " -- Layer: model.layers.5 (Attention)\n",
      " -- Linear: model.layers.5.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.5.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.5.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.5.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.001398\n",
      " -- Layer: model.layers.5 (MLP)\n",
      " -- Linear: model.layers.5.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.5.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.5.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.002675\n",
      " -- Layer: model.layers.6 (Attention)\n",
      " -- Linear: model.layers.6.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.6.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.6.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.6.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.001933\n",
      " -- Layer: model.layers.6 (MLP)\n",
      " -- Linear: model.layers.6.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.6.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.6.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.003236\n",
      " -- Layer: model.layers.7 (Attention)\n",
      " -- Linear: model.layers.7.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.7.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.7.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.7.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.002365\n",
      " -- Layer: model.layers.7 (MLP)\n",
      " -- Linear: model.layers.7.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.7.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.7.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.003826\n",
      " -- Layer: model.layers.8 (Attention)\n",
      " -- Linear: model.layers.8.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.8.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.8.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.8.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.002044\n",
      " -- Layer: model.layers.8 (MLP)\n",
      " -- Linear: model.layers.8.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.8.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.8.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.004262\n",
      " -- Layer: model.layers.9 (Attention)\n",
      " -- Linear: model.layers.9.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.9.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.9.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.9.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003233\n",
      " -- Layer: model.layers.9 (MLP)\n",
      " -- Linear: model.layers.9.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.9.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.9.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.003166\n",
      " -- Layer: model.layers.10 (Attention)\n",
      " -- Linear: model.layers.10.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.10.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.10.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.10.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.002746\n",
      " -- Layer: model.layers.10 (MLP)\n",
      " -- Linear: model.layers.10.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.10.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.10.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.003359\n",
      " -- Layer: model.layers.11 (Attention)\n",
      " -- Linear: model.layers.11.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.11.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.11.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.11.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003014\n",
      " -- Layer: model.layers.11 (MLP)\n",
      " -- Linear: model.layers.11.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.11.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.11.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.003560\n",
      " -- Layer: model.layers.12 (Attention)\n",
      " -- Linear: model.layers.12.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.12.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.12.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.12.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004164\n",
      " -- Layer: model.layers.12 (MLP)\n",
      " -- Linear: model.layers.12.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.12.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.12.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.003973\n",
      " -- Layer: model.layers.13 (Attention)\n",
      " -- Linear: model.layers.13.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.13.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.13.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.13.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003975\n",
      " -- Layer: model.layers.13 (MLP)\n",
      " -- Linear: model.layers.13.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.13.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.13.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.004367\n",
      " -- Layer: model.layers.14 (Attention)\n",
      " -- Linear: model.layers.14.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.14.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.14.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.14.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004020\n",
      " -- Layer: model.layers.14 (MLP)\n",
      " -- Linear: model.layers.14.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.14.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.14.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.004701\n",
      " -- Layer: model.layers.15 (Attention)\n",
      " -- Linear: model.layers.15.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.15.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.15.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.15.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004393\n",
      " -- Layer: model.layers.15 (MLP)\n",
      " -- Linear: model.layers.15.mlp.gate_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.15.mlp.up_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.15.mlp.down_proj -> 0.15:8b_128g/0.85:6b_128g s4, 6.34 bpw\n",
      " -- Module quantized, rfn_error: 0.004931\n",
      " -- Layer: model.layers.16 (Attention)\n",
      " -- Linear: model.layers.16.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.16.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.16.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.16.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004624\n",
      " -- Layer: model.layers.16 (MLP)\n",
      " -- Linear: model.layers.16.mlp.gate_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.16.mlp.up_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.16.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.005423\n",
      " -- Layer: model.layers.17 (Attention)\n",
      " -- Linear: model.layers.17.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.17.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.17.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.17.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004639\n",
      " -- Layer: model.layers.17 (MLP)\n",
      " -- Linear: model.layers.17.mlp.gate_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.17.mlp.up_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.17.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.005912\n",
      " -- Layer: model.layers.18 (Attention)\n",
      " -- Linear: model.layers.18.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.18.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.18.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.18.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004914\n",
      " -- Layer: model.layers.18 (MLP)\n",
      " -- Linear: model.layers.18.mlp.gate_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.18.mlp.up_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.18.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.006280\n",
      " -- Layer: model.layers.19 (Attention)\n",
      " -- Linear: model.layers.19.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.19.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.19.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.19.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004983\n",
      " -- Layer: model.layers.19 (MLP)\n",
      " -- Linear: model.layers.19.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.19.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.19.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.006813\n",
      " -- Layer: model.layers.20 (Attention)\n",
      " -- Linear: model.layers.20.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.20.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.20.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.20.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004720\n",
      " -- Layer: model.layers.20 (MLP)\n",
      " -- Linear: model.layers.20.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.20.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.20.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.007469\n",
      " -- Layer: model.layers.21 (Attention)\n",
      " -- Linear: model.layers.21.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.21.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.21.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.21.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003796\n",
      " -- Layer: model.layers.21 (MLP)\n",
      " -- Linear: model.layers.21.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.21.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.21.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.008275\n",
      " -- Layer: model.layers.22 (Attention)\n",
      " -- Linear: model.layers.22.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.22.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.22.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.22.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003181\n",
      " -- Layer: model.layers.22 (MLP)\n",
      " -- Linear: model.layers.22.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.22.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.22.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.008565\n",
      " -- Layer: model.layers.23 (Attention)\n",
      " -- Linear: model.layers.23.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.23.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.23.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.23.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004492\n",
      " -- Layer: model.layers.23 (MLP)\n",
      " -- Linear: model.layers.23.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.23.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.23.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.008611\n",
      " -- Layer: model.layers.24 (Attention)\n",
      " -- Linear: model.layers.24.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.24.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.24.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.24.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004439\n",
      " -- Layer: model.layers.24 (MLP)\n",
      " -- Linear: model.layers.24.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.24.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.24.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.009322\n",
      " -- Layer: model.layers.25 (Attention)\n",
      " -- Linear: model.layers.25.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.25.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.25.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.25.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003703\n",
      " -- Layer: model.layers.25 (MLP)\n",
      " -- Linear: model.layers.25.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.25.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.25.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.008794\n",
      " -- Layer: model.layers.26 (Attention)\n",
      " -- Linear: model.layers.26.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.26.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.26.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.26.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003669\n",
      " -- Layer: model.layers.26 (MLP)\n",
      " -- Linear: model.layers.26.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.26.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.26.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.009173\n",
      " -- Layer: model.layers.27 (Attention)\n",
      " -- Linear: model.layers.27.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.27.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.27.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.27.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003546\n",
      " -- Layer: model.layers.27 (MLP)\n",
      " -- Linear: model.layers.27.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.27.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.27.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.008348\n",
      " -- Layer: model.layers.28 (Attention)\n",
      " -- Linear: model.layers.28.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.28.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.28.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.28.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003859\n",
      " -- Layer: model.layers.28 (MLP)\n",
      " -- Linear: model.layers.28.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.28.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.28.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.008538\n",
      " -- Layer: model.layers.29 (Attention)\n",
      " -- Linear: model.layers.29.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.29.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.29.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.29.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004651\n",
      " -- Layer: model.layers.29 (MLP)\n",
      " -- Linear: model.layers.29.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.29.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.29.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.007363\n",
      " -- Layer: model.layers.30 (Attention)\n",
      " -- Linear: model.layers.30.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.30.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.30.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.30.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004636\n",
      " -- Layer: model.layers.30 (MLP)\n",
      " -- Linear: model.layers.30.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.30.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.30.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.004910\n",
      " -- Layer: model.layers.31 (Attention)\n",
      " -- Linear: model.layers.31.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.31.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.31.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.31.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.005565\n",
      " -- Layer: model.layers.31 (MLP)\n",
      " -- Linear: model.layers.31.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.31.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.31.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.008758\n",
      " -- Layer: model.norm (RMSNorm)\n",
      " -- Module quantized, rfn_error: 0.000000\n",
      " -- Layer: lm_head (Linear)\n",
      " -- Linear: lm_head -> 0.15:8b_128g/0.85:6b_128g s4, 6.34 bpw\n",
      " -- Module quantized, calibration perplexity (quant): 6.3973\n",
      " -- Compiling output file...\n",
      " -- Writing shard 1...\n",
      " --   pastiche-crown-clown-7b-dare-6.5bpw-exl2/output.safetensors (5,757 MB)\n",
      " -- Finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download dataset\n",
    "!wget https://huggingface.co/datasets/wikitext/resolve/9a9e482b5987f9d25b3a9b2883fc6cc9fd8071b3/wikitext-103-v1/wikitext-test.parquet\n",
    "\n",
    "model_name = str(model_id.value).split('/')\n",
    "new_model_name = str(new_model_id.value).split('/')\n",
    "command = f\"mkdir {new_model_name[1]}-{bpw.value}bpw-exl2\"\n",
    "os.system(command)\n",
    "\n",
    "quant = f\"{new_model_name[1]}-{bpw.value}bpw-exl2\"\n",
    "command = f\"python exllamav2/convert.py -i {model_name[1]} -o {quant} -c wikitext-test.parquet -b {bpw.value}\"\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending incremental file list\n",
      "./\n",
      "README.md\n",
      "config.json\n",
      "mergekit_config.yml\n",
      "model.safetensors.index.json\n",
      "special_tokens_map.json\n",
      "tokenizer.json\n",
      "tokenizer.model\n",
      "tokenizer_config.json\n",
      "\n",
      "sent 2,317,021 bytes  received 171 bytes  4,634,384.00 bytes/sec\n",
      "total size is 2,315,825  speedup is 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup and copy files\n",
    "command = f\"rm -rf {quant}/out_tensor\"\n",
    "os.system(command)\n",
    "\n",
    "command = f\"rsync -av --exclude='*.safetensors' --exclude='.*' ./{model_name[1]}/ ./{quant}/\"\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create HF model card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import ModelCard\n",
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ca2d480d724f49aadf5763c8a2bb0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='apache-2.0', description='License', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "license = widgets.Text(\n",
    "    value=\"apache-2.0\",\n",
    "    description='License',\n",
    "    disabled=False\n",
    ")\n",
    "license.style.description_width = 'initial'\n",
    "display(license)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the jinja template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_text = \"\"\"\n",
    "---\n",
    "license: {{ license }}\n",
    "---\n",
    "\n",
    "# {{ new_model_id }}\n",
    "\n",
    "An EXL2 {{ bpw }}bpw quantised version of [{{ model_id }}]({{ model_url }}).\n",
    "\n",
    "An incomplete list of clients and libraries that are known to support EXL2:\n",
    "* [text-generation-webui](https://github.com/oobabooga/text-generation-webui), the most widely used web UI, with many features and powerful extensions. Supports GPU acceleration.\n",
    "* [exllamav2](https://github.com/turboderp/exllamav2), an inference library for running local LLMs on modern consumer GPUs.\n",
    "\"\"\"\n",
    "\n",
    "    # Create a Jinja template object\n",
    "jinja_template = Template(template_text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the template\n",
    "content = jinja_template.render(\n",
    "          license = license.value,\n",
    "          new_model_id = new_model_id.value,\n",
    "          bpw = bpw.value,\n",
    "          model_id = model_id.value,\n",
    "          model_url = \"https://huggingface.co/\" + model_id.value,\n",
    "          )\n",
    "\n",
    "# Save the model card\n",
    "card = ModelCard(content)\n",
    "card.save(f\"{quant}/README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cca32c66a7848e485f70d0c6241832e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4926c59e86484a36b56ac21e9b1831eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cal_data.safetensors:   0%|          | 0.00/1.64M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4220155ed6714f918fc8aeb403163bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "output.safetensors:   0%|          | 0.00/6.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2426e0b0ba41cdb8fe7d1d83ecb7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hidden_states.safetensors:   0%|          | 0.00/1.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a02692efeb423c9e0d3c102629d315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/CorticalStack/pastiche-crown-clown-7b-dare-6.5bpw-exl2/commit/d5426c66b91a197547ef6eae662f34fd2c7e04e5', commit_message='Upload folder using huggingface_hub', commit_description='', oid='d5426c66b91a197547ef6eae662f34fd2c7e04e5', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty repo\n",
    "api = HfApi()\n",
    "create_repo(\n",
    "    repo_id = f\"CorticalStack/{quant}\",\n",
    "    repo_type=\"model\",\n",
    "    exist_ok=True,\n",
    "    token=HF_TOKEN\n",
    ")\n",
    "\n",
    "# Upload exl2 files\n",
    "api.upload_folder(\n",
    "    folder_path=quant,\n",
    "    repo_id=f\"CorticalStack/{quant}\",\n",
    "    token=HF_TOKEN\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaiplayground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
