{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from huggingface_hub import HfApi, create_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables like HuggingFace token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # take environment variables from .env.\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify HuggingFace Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692a54d626474fb8b73c0fcf00f3934f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='CorticalStack/mistral-7b-alpaca-sft', description='Model ID', style=TextStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe96534c638c457281c5416eae21ebf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='CorticalStack/mistral-7b-alpaca', description='New model ID', style=TextStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = widgets.Text(\n",
    "    value='CorticalStack/mistral-7b-alpaca-sft',\n",
    "    description='Model ID',\n",
    "    disabled=False\n",
    ")\n",
    "model_id.style.description_width = 'initial'\n",
    "display(model_id)\n",
    "\n",
    "new_model_id = widgets.Text(\n",
    "    value='CorticalStack/mistral-7b-alpaca',\n",
    "    description='New model ID',\n",
    "    disabled=False\n",
    ")\n",
    "new_model_id.style.description_width = 'initial'\n",
    "display(new_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXL2 quant parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0c98bfdfb74ab6bc0f55d31445c204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=6.5, description='BPW', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bpw = widgets.FloatText(\n",
    "    value=6.5,\n",
    "    description='BPW',\n",
    "    disabled=False\n",
    ")\n",
    "bpw.style.description_width = 'initial'\n",
    "display(bpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the source model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = str(model_id.value).split('/')\n",
    "if not os.path.isdir(model_name[1]):\n",
    "    !git clone https://huggingface.co/{model_id.value}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the EXL2 quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-15 23:04:34--  https://huggingface.co/datasets/wikitext/resolve/9a9e482b5987f9d25b3a9b2883fc6cc9fd8071b3/wikitext-103-v1/wikitext-test.parquet\n",
      "Resolving huggingface.co (huggingface.co)... 18.165.183.98, 18.165.183.94, 18.165.183.117, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.165.183.98|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 721735 (705K)\n",
      "Saving to: ‘wikitext-test.parquet.33’\n",
      "\n",
      "wikitext-test.parqu 100%[===================>] 704.82K  1.92MB/s    in 0.4s    \n",
      "\n",
      "2024-02-15 23:04:35 (1.92 MB/s) - ‘wikitext-test.parquet.33’ saved [721735/721735]\n",
      "\n",
      " -- Beginning new job\n",
      " -- Input: mistral-7b-alpaca-sft\n",
      " -- Output: mistral-7b-alpaca-6.5bpw-exl2\n",
      " -- Calibration dataset: wikitext-test.parquet, 100 / 16 rows, 2048 tokens per sample\n",
      " -- Target bits per weight: 6.5 (decoder), 6 (head)\n",
      " -- Max shard size: 8192 MB\n",
      " -- Tokenizing samples (measurement)...\n",
      " -- First 50 tokens of dataset:\n",
      "    ' = Robert Boulter = \\n  Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed'\n",
      " -- Last 50 tokens of dataset:\n",
      "    'Changnyong @-@ Yongsan road and cut the division in two ; the 38th and 23d Infantry Regiments with the bulk of the division artillery in the north were separated from the division headquarters and the'\n",
      " -- Token embeddings (measurement)...\n",
      " -- Measuring quantization impact...\n",
      " -- Layer: model.layers.0 (Attention)\n",
      " -- model.layers.0.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.90583692\n",
      " -- 2.1987 bpw  accuracy: 0.92227239\n",
      " -- 2.2831 bpw  accuracy: 0.92623465\n",
      " -- 2.6768 bpw  accuracy: 0.95695872\n",
      " -- 3.1689 bpw  accuracy: 0.95749895\n",
      " -- 3.1705 bpw  accuracy: 0.95802840\n",
      " -- 4.0439 bpw  accuracy: 0.96933744\n",
      " -- 4.0471 bpw  accuracy: 0.97067939\n",
      " -- 4.0816 bpw  accuracy: 0.97382540\n",
      " -- 4.1381 bpw  accuracy: 0.97557745\n",
      " -- 4.1705 bpw  accuracy: 0.97887380\n",
      " -- 4.1902 bpw  accuracy: 0.98027875\n",
      " -- 4.2737 bpw  accuracy: 0.98106073\n",
      " -- 4.3295 bpw  accuracy: 0.98297016\n",
      " -- 5.2564 bpw  accuracy: 0.98962236\n",
      " -- 5.3295 bpw  accuracy: 0.99149211\n",
      " -- 6.0439 bpw  accuracy: 0.99197731\n",
      " -- 6.3381 bpw  accuracy: 0.99474028\n",
      " -- 8.0439 bpw  accuracy: 0.99783646\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.0 (Attention)    |\n",
      "| Duration: 6.77 seconds                  |\n",
      "| Completed step: 1/67                    |\n",
      "| Avg time / step (rolling): 6.77 seconds |\n",
      "| Estimated remaining time: 7min 27sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.0 (MLP)\n",
      " -- model.layers.0.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.0.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.0.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.0.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.0.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91122035\n",
      " -- 2.3230 bpw  accuracy: 0.91361575\n",
      " -- 2.5958 bpw  accuracy: 0.92638814\n",
      " -- 2.9120 bpw  accuracy: 0.93043535\n",
      " -- 3.2833 bpw  accuracy: 0.96400670\n",
      " -- 3.3655 bpw  accuracy: 0.96763808\n",
      " -- 3.6186 bpw  accuracy: 0.97433624\n",
      " -- 4.1368 bpw  accuracy: 0.98156064\n",
      " -- 4.1977 bpw  accuracy: 0.98350615\n",
      " -- 4.2662 bpw  accuracy: 0.98261084\n",
      " -- 4.3484 bpw  accuracy: 0.98456084\n",
      " -- 5.2491 bpw  accuracy: 0.99120286\n",
      " -- 5.3313 bpw  accuracy: 0.99253642\n",
      " -- 6.0713 bpw  accuracy: 0.99508424\n",
      " -- 6.3032 bpw  accuracy: 0.99550577\n",
      " -- 6.8687 bpw  accuracy: 0.99699629\n",
      " -- 8.0354 bpw  accuracy: 0.99855541\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.0 (MLP)          |\n",
      "| Duration: 12.47 seconds                 |\n",
      "| Completed step: 2/67                    |\n",
      "| Avg time / step (rolling): 9.62 seconds |\n",
      "| Estimated remaining time: 10min 25sec   |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.1 (Attention)\n",
      " -- model.layers.1.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.88659681\n",
      " -- 2.1987 bpw  accuracy: 0.89427325\n",
      " -- 2.2831 bpw  accuracy: 0.91187874\n",
      " -- 2.6768 bpw  accuracy: 0.93273289\n",
      " -- 3.1689 bpw  accuracy: 0.93580503\n",
      " -- 3.1705 bpw  accuracy: 0.94441694\n",
      " -- 4.0439 bpw  accuracy: 0.94386851\n",
      " -- 4.0471 bpw  accuracy: 0.95317819\n",
      " -- 4.0816 bpw  accuracy: 0.96318311\n",
      " -- 4.1381 bpw  accuracy: 0.96398949\n",
      " -- 4.1705 bpw  accuracy: 0.97181462\n",
      " -- 4.1902 bpw  accuracy: 0.97720257\n",
      " -- 4.2737 bpw  accuracy: 0.97329886\n",
      " -- 4.3295 bpw  accuracy: 0.97884647\n",
      " -- 5.2564 bpw  accuracy: 0.98386593\n",
      " -- 5.3295 bpw  accuracy: 0.98945804\n",
      " -- 6.0439 bpw  accuracy: 0.98537764\n",
      " -- 6.3381 bpw  accuracy: 0.99512779\n",
      " -- 8.0439 bpw  accuracy: 0.99611191\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.1 (Attention)    |\n",
      "| Duration: 5.90 seconds                  |\n",
      "| Completed step: 3/67                    |\n",
      "| Avg time / step (rolling): 8.38 seconds |\n",
      "| Estimated remaining time: 8min 56sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.1 (MLP)\n",
      " -- model.layers.1.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.1.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.1.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.1.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.1.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.95891740\n",
      " -- 2.3230 bpw  accuracy: 0.96478629\n",
      " -- 2.5958 bpw  accuracy: 0.96322239\n",
      " -- 2.9120 bpw  accuracy: 0.96328331\n",
      " -- 3.2833 bpw  accuracy: 0.99276099\n",
      " -- 3.3655 bpw  accuracy: 0.99486997\n",
      " -- 3.6186 bpw  accuracy: 0.99528785\n",
      " -- 4.1368 bpw  accuracy: 0.99768367\n",
      " -- 4.1977 bpw  accuracy: 0.99786576\n",
      " -- 4.2662 bpw  accuracy: 0.99785268\n",
      " -- 4.3484 bpw  accuracy: 0.99821387\n",
      " -- 5.2491 bpw  accuracy: 0.99873139\n",
      " -- 5.3313 bpw  accuracy: 0.99884421\n",
      " -- 6.0713 bpw  accuracy: 0.99918224\n",
      " -- 6.3032 bpw  accuracy: 0.99901353\n",
      " -- 6.8687 bpw  accuracy: 0.99908371\n",
      " -- 8.0354 bpw  accuracy: 0.99948774\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.1 (MLP)          |\n",
      "| Duration: 12.53 seconds                 |\n",
      "| Completed step: 4/67                    |\n",
      "| Avg time / step (rolling): 9.42 seconds |\n",
      "| Estimated remaining time: 9min 53sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.2 (Attention)\n",
      " -- model.layers.2.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.99338467\n",
      " -- 2.1987 bpw  accuracy: 0.99419162\n",
      " -- 2.2831 bpw  accuracy: 0.99461697\n",
      " -- 2.6768 bpw  accuracy: 0.99548495\n",
      " -- 3.1689 bpw  accuracy: 0.99623160\n",
      " -- 3.1705 bpw  accuracy: 0.99622760\n",
      " -- 4.0439 bpw  accuracy: 0.99745222\n",
      " -- 4.0471 bpw  accuracy: 0.99749536\n",
      " -- 4.0816 bpw  accuracy: 0.99789112\n",
      " -- 4.1381 bpw  accuracy: 0.99793195\n",
      " -- 4.1705 bpw  accuracy: 0.99780476\n",
      " -- 4.1902 bpw  accuracy: 0.99806800\n",
      " -- 4.2737 bpw  accuracy: 0.99855119\n",
      " -- 4.3295 bpw  accuracy: 0.99863893\n",
      " -- 5.2564 bpw  accuracy: 0.99924023\n",
      " -- 5.3295 bpw  accuracy: 0.99936674\n",
      " -- 6.0439 bpw  accuracy: 0.99936124\n",
      " -- 6.3381 bpw  accuracy: 0.99972225\n",
      " -- 8.0439 bpw  accuracy: 0.99982499\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.2 (Attention)    |\n",
      "| Duration: 5.66 seconds                  |\n",
      "| Completed step: 5/67                    |\n",
      "| Avg time / step (rolling): 8.67 seconds |\n",
      "| Estimated remaining time: 8min 57sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.2 (MLP)\n",
      " -- model.layers.2.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.2.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.2.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.2.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.2.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.99192534\n",
      " -- 2.3230 bpw  accuracy: 0.99213007\n",
      " -- 2.5958 bpw  accuracy: 0.99337454\n",
      " -- 2.9120 bpw  accuracy: 0.99377172\n",
      " -- 3.2833 bpw  accuracy: 0.99599698\n",
      " -- 3.3655 bpw  accuracy: 0.99632134\n",
      " -- 3.6186 bpw  accuracy: 0.99684839\n",
      " -- 4.1368 bpw  accuracy: 0.99793894\n",
      " -- 4.1977 bpw  accuracy: 0.99813761\n",
      " -- 4.2662 bpw  accuracy: 0.99797914\n",
      " -- 4.3484 bpw  accuracy: 0.99823825\n",
      " -- 5.2491 bpw  accuracy: 0.99899820\n",
      " -- 5.3313 bpw  accuracy: 0.99913868\n",
      " -- 6.0713 bpw  accuracy: 0.99945124\n",
      " -- 6.3032 bpw  accuracy: 0.99948170\n",
      " -- 6.8687 bpw  accuracy: 0.99958667\n",
      " -- 8.0354 bpw  accuracy: 0.99985203\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.2 (MLP)          |\n",
      "| Duration: 12.53 seconds                 |\n",
      "| Completed step: 6/67                    |\n",
      "| Avg time / step (rolling): 9.31 seconds |\n",
      "| Estimated remaining time: 9min 27sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.3 (Attention)\n",
      " -- model.layers.3.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.99170955\n",
      " -- 2.1987 bpw  accuracy: 0.99196989\n",
      " -- 2.2831 bpw  accuracy: 0.99344043\n",
      " -- 2.6768 bpw  accuracy: 0.99482262\n",
      " -- 3.1689 bpw  accuracy: 0.99523527\n",
      " -- 3.1705 bpw  accuracy: 0.99570594\n",
      " -- 4.0439 bpw  accuracy: 0.99592022\n",
      " -- 4.0471 bpw  accuracy: 0.99648994\n",
      " -- 4.0816 bpw  accuracy: 0.99685958\n",
      " -- 4.1381 bpw  accuracy: 0.99692597\n",
      " -- 4.1705 bpw  accuracy: 0.99775685\n",
      " -- 4.1902 bpw  accuracy: 0.99801914\n",
      " -- 4.2737 bpw  accuracy: 0.99792973\n",
      " -- 4.3295 bpw  accuracy: 0.99819711\n",
      " -- 5.2564 bpw  accuracy: 0.99883093\n",
      " -- 5.3295 bpw  accuracy: 0.99911585\n",
      " -- 6.0439 bpw  accuracy: 0.99895286\n",
      " -- 6.3381 bpw  accuracy: 0.99963050\n",
      " -- 8.0439 bpw  accuracy: 0.99974526\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.3 (Attention)    |\n",
      "| Duration: 5.65 seconds                  |\n",
      "| Completed step: 7/67                    |\n",
      "| Avg time / step (rolling): 8.79 seconds |\n",
      "| Estimated remaining time: 8min 47sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.3 (MLP)\n",
      " -- model.layers.3.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.3.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.3.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.3.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.3.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.98809496\n",
      " -- 2.3230 bpw  accuracy: 0.98838252\n",
      " -- 2.5958 bpw  accuracy: 0.99017133\n",
      " -- 2.9120 bpw  accuracy: 0.99074381\n",
      " -- 3.2833 bpw  accuracy: 0.99400621\n",
      " -- 3.3655 bpw  accuracy: 0.99449991\n",
      " -- 3.6186 bpw  accuracy: 0.99525689\n",
      " -- 4.1368 bpw  accuracy: 0.99691851\n",
      " -- 4.1977 bpw  accuracy: 0.99721268\n",
      " -- 4.2662 bpw  accuracy: 0.99696755\n",
      " -- 4.3484 bpw  accuracy: 0.99736083\n",
      " -- 5.2491 bpw  accuracy: 0.99849874\n",
      " -- 5.3313 bpw  accuracy: 0.99870998\n",
      " -- 6.0713 bpw  accuracy: 0.99917761\n",
      " -- 6.3032 bpw  accuracy: 0.99922292\n",
      " -- 6.8687 bpw  accuracy: 0.99937169\n",
      " -- 8.0354 bpw  accuracy: 0.99977956\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.3 (MLP)          |\n",
      "| Duration: 12.56 seconds                 |\n",
      "| Completed step: 8/67                    |\n",
      "| Avg time / step (rolling): 9.26 seconds |\n",
      "| Estimated remaining time: 9min 6sec     |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.4 (Attention)\n",
      " -- model.layers.4.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.98959244\n",
      " -- 2.1987 bpw  accuracy: 0.99004597\n",
      " -- 2.2831 bpw  accuracy: 0.99189719\n",
      " -- 2.6768 bpw  accuracy: 0.99345186\n",
      " -- 3.1689 bpw  accuracy: 0.99434947\n",
      " -- 3.1705 bpw  accuracy: 0.99490872\n",
      " -- 4.0439 bpw  accuracy: 0.99535283\n",
      " -- 4.0471 bpw  accuracy: 0.99594052\n",
      " -- 4.0816 bpw  accuracy: 0.99642095\n",
      " -- 4.1381 bpw  accuracy: 0.99662864\n",
      " -- 4.1705 bpw  accuracy: 0.99752881\n",
      " -- 4.1902 bpw  accuracy: 0.99766220\n",
      " -- 4.2737 bpw  accuracy: 0.99772160\n",
      " -- 4.3295 bpw  accuracy: 0.99796887\n",
      " -- 5.2564 bpw  accuracy: 0.99866931\n",
      " -- 5.3295 bpw  accuracy: 0.99898613\n",
      " -- 6.0439 bpw  accuracy: 0.99883609\n",
      " -- 6.3381 bpw  accuracy: 0.99955416\n",
      " -- 8.0439 bpw  accuracy: 0.99971339\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.4 (Attention)    |\n",
      "| Duration: 5.89 seconds                  |\n",
      "| Completed step: 9/67                    |\n",
      "| Avg time / step (rolling): 8.88 seconds |\n",
      "| Estimated remaining time: 8min 35sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.4 (MLP)\n",
      " -- model.layers.4.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.4.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.4.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.4.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.4.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.98352070\n",
      " -- 2.3230 bpw  accuracy: 0.98396718\n",
      " -- 2.5958 bpw  accuracy: 0.98659586\n",
      " -- 2.9120 bpw  accuracy: 0.98740843\n",
      " -- 3.2833 bpw  accuracy: 0.99170358\n",
      " -- 3.3655 bpw  accuracy: 0.99241086\n",
      " -- 3.6186 bpw  accuracy: 0.99349237\n",
      " -- 4.1368 bpw  accuracy: 0.99572247\n",
      " -- 4.1977 bpw  accuracy: 0.99613170\n",
      " -- 4.2662 bpw  accuracy: 0.99579707\n",
      " -- 4.3484 bpw  accuracy: 0.99635538\n",
      " -- 5.2491 bpw  accuracy: 0.99791965\n",
      " -- 5.3313 bpw  accuracy: 0.99821794\n",
      " -- 6.0713 bpw  accuracy: 0.99885142\n",
      " -- 6.3032 bpw  accuracy: 0.99892050\n",
      " -- 6.8687 bpw  accuracy: 0.99913921\n",
      " -- 8.0354 bpw  accuracy: 0.99969115\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.4 (MLP)          |\n",
      "| Duration: 12.63 seconds                 |\n",
      "| Completed step: 10/67                   |\n",
      "| Avg time / step (rolling): 9.26 seconds |\n",
      "| Estimated remaining time: 8min 47sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.5 (Attention)\n",
      " -- model.layers.5.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.98652072\n",
      " -- 2.1987 bpw  accuracy: 0.98680702\n",
      " -- 2.2831 bpw  accuracy: 0.98871186\n",
      " -- 2.6768 bpw  accuracy: 0.99126275\n",
      " -- 3.1689 bpw  accuracy: 0.99307371\n",
      " -- 3.1705 bpw  accuracy: 0.99336754\n",
      " -- 4.0439 bpw  accuracy: 0.99509570\n",
      " -- 4.0471 bpw  accuracy: 0.99521581\n",
      " -- 4.0816 bpw  accuracy: 0.99593136\n",
      " -- 4.1381 bpw  accuracy: 0.99607674\n",
      " -- 4.1705 bpw  accuracy: 0.99670428\n",
      " -- 4.1902 bpw  accuracy: 0.99698675\n",
      " -- 4.2737 bpw  accuracy: 0.99713113\n",
      " -- 4.3295 bpw  accuracy: 0.99738471\n",
      " -- 5.2564 bpw  accuracy: 0.99838921\n",
      " -- 5.3295 bpw  accuracy: 0.99869491\n",
      " -- 6.0439 bpw  accuracy: 0.99871538\n",
      " -- 6.3381 bpw  accuracy: 0.99935339\n",
      " -- 8.0439 bpw  accuracy: 0.99966834\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.5 (Attention)        |\n",
      "| Duration: 5.89 seconds                      |\n",
      "| Completed step: 11/67                       |\n",
      "| Avg time / step (rolling): 9.17 seconds     |\n",
      "| Estimated remaining time: 8min 33sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.5 (MLP)\n",
      " -- model.layers.5.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.5.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.5.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.5.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.5.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.97821275\n",
      " -- 2.3230 bpw  accuracy: 0.97880511\n",
      " -- 2.5958 bpw  accuracy: 0.98228031\n",
      " -- 2.9120 bpw  accuracy: 0.98331094\n",
      " -- 3.2833 bpw  accuracy: 0.98907294\n",
      " -- 3.3655 bpw  accuracy: 0.98998463\n",
      " -- 3.6186 bpw  accuracy: 0.99138389\n",
      " -- 4.1368 bpw  accuracy: 0.99439166\n",
      " -- 4.1977 bpw  accuracy: 0.99490618\n",
      " -- 4.2662 bpw  accuracy: 0.99446957\n",
      " -- 4.3484 bpw  accuracy: 0.99519388\n",
      " -- 5.2491 bpw  accuracy: 0.99726792\n",
      " -- 5.3313 bpw  accuracy: 0.99765204\n",
      " -- 6.0713 bpw  accuracy: 0.99849593\n",
      " -- 6.3032 bpw  accuracy: 0.99858456\n",
      " -- 6.8687 bpw  accuracy: 0.99886721\n",
      " -- 8.0354 bpw  accuracy: 0.99959062\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.5 (MLP)              |\n",
      "| Duration: 12.62 seconds                     |\n",
      "| Completed step: 12/67                       |\n",
      "| Avg time / step (rolling): 9.19 seconds     |\n",
      "| Estimated remaining time: 8min 25sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.6 (Attention)\n",
      " -- model.layers.6.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.98490784\n",
      " -- 2.1987 bpw  accuracy: 0.98562137\n",
      " -- 2.2831 bpw  accuracy: 0.98759441\n",
      " -- 2.6768 bpw  accuracy: 0.99057465\n",
      " -- 3.1689 bpw  accuracy: 0.99255273\n",
      " -- 3.1705 bpw  accuracy: 0.99266836\n",
      " -- 4.0439 bpw  accuracy: 0.99451921\n",
      " -- 4.0471 bpw  accuracy: 0.99457974\n",
      " -- 4.0816 bpw  accuracy: 0.99557931\n",
      " -- 4.1381 bpw  accuracy: 0.99578619\n",
      " -- 4.1705 bpw  accuracy: 0.99646851\n",
      " -- 4.1902 bpw  accuracy: 0.99670895\n",
      " -- 4.2737 bpw  accuracy: 0.99684764\n",
      " -- 4.3295 bpw  accuracy: 0.99712648\n",
      " -- 5.2564 bpw  accuracy: 0.99827953\n",
      " -- 5.3295 bpw  accuracy: 0.99855230\n",
      " -- 6.0439 bpw  accuracy: 0.99864892\n",
      " -- 6.3381 bpw  accuracy: 0.99927821\n",
      " -- 8.0439 bpw  accuracy: 0.99963352\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.6 (Attention)        |\n",
      "| Duration: 5.90 seconds                      |\n",
      "| Completed step: 13/67                       |\n",
      "| Avg time / step (rolling): 9.19 seconds     |\n",
      "| Estimated remaining time: 8min 16sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.6 (MLP)\n",
      " -- model.layers.6.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.6.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.6.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.6.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.6.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.97425174\n",
      " -- 2.3230 bpw  accuracy: 0.97491090\n",
      " -- 2.5958 bpw  accuracy: 0.97921299\n",
      " -- 2.9120 bpw  accuracy: 0.98049050\n",
      " -- 3.2833 bpw  accuracy: 0.98704100\n",
      " -- 3.3655 bpw  accuracy: 0.98814980\n",
      " -- 3.6186 bpw  accuracy: 0.98989472\n",
      " -- 4.1368 bpw  accuracy: 0.99333047\n",
      " -- 4.1977 bpw  accuracy: 0.99396831\n",
      " -- 4.2662 bpw  accuracy: 0.99343124\n",
      " -- 4.3484 bpw  accuracy: 0.99430115\n",
      " -- 5.2491 bpw  accuracy: 0.99674945\n",
      " -- 5.3313 bpw  accuracy: 0.99721505\n",
      " -- 6.0713 bpw  accuracy: 0.99821315\n",
      " -- 6.3032 bpw  accuracy: 0.99831495\n",
      " -- 6.8687 bpw  accuracy: 0.99867439\n",
      " -- 8.0354 bpw  accuracy: 0.99951992\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.6 (MLP)              |\n",
      "| Duration: 12.64 seconds                     |\n",
      "| Completed step: 14/67                       |\n",
      "| Avg time / step (rolling): 9.20 seconds     |\n",
      "| Estimated remaining time: 8min 7sec         |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.7 (Attention)\n",
      " -- model.layers.7.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.98184880\n",
      " -- 2.1987 bpw  accuracy: 0.98250570\n",
      " -- 2.2831 bpw  accuracy: 0.98456838\n",
      " -- 2.6768 bpw  accuracy: 0.98858559\n",
      " -- 3.1689 bpw  accuracy: 0.99061604\n",
      " -- 3.1705 bpw  accuracy: 0.99102581\n",
      " -- 4.0439 bpw  accuracy: 0.99326906\n",
      " -- 4.0471 bpw  accuracy: 0.99379139\n",
      " -- 4.0816 bpw  accuracy: 0.99459791\n",
      " -- 4.1381 bpw  accuracy: 0.99488844\n",
      " -- 4.1705 bpw  accuracy: 0.99551100\n",
      " -- 4.1902 bpw  accuracy: 0.99580627\n",
      " -- 4.2737 bpw  accuracy: 0.99592581\n",
      " -- 4.3295 bpw  accuracy: 0.99641011\n",
      " -- 5.2564 bpw  accuracy: 0.99785712\n",
      " -- 5.3295 bpw  accuracy: 0.99819995\n",
      " -- 6.0439 bpw  accuracy: 0.99841379\n",
      " -- 6.3381 bpw  accuracy: 0.99899529\n",
      " -- 8.0439 bpw  accuracy: 0.99957754\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.7 (Attention)        |\n",
      "| Duration: 5.91 seconds                      |\n",
      "| Completed step: 15/67                       |\n",
      "| Avg time / step (rolling): 9.22 seconds     |\n",
      "| Estimated remaining time: 7min 59sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.7 (MLP)\n",
      " -- model.layers.7.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.7.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.7.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.7.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.7.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.96992661\n",
      " -- 2.3230 bpw  accuracy: 0.97073477\n",
      " -- 2.5958 bpw  accuracy: 0.97551820\n",
      " -- 2.9120 bpw  accuracy: 0.97693057\n",
      " -- 3.2833 bpw  accuracy: 0.98486616\n",
      " -- 3.3655 bpw  accuracy: 0.98617097\n",
      " -- 3.6186 bpw  accuracy: 0.98808992\n",
      " -- 4.1368 bpw  accuracy: 0.99222279\n",
      " -- 4.1977 bpw  accuracy: 0.99295375\n",
      " -- 4.2662 bpw  accuracy: 0.99231647\n",
      " -- 4.3484 bpw  accuracy: 0.99334321\n",
      " -- 5.2491 bpw  accuracy: 0.99619414\n",
      " -- 5.3313 bpw  accuracy: 0.99674674\n",
      " -- 6.0713 bpw  accuracy: 0.99790645\n",
      " -- 6.3032 bpw  accuracy: 0.99802338\n",
      " -- 6.8687 bpw  accuracy: 0.99841260\n",
      " -- 8.0354 bpw  accuracy: 0.99943790\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.7 (MLP)              |\n",
      "| Duration: 12.64 seconds                     |\n",
      "| Completed step: 16/67                       |\n",
      "| Avg time / step (rolling): 9.23 seconds     |\n",
      "| Estimated remaining time: 7min 50sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.8 (Attention)\n",
      " -- model.layers.8.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.98038626\n",
      " -- 2.1987 bpw  accuracy: 0.98099138\n",
      " -- 2.2831 bpw  accuracy: 0.98301967\n",
      " -- 2.6768 bpw  accuracy: 0.98748156\n",
      " -- 3.1689 bpw  accuracy: 0.98971303\n",
      " -- 3.1705 bpw  accuracy: 0.99012038\n",
      " -- 4.0439 bpw  accuracy: 0.99270296\n",
      " -- 4.0471 bpw  accuracy: 0.99327347\n",
      " -- 4.0816 bpw  accuracy: 0.99405864\n",
      " -- 4.1381 bpw  accuracy: 0.99451272\n",
      " -- 4.1705 bpw  accuracy: 0.99513902\n",
      " -- 4.1902 bpw  accuracy: 0.99546206\n",
      " -- 4.2737 bpw  accuracy: 0.99570600\n",
      " -- 4.3295 bpw  accuracy: 0.99599203\n",
      " -- 5.2564 bpw  accuracy: 0.99751897\n",
      " -- 5.3295 bpw  accuracy: 0.99802104\n",
      " -- 6.0439 bpw  accuracy: 0.99810574\n",
      " -- 6.3381 bpw  accuracy: 0.99892809\n",
      " -- 8.0439 bpw  accuracy: 0.99949762\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.8 (Attention)        |\n",
      "| Duration: 5.91 seconds                      |\n",
      "| Completed step: 17/67                       |\n",
      "| Avg time / step (rolling): 9.26 seconds     |\n",
      "| Estimated remaining time: 7min 43sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.8 (MLP)\n",
      " -- model.layers.8.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.8.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.8.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.8.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.8.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.96685744\n",
      " -- 2.3230 bpw  accuracy: 0.96771763\n",
      " -- 2.5958 bpw  accuracy: 0.97310363\n",
      " -- 2.9120 bpw  accuracy: 0.97466608\n",
      " -- 3.2833 bpw  accuracy: 0.98332532\n",
      " -- 3.3655 bpw  accuracy: 0.98476109\n",
      " -- 3.6186 bpw  accuracy: 0.98691160\n",
      " -- 4.1368 bpw  accuracy: 0.99142848\n",
      " -- 4.1977 bpw  accuracy: 0.99223517\n",
      " -- 4.2662 bpw  accuracy: 0.99154361\n",
      " -- 4.3484 bpw  accuracy: 0.99267144\n",
      " -- 5.2491 bpw  accuracy: 0.99581136\n",
      " -- 5.3313 bpw  accuracy: 0.99641551\n",
      " -- 6.0713 bpw  accuracy: 0.99769630\n",
      " -- 6.3032 bpw  accuracy: 0.99782714\n",
      " -- 6.8687 bpw  accuracy: 0.99826298\n",
      " -- 8.0354 bpw  accuracy: 0.99937896\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.8 (MLP)              |\n",
      "| Duration: 12.64 seconds                     |\n",
      "| Completed step: 18/67                       |\n",
      "| Avg time / step (rolling): 9.27 seconds     |\n",
      "| Estimated remaining time: 7min 34sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.9 (Attention)\n",
      " -- model.layers.9.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.97813894\n",
      " -- 2.1987 bpw  accuracy: 0.97882835\n",
      " -- 2.2831 bpw  accuracy: 0.98081374\n",
      " -- 2.6768 bpw  accuracy: 0.98521034\n",
      " -- 3.1689 bpw  accuracy: 0.98882836\n",
      " -- 3.1705 bpw  accuracy: 0.98905451\n",
      " -- 4.0439 bpw  accuracy: 0.99216686\n",
      " -- 4.0471 bpw  accuracy: 0.99245063\n",
      " -- 4.0816 bpw  accuracy: 0.99348500\n",
      " -- 4.1381 bpw  accuracy: 0.99371135\n",
      " -- 4.1705 bpw  accuracy: 0.99469035\n",
      " -- 4.1902 bpw  accuracy: 0.99500717\n",
      " -- 4.2737 bpw  accuracy: 0.99524542\n",
      " -- 4.3295 bpw  accuracy: 0.99570829\n",
      " -- 5.2564 bpw  accuracy: 0.99741600\n",
      " -- 5.3295 bpw  accuracy: 0.99776744\n",
      " -- 6.0439 bpw  accuracy: 0.99811730\n",
      " -- 6.3381 bpw  accuracy: 0.99870201\n",
      " -- 8.0439 bpw  accuracy: 0.99948366\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.9 (Attention)        |\n",
      "| Duration: 5.92 seconds                      |\n",
      "| Completed step: 19/67                       |\n",
      "| Avg time / step (rolling): 9.27 seconds     |\n",
      "| Estimated remaining time: 7min 25sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.9 (MLP)\n",
      " -- model.layers.9.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.9.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.9.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.9.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.9.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.96371641\n",
      " -- 2.3230 bpw  accuracy: 0.96467262\n",
      " -- 2.5958 bpw  accuracy: 0.97062040\n",
      " -- 2.9120 bpw  accuracy: 0.97239717\n",
      " -- 3.2833 bpw  accuracy: 0.98165114\n",
      " -- 3.3655 bpw  accuracy: 0.98322284\n",
      " -- 3.6186 bpw  accuracy: 0.98566992\n",
      " -- 4.1368 bpw  accuracy: 0.99054928\n",
      " -- 4.1977 bpw  accuracy: 0.99142193\n",
      " -- 4.2662 bpw  accuracy: 0.99067739\n",
      " -- 4.3484 bpw  accuracy: 0.99191221\n",
      " -- 5.2491 bpw  accuracy: 0.99538382\n",
      " -- 5.3313 bpw  accuracy: 0.99604620\n",
      " -- 6.0713 bpw  accuracy: 0.99745088\n",
      " -- 6.3032 bpw  accuracy: 0.99760130\n",
      " -- 6.8687 bpw  accuracy: 0.99808701\n",
      " -- 8.0354 bpw  accuracy: 0.99929938\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.9 (MLP)              |\n",
      "| Duration: 12.71 seconds                     |\n",
      "| Completed step: 20/67                       |\n",
      "| Avg time / step (rolling): 9.28 seconds     |\n",
      "| Estimated remaining time: 7min 16sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.10 (Attention)\n",
      " -- model.layers.10.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.97437903\n",
      " -- 2.1987 bpw  accuracy: 0.97538614\n",
      " -- 2.2831 bpw  accuracy: 0.97762574\n",
      " -- 2.6768 bpw  accuracy: 0.98309198\n",
      " -- 3.1689 bpw  accuracy: 0.98668953\n",
      " -- 3.1705 bpw  accuracy: 0.98720882\n",
      " -- 4.0439 bpw  accuracy: 0.99081805\n",
      " -- 4.0471 bpw  accuracy: 0.99151129\n",
      " -- 4.0816 bpw  accuracy: 0.99259013\n",
      " -- 4.1381 bpw  accuracy: 0.99280126\n",
      " -- 4.1705 bpw  accuracy: 0.99338121\n",
      " -- 4.1902 bpw  accuracy: 0.99393130\n",
      " -- 4.2737 bpw  accuracy: 0.99423634\n",
      " -- 4.3295 bpw  accuracy: 0.99480901\n",
      " -- 5.2564 bpw  accuracy: 0.99691277\n",
      " -- 5.3295 bpw  accuracy: 0.99741725\n",
      " -- 6.0439 bpw  accuracy: 0.99775560\n",
      " -- 6.3381 bpw  accuracy: 0.99855077\n",
      " -- 8.0439 bpw  accuracy: 0.99940834\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.10 (Attention)       |\n",
      "| Duration: 5.92 seconds                      |\n",
      "| Completed step: 21/67                       |\n",
      "| Avg time / step (rolling): 9.28 seconds     |\n",
      "| Estimated remaining time: 7min 6sec         |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.10 (MLP)\n",
      " -- model.layers.10.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.10.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.10.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.10.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.10.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.96137827\n",
      " -- 2.3230 bpw  accuracy: 0.96245044\n",
      " -- 2.5958 bpw  accuracy: 0.96915864\n",
      " -- 2.9120 bpw  accuracy: 0.97116217\n",
      " -- 3.2833 bpw  accuracy: 0.98044226\n",
      " -- 3.3655 bpw  accuracy: 0.98215336\n",
      " -- 3.6186 bpw  accuracy: 0.98490497\n",
      " -- 4.1368 bpw  accuracy: 0.98984606\n",
      " -- 4.1977 bpw  accuracy: 0.99086147\n",
      " -- 4.2662 bpw  accuracy: 0.99006362\n",
      " -- 4.3484 bpw  accuracy: 0.99140567\n",
      " -- 5.2491 bpw  accuracy: 0.99508266\n",
      " -- 5.3313 bpw  accuracy: 0.99579653\n",
      " -- 6.0713 bpw  accuracy: 0.99728235\n",
      " -- 6.3032 bpw  accuracy: 0.99745179\n",
      " -- 6.8687 bpw  accuracy: 0.99802170\n",
      " -- 8.0354 bpw  accuracy: 0.99926734\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.10 (MLP)             |\n",
      "| Duration: 12.68 seconds                     |\n",
      "| Completed step: 22/67                       |\n",
      "| Avg time / step (rolling): 9.29 seconds     |\n",
      "| Estimated remaining time: 6min 57sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.11 (Attention)\n",
      " -- model.layers.11.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96981987\n",
      " -- 2.1987 bpw  accuracy: 0.97108255\n",
      " -- 2.2831 bpw  accuracy: 0.97374235\n",
      " -- 2.6768 bpw  accuracy: 0.98027944\n",
      " -- 3.1689 bpw  accuracy: 0.98404948\n",
      " -- 3.1705 bpw  accuracy: 0.98461858\n",
      " -- 4.0439 bpw  accuracy: 0.98866223\n",
      " -- 4.0471 bpw  accuracy: 0.98943498\n",
      " -- 4.0816 bpw  accuracy: 0.99093753\n",
      " -- 4.1381 bpw  accuracy: 0.99145705\n",
      " -- 4.1705 bpw  accuracy: 0.99243057\n",
      " -- 4.1902 bpw  accuracy: 0.99297052\n",
      " -- 4.2737 bpw  accuracy: 0.99334578\n",
      " -- 4.3295 bpw  accuracy: 0.99391284\n",
      " -- 5.2564 bpw  accuracy: 0.99618926\n",
      " -- 5.3295 bpw  accuracy: 0.99690138\n",
      " -- 6.0439 bpw  accuracy: 0.99710201\n",
      " -- 6.3381 bpw  accuracy: 0.99815919\n",
      " -- 8.0439 bpw  accuracy: 0.99921752\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.11 (Attention)       |\n",
      "| Duration: 5.95 seconds                      |\n",
      "| Completed step: 23/67                       |\n",
      "| Avg time / step (rolling): 9.29 seconds     |\n",
      "| Estimated remaining time: 6min 48sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.11 (MLP)\n",
      " -- model.layers.11.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.11.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.11.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.11.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.11.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.95859383\n",
      " -- 2.3230 bpw  accuracy: 0.95978761\n",
      " -- 2.5958 bpw  accuracy: 0.96701130\n",
      " -- 2.9120 bpw  accuracy: 0.96918066\n",
      " -- 3.2833 bpw  accuracy: 0.97902120\n",
      " -- 3.3655 bpw  accuracy: 0.98085413\n",
      " -- 3.6186 bpw  accuracy: 0.98383008\n",
      " -- 4.1368 bpw  accuracy: 0.98908358\n",
      " -- 4.1977 bpw  accuracy: 0.99017716\n",
      " -- 4.2662 bpw  accuracy: 0.98935359\n",
      " -- 4.3484 bpw  accuracy: 0.99077773\n",
      " -- 5.2491 bpw  accuracy: 0.99473352\n",
      " -- 5.3313 bpw  accuracy: 0.99549243\n",
      " -- 6.0713 bpw  accuracy: 0.99707636\n",
      " -- 6.3032 bpw  accuracy: 0.99727619\n",
      " -- 6.8687 bpw  accuracy: 0.99789201\n",
      " -- 8.0354 bpw  accuracy: 0.99921550\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.11 (MLP)             |\n",
      "| Duration: 12.69 seconds                     |\n",
      "| Completed step: 24/67                       |\n",
      "| Avg time / step (rolling): 9.30 seconds     |\n",
      "| Estimated remaining time: 6min 39sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.12 (Attention)\n",
      " -- model.layers.12.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96287889\n",
      " -- 2.1987 bpw  accuracy: 0.96413599\n",
      " -- 2.2831 bpw  accuracy: 0.96834807\n",
      " -- 2.6768 bpw  accuracy: 0.97514802\n",
      " -- 3.1689 bpw  accuracy: 0.98052176\n",
      " -- 3.1705 bpw  accuracy: 0.98142659\n",
      " -- 4.0439 bpw  accuracy: 0.98568813\n",
      " -- 4.0471 bpw  accuracy: 0.98685676\n",
      " -- 4.0816 bpw  accuracy: 0.98820274\n",
      " -- 4.1381 bpw  accuracy: 0.98867370\n",
      " -- 4.1705 bpw  accuracy: 0.99059913\n",
      " -- 4.1902 bpw  accuracy: 0.99127305\n",
      " -- 4.2737 bpw  accuracy: 0.99145322\n",
      " -- 4.3295 bpw  accuracy: 0.99219427\n",
      " -- 5.2564 bpw  accuracy: 0.99532659\n",
      " -- 5.3295 bpw  accuracy: 0.99618026\n",
      " -- 6.0439 bpw  accuracy: 0.99638831\n",
      " -- 6.3381 bpw  accuracy: 0.99798949\n",
      " -- 8.0439 bpw  accuracy: 0.99895861\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.12 (Attention)       |\n",
      "| Duration: 5.94 seconds                      |\n",
      "| Completed step: 25/67                       |\n",
      "| Avg time / step (rolling): 9.30 seconds     |\n",
      "| Estimated remaining time: 6min 30sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.12 (MLP)\n",
      " -- model.layers.12.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.12.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.12.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.12.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.12.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.95419558\n",
      " -- 2.3230 bpw  accuracy: 0.95556662\n",
      " -- 2.5958 bpw  accuracy: 0.96316296\n",
      " -- 2.9120 bpw  accuracy: 0.96545708\n",
      " -- 3.2833 bpw  accuracy: 0.97677398\n",
      " -- 3.3655 bpw  accuracy: 0.97884532\n",
      " -- 3.6186 bpw  accuracy: 0.98197386\n",
      " -- 4.1368 bpw  accuracy: 0.98792195\n",
      " -- 4.1977 bpw  accuracy: 0.98911457\n",
      " -- 4.2662 bpw  accuracy: 0.98819529\n",
      " -- 4.3484 bpw  accuracy: 0.98980240\n",
      " -- 5.2491 bpw  accuracy: 0.99415605\n",
      " -- 5.3313 bpw  accuracy: 0.99500842\n",
      " -- 6.0713 bpw  accuracy: 0.99674244\n",
      " -- 6.3032 bpw  accuracy: 0.99696381\n",
      " -- 6.8687 bpw  accuracy: 0.99758872\n",
      " -- 8.0354 bpw  accuracy: 0.99911010\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.12 (MLP)             |\n",
      "| Duration: 12.75 seconds                     |\n",
      "| Completed step: 26/67                       |\n",
      "| Avg time / step (rolling): 9.31 seconds     |\n",
      "| Estimated remaining time: 6min 21sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.13 (Attention)\n",
      " -- model.layers.13.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96470545\n",
      " -- 2.1987 bpw  accuracy: 0.96597350\n",
      " -- 2.2831 bpw  accuracy: 0.96881094\n",
      " -- 2.6768 bpw  accuracy: 0.97731663\n",
      " -- 3.1689 bpw  accuracy: 0.98136767\n",
      " -- 3.1705 bpw  accuracy: 0.98198028\n",
      " -- 4.0439 bpw  accuracy: 0.98801660\n",
      " -- 4.0471 bpw  accuracy: 0.98887967\n",
      " -- 4.0816 bpw  accuracy: 0.99015216\n",
      " -- 4.1381 bpw  accuracy: 0.99058561\n",
      " -- 4.1705 bpw  accuracy: 0.99096482\n",
      " -- 4.1902 bpw  accuracy: 0.99148114\n",
      " -- 4.2737 bpw  accuracy: 0.99202894\n",
      " -- 4.3295 bpw  accuracy: 0.99285317\n",
      " -- 5.2564 bpw  accuracy: 0.99569378\n",
      " -- 5.3295 bpw  accuracy: 0.99641385\n",
      " -- 6.0439 bpw  accuracy: 0.99702716\n",
      " -- 6.3381 bpw  accuracy: 0.99796475\n",
      " -- 8.0439 bpw  accuracy: 0.99919600\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.13 (Attention)       |\n",
      "| Duration: 5.92 seconds                      |\n",
      "| Completed step: 27/67                       |\n",
      "| Avg time / step (rolling): 9.31 seconds     |\n",
      "| Estimated remaining time: 6min 12sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.13 (MLP)\n",
      " -- model.layers.13.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.13.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.13.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.13.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.13.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.94985841\n",
      " -- 2.3230 bpw  accuracy: 0.95134312\n",
      " -- 2.5958 bpw  accuracy: 0.95981956\n",
      " -- 2.9120 bpw  accuracy: 0.96242797\n",
      " -- 3.2833 bpw  accuracy: 0.97448919\n",
      " -- 3.3655 bpw  accuracy: 0.97674586\n",
      " -- 3.6186 bpw  accuracy: 0.98024937\n",
      " -- 4.1368 bpw  accuracy: 0.98668353\n",
      " -- 4.1977 bpw  accuracy: 0.98801875\n",
      " -- 4.2662 bpw  accuracy: 0.98703018\n",
      " -- 4.3484 bpw  accuracy: 0.98879458\n",
      " -- 5.2491 bpw  accuracy: 0.99358596\n",
      " -- 5.3313 bpw  accuracy: 0.99452471\n",
      " -- 6.0713 bpw  accuracy: 0.99642785\n",
      " -- 6.3032 bpw  accuracy: 0.99667665\n",
      " -- 6.8687 bpw  accuracy: 0.99739802\n",
      " -- 8.0354 bpw  accuracy: 0.99903422\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.13 (MLP)             |\n",
      "| Duration: 12.72 seconds                     |\n",
      "| Completed step: 28/67                       |\n",
      "| Avg time / step (rolling): 9.32 seconds     |\n",
      "| Estimated remaining time: 6min 3sec         |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.14 (Attention)\n",
      " -- model.layers.14.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95935708\n",
      " -- 2.1987 bpw  accuracy: 0.96119051\n",
      " -- 2.2831 bpw  accuracy: 0.96500258\n",
      " -- 2.6768 bpw  accuracy: 0.97422028\n",
      " -- 3.1689 bpw  accuracy: 0.97847117\n",
      " -- 3.1705 bpw  accuracy: 0.97961935\n",
      " -- 4.0439 bpw  accuracy: 0.98573545\n",
      " -- 4.0471 bpw  accuracy: 0.98732374\n",
      " -- 4.0816 bpw  accuracy: 0.98797222\n",
      " -- 4.1381 bpw  accuracy: 0.98892176\n",
      " -- 4.1705 bpw  accuracy: 0.98957101\n",
      " -- 4.1902 bpw  accuracy: 0.99028801\n",
      " -- 4.2737 bpw  accuracy: 0.99089945\n",
      " -- 4.3295 bpw  accuracy: 0.99175802\n",
      " -- 5.2564 bpw  accuracy: 0.99481337\n",
      " -- 5.3295 bpw  accuracy: 0.99594716\n",
      " -- 6.0439 bpw  accuracy: 0.99612663\n",
      " -- 6.3381 bpw  accuracy: 0.99777103\n",
      " -- 8.0439 bpw  accuracy: 0.99897367\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.14 (Attention)       |\n",
      "| Duration: 5.93 seconds                      |\n",
      "| Completed step: 29/67                       |\n",
      "| Avg time / step (rolling): 9.32 seconds     |\n",
      "| Estimated remaining time: 5min 54sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.14 (MLP)\n",
      " -- model.layers.14.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.14.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.14.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.14.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.14.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.94578787\n",
      " -- 2.3230 bpw  accuracy: 0.94736149\n",
      " -- 2.5958 bpw  accuracy: 0.95626481\n",
      " -- 2.9120 bpw  accuracy: 0.95897223\n",
      " -- 3.2833 bpw  accuracy: 0.97251338\n",
      " -- 3.3655 bpw  accuracy: 0.97501254\n",
      " -- 3.6186 bpw  accuracy: 0.97864408\n",
      " -- 4.1368 bpw  accuracy: 0.98562327\n",
      " -- 4.1977 bpw  accuracy: 0.98698266\n",
      " -- 4.2662 bpw  accuracy: 0.98607753\n",
      " -- 4.3484 bpw  accuracy: 0.98790616\n",
      " -- 5.2491 bpw  accuracy: 0.99308303\n",
      " -- 5.3313 bpw  accuracy: 0.99409170\n",
      " -- 6.0713 bpw  accuracy: 0.99607775\n",
      " -- 6.3032 bpw  accuracy: 0.99641389\n",
      " -- 6.8687 bpw  accuracy: 0.99716197\n",
      " -- 8.0354 bpw  accuracy: 0.99887687\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.14 (MLP)             |\n",
      "| Duration: 12.79 seconds                     |\n",
      "| Completed step: 30/67                       |\n",
      "| Avg time / step (rolling): 9.33 seconds     |\n",
      "| Estimated remaining time: 5min 45sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.15 (Attention)\n",
      " -- model.layers.15.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95534538\n",
      " -- 2.1987 bpw  accuracy: 0.95665649\n",
      " -- 2.2831 bpw  accuracy: 0.96101077\n",
      " -- 2.6768 bpw  accuracy: 0.96902782\n",
      " -- 3.1689 bpw  accuracy: 0.97528601\n",
      " -- 3.1705 bpw  accuracy: 0.97687452\n",
      " -- 4.0439 bpw  accuracy: 0.98203178\n",
      " -- 4.0471 bpw  accuracy: 0.98396167\n",
      " -- 4.0816 bpw  accuracy: 0.98498416\n",
      " -- 4.1381 bpw  accuracy: 0.98542746\n",
      " -- 4.1705 bpw  accuracy: 0.98823753\n",
      " -- 4.1902 bpw  accuracy: 0.98900545\n",
      " -- 4.2737 bpw  accuracy: 0.98953551\n",
      " -- 4.3295 bpw  accuracy: 0.99043216\n",
      " -- 5.2564 bpw  accuracy: 0.99410800\n",
      " -- 5.3295 bpw  accuracy: 0.99527867\n",
      " -- 6.0439 bpw  accuracy: 0.99532138\n",
      " -- 6.3381 bpw  accuracy: 0.99744927\n",
      " -- 8.0439 bpw  accuracy: 0.99877059\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.15 (Attention)        |\n",
      "| Duration: 5.92 seconds                       |\n",
      "| Completed step: 31/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 5min 35sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.15 (MLP)\n",
      " -- model.layers.15.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.15.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.15.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.15.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.15.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.94168838\n",
      " -- 2.3230 bpw  accuracy: 0.94333634\n",
      " -- 2.5958 bpw  accuracy: 0.95278961\n",
      " -- 2.9120 bpw  accuracy: 0.95568677\n",
      " -- 3.2833 bpw  accuracy: 0.97047919\n",
      " -- 3.3655 bpw  accuracy: 0.97302757\n",
      " -- 3.6186 bpw  accuracy: 0.97689711\n",
      " -- 4.1368 bpw  accuracy: 0.98461405\n",
      " -- 4.1977 bpw  accuracy: 0.98608382\n",
      " -- 4.2662 bpw  accuracy: 0.98499321\n",
      " -- 4.3484 bpw  accuracy: 0.98700251\n",
      " -- 5.2491 bpw  accuracy: 0.99257048\n",
      " -- 5.3313 bpw  accuracy: 0.99364462\n",
      " -- 6.0713 bpw  accuracy: 0.99585666\n",
      " -- 6.3032 bpw  accuracy: 0.99614825\n",
      " -- 6.8687 bpw  accuracy: 0.99692805\n",
      " -- 8.0354 bpw  accuracy: 0.99886750\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.15 (MLP)              |\n",
      "| Duration: 12.76 seconds                      |\n",
      "| Completed step: 32/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 5min 26sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.16 (Attention)\n",
      " -- model.layers.16.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95692859\n",
      " -- 2.1987 bpw  accuracy: 0.95826300\n",
      " -- 2.2831 bpw  accuracy: 0.96250571\n",
      " -- 2.6768 bpw  accuracy: 0.97175337\n",
      " -- 3.1689 bpw  accuracy: 0.97764953\n",
      " -- 3.1705 bpw  accuracy: 0.97862981\n",
      " -- 4.0439 bpw  accuracy: 0.98541043\n",
      " -- 4.0471 bpw  accuracy: 0.98673993\n",
      " -- 4.0816 bpw  accuracy: 0.98675157\n",
      " -- 4.1381 bpw  accuracy: 0.98815756\n",
      " -- 4.1705 bpw  accuracy: 0.98904965\n",
      " -- 4.1902 bpw  accuracy: 0.98975991\n",
      " -- 4.2737 bpw  accuracy: 0.99038396\n",
      " -- 4.3295 bpw  accuracy: 0.99135514\n",
      " -- 5.2564 bpw  accuracy: 0.99478835\n",
      " -- 5.3295 bpw  accuracy: 0.99568544\n",
      " -- 6.0439 bpw  accuracy: 0.99623962\n",
      " -- 6.3381 bpw  accuracy: 0.99760178\n",
      " -- 8.0439 bpw  accuracy: 0.99889425\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.16 (Attention)        |\n",
      "| Duration: 5.93 seconds                       |\n",
      "| Completed step: 33/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 5min 17sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.16 (MLP)\n",
      " -- model.layers.16.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.16.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.16.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.16.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.16.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.93522091\n",
      " -- 2.3230 bpw  accuracy: 0.93702847\n",
      " -- 2.5958 bpw  accuracy: 0.94746122\n",
      " -- 2.9120 bpw  accuracy: 0.95073487\n",
      " -- 3.2833 bpw  accuracy: 0.96724018\n",
      " -- 3.3655 bpw  accuracy: 0.97005731\n",
      " -- 3.6186 bpw  accuracy: 0.97436185\n",
      " -- 4.1368 bpw  accuracy: 0.98286930\n",
      " -- 4.1977 bpw  accuracy: 0.98449624\n",
      " -- 4.2662 bpw  accuracy: 0.98339812\n",
      " -- 4.3484 bpw  accuracy: 0.98559165\n",
      " -- 5.2491 bpw  accuracy: 0.99179451\n",
      " -- 5.3313 bpw  accuracy: 0.99295317\n",
      " -- 6.0713 bpw  accuracy: 0.99539488\n",
      " -- 6.3032 bpw  accuracy: 0.99576100\n",
      " -- 6.8687 bpw  accuracy: 0.99662660\n",
      " -- 8.0354 bpw  accuracy: 0.99873437\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.16 (MLP)              |\n",
      "| Duration: 12.71 seconds                      |\n",
      "| Completed step: 34/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 5min 8sec          |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.17 (Attention)\n",
      " -- model.layers.17.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95319562\n",
      " -- 2.1987 bpw  accuracy: 0.95475806\n",
      " -- 2.2831 bpw  accuracy: 0.95886227\n",
      " -- 2.6768 bpw  accuracy: 0.96921077\n",
      " -- 3.1689 bpw  accuracy: 0.97526391\n",
      " -- 3.1705 bpw  accuracy: 0.97682123\n",
      " -- 4.0439 bpw  accuracy: 0.98280460\n",
      " -- 4.0471 bpw  accuracy: 0.98485974\n",
      " -- 4.0816 bpw  accuracy: 0.98585407\n",
      " -- 4.1381 bpw  accuracy: 0.98651459\n",
      " -- 4.1705 bpw  accuracy: 0.98803397\n",
      " -- 4.1902 bpw  accuracy: 0.98903095\n",
      " -- 4.2737 bpw  accuracy: 0.98957590\n",
      " -- 4.3295 bpw  accuracy: 0.99042429\n",
      " -- 5.2564 bpw  accuracy: 0.99387860\n",
      " -- 5.3295 bpw  accuracy: 0.99524010\n",
      " -- 6.0439 bpw  accuracy: 0.99529188\n",
      " -- 6.3381 bpw  accuracy: 0.99742731\n",
      " -- 8.0439 bpw  accuracy: 0.99878451\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.17 (Attention)        |\n",
      "| Duration: 5.96 seconds                       |\n",
      "| Completed step: 35/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 4min 58sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.17 (MLP)\n",
      " -- model.layers.17.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.17.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.17.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.17.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.17.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92775315\n",
      " -- 2.3230 bpw  accuracy: 0.92979371\n",
      " -- 2.5958 bpw  accuracy: 0.94168371\n",
      " -- 2.9120 bpw  accuracy: 0.94551005\n",
      " -- 3.2833 bpw  accuracy: 0.96333989\n",
      " -- 3.3655 bpw  accuracy: 0.96652294\n",
      " -- 3.6186 bpw  accuracy: 0.97146887\n",
      " -- 4.1368 bpw  accuracy: 0.98074945\n",
      " -- 4.1977 bpw  accuracy: 0.98263661\n",
      " -- 4.2662 bpw  accuracy: 0.98137273\n",
      " -- 4.3484 bpw  accuracy: 0.98386303\n",
      " -- 5.2491 bpw  accuracy: 0.99076824\n",
      " -- 5.3313 bpw  accuracy: 0.99209633\n",
      " -- 6.0713 bpw  accuracy: 0.99482167\n",
      " -- 6.3032 bpw  accuracy: 0.99522440\n",
      " -- 6.8687 bpw  accuracy: 0.99624525\n",
      " -- 8.0354 bpw  accuracy: 0.99857407\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.17 (MLP)              |\n",
      "| Duration: 12.76 seconds                      |\n",
      "| Completed step: 36/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 4min 49sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.18 (Attention)\n",
      " -- model.layers.18.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95098485\n",
      " -- 2.1987 bpw  accuracy: 0.95251616\n",
      " -- 2.2831 bpw  accuracy: 0.95651499\n",
      " -- 2.6768 bpw  accuracy: 0.96439984\n",
      " -- 3.1689 bpw  accuracy: 0.97130303\n",
      " -- 3.1705 bpw  accuracy: 0.97584740\n",
      " -- 4.0439 bpw  accuracy: 0.97693021\n",
      " -- 4.0471 bpw  accuracy: 0.98316334\n",
      " -- 4.0816 bpw  accuracy: 0.98415130\n",
      " -- 4.1381 bpw  accuracy: 0.98482328\n",
      " -- 4.1705 bpw  accuracy: 0.98762412\n",
      " -- 4.1902 bpw  accuracy: 0.98834585\n",
      " -- 4.2737 bpw  accuracy: 0.98863773\n",
      " -- 4.3295 bpw  accuracy: 0.98975863\n",
      " -- 5.2564 bpw  accuracy: 0.99252112\n",
      " -- 5.3295 bpw  accuracy: 0.99501156\n",
      " -- 6.0439 bpw  accuracy: 0.99353071\n",
      " -- 6.3381 bpw  accuracy: 0.99745200\n",
      " -- 8.0439 bpw  accuracy: 0.99818460\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.18 (Attention)        |\n",
      "| Duration: 5.93 seconds                       |\n",
      "| Completed step: 37/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 4min 40sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.18 (MLP)\n",
      " -- model.layers.18.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.18.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.18.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.18.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.18.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92301570\n",
      " -- 2.3230 bpw  accuracy: 0.92525908\n",
      " -- 2.5958 bpw  accuracy: 0.93788211\n",
      " -- 2.9120 bpw  accuracy: 0.94200867\n",
      " -- 3.2833 bpw  accuracy: 0.96099594\n",
      " -- 3.3655 bpw  accuracy: 0.96439715\n",
      " -- 3.6186 bpw  accuracy: 0.96966844\n",
      " -- 4.1368 bpw  accuracy: 0.97944059\n",
      " -- 4.1977 bpw  accuracy: 0.98146686\n",
      " -- 4.2662 bpw  accuracy: 0.98020232\n",
      " -- 4.3484 bpw  accuracy: 0.98285325\n",
      " -- 5.2491 bpw  accuracy: 0.99017974\n",
      " -- 5.3313 bpw  accuracy: 0.99160129\n",
      " -- 6.0713 bpw  accuracy: 0.99446712\n",
      " -- 6.3032 bpw  accuracy: 0.99492434\n",
      " -- 6.8687 bpw  accuracy: 0.99602054\n",
      " -- 8.0354 bpw  accuracy: 0.99845724\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.18 (MLP)              |\n",
      "| Duration: 12.73 seconds                      |\n",
      "| Completed step: 38/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 4min 30sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.19 (Attention)\n",
      " -- model.layers.19.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95243978\n",
      " -- 2.1987 bpw  accuracy: 0.95375234\n",
      " -- 2.2831 bpw  accuracy: 0.95854085\n",
      " -- 2.6768 bpw  accuracy: 0.96758049\n",
      " -- 3.1689 bpw  accuracy: 0.97489434\n",
      " -- 3.1705 bpw  accuracy: 0.97617110\n",
      " -- 4.0439 bpw  accuracy: 0.98197893\n",
      " -- 4.0471 bpw  accuracy: 0.98362698\n",
      " -- 4.0816 bpw  accuracy: 0.98369437\n",
      " -- 4.1381 bpw  accuracy: 0.98600835\n",
      " -- 4.1705 bpw  accuracy: 0.98805929\n",
      " -- 4.1902 bpw  accuracy: 0.98884526\n",
      " -- 4.2737 bpw  accuracy: 0.98950584\n",
      " -- 4.3295 bpw  accuracy: 0.99019231\n",
      " -- 5.2564 bpw  accuracy: 0.99376293\n",
      " -- 5.3295 bpw  accuracy: 0.99518938\n",
      " -- 6.0439 bpw  accuracy: 0.99510694\n",
      " -- 6.3381 bpw  accuracy: 0.99737173\n",
      " -- 8.0439 bpw  accuracy: 0.99871980\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.19 (Attention)        |\n",
      "| Duration: 5.93 seconds                       |\n",
      "| Completed step: 39/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 4min 21sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.19 (MLP)\n",
      " -- model.layers.19.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.19.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.19.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.19.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.19.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92101506\n",
      " -- 2.3230 bpw  accuracy: 0.92330263\n",
      " -- 2.5958 bpw  accuracy: 0.93602939\n",
      " -- 2.9120 bpw  accuracy: 0.94025165\n",
      " -- 3.2833 bpw  accuracy: 0.95994016\n",
      " -- 3.3655 bpw  accuracy: 0.96346918\n",
      " -- 3.6186 bpw  accuracy: 0.96883221\n",
      " -- 4.1368 bpw  accuracy: 0.97881830\n",
      " -- 4.1977 bpw  accuracy: 0.98091423\n",
      " -- 4.2662 bpw  accuracy: 0.97961377\n",
      " -- 4.3484 bpw  accuracy: 0.98239775\n",
      " -- 5.2491 bpw  accuracy: 0.98985133\n",
      " -- 5.3313 bpw  accuracy: 0.99135584\n",
      " -- 6.0713 bpw  accuracy: 0.99424688\n",
      " -- 6.3032 bpw  accuracy: 0.99475043\n",
      " -- 6.8687 bpw  accuracy: 0.99585739\n",
      " -- 8.0354 bpw  accuracy: 0.99837334\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.19 (MLP)              |\n",
      "| Duration: 12.72 seconds                      |\n",
      "| Completed step: 40/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 4min 12sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.20 (Attention)\n",
      " -- model.layers.20.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95742921\n",
      " -- 2.1987 bpw  accuracy: 0.95898025\n",
      " -- 2.2831 bpw  accuracy: 0.96230600\n",
      " -- 2.6768 bpw  accuracy: 0.97050749\n",
      " -- 3.1689 bpw  accuracy: 0.97594694\n",
      " -- 3.1705 bpw  accuracy: 0.97887605\n",
      " -- 4.0439 bpw  accuracy: 0.98129614\n",
      " -- 4.0471 bpw  accuracy: 0.98522568\n",
      " -- 4.0816 bpw  accuracy: 0.98674334\n",
      " -- 4.1381 bpw  accuracy: 0.98753658\n",
      " -- 4.1705 bpw  accuracy: 0.98941766\n",
      " -- 4.1902 bpw  accuracy: 0.99022441\n",
      " -- 4.2737 bpw  accuracy: 0.99056432\n",
      " -- 4.3295 bpw  accuracy: 0.99131056\n",
      " -- 5.2564 bpw  accuracy: 0.99420257\n",
      " -- 5.3295 bpw  accuracy: 0.99561266\n",
      " -- 6.0439 bpw  accuracy: 0.99522939\n",
      " -- 6.3381 bpw  accuracy: 0.99740703\n",
      " -- 8.0439 bpw  accuracy: 0.99868785\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.20 (Attention)        |\n",
      "| Duration: 5.95 seconds                       |\n",
      "| Completed step: 41/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 4min 2sec          |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.20 (MLP)\n",
      " -- model.layers.20.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.20.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.20.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.20.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.20.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92177223\n",
      " -- 2.3230 bpw  accuracy: 0.92393315\n",
      " -- 2.5958 bpw  accuracy: 0.93597986\n",
      " -- 2.9120 bpw  accuracy: 0.93987658\n",
      " -- 3.2833 bpw  accuracy: 0.96043410\n",
      " -- 3.3655 bpw  accuracy: 0.96377924\n",
      " -- 3.6186 bpw  accuracy: 0.96886241\n",
      " -- 4.1368 bpw  accuracy: 0.97933795\n",
      " -- 4.1977 bpw  accuracy: 0.98129708\n",
      " -- 4.2662 bpw  accuracy: 0.97995357\n",
      " -- 4.3484 bpw  accuracy: 0.98258582\n",
      " -- 5.2491 bpw  accuracy: 0.99007710\n",
      " -- 5.3313 bpw  accuracy: 0.99148118\n",
      " -- 6.0713 bpw  accuracy: 0.99445199\n",
      " -- 6.3032 bpw  accuracy: 0.99487020\n",
      " -- 6.8687 bpw  accuracy: 0.99589158\n",
      " -- 8.0354 bpw  accuracy: 0.99844761\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.20 (MLP)              |\n",
      "| Duration: 12.76 seconds                      |\n",
      "| Completed step: 42/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 3min 53sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.21 (Attention)\n",
      " -- model.layers.21.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96163334\n",
      " -- 2.1987 bpw  accuracy: 0.96310685\n",
      " -- 2.2831 bpw  accuracy: 0.96566866\n",
      " -- 2.6768 bpw  accuracy: 0.97293069\n",
      " -- 3.1689 bpw  accuracy: 0.97775338\n",
      " -- 3.1705 bpw  accuracy: 0.98073374\n",
      " -- 4.0439 bpw  accuracy: 0.98257000\n",
      " -- 4.0471 bpw  accuracy: 0.98636386\n",
      " -- 4.0816 bpw  accuracy: 0.98749010\n",
      " -- 4.1381 bpw  accuracy: 0.98808723\n",
      " -- 4.1705 bpw  accuracy: 0.99017556\n",
      " -- 4.1902 bpw  accuracy: 0.99108141\n",
      " -- 4.2737 bpw  accuracy: 0.99123129\n",
      " -- 4.3295 bpw  accuracy: 0.99203587\n",
      " -- 5.2564 bpw  accuracy: 0.99457055\n",
      " -- 5.3295 bpw  accuracy: 0.99603104\n",
      " -- 6.0439 bpw  accuracy: 0.99540258\n",
      " -- 6.3381 bpw  accuracy: 0.99792257\n",
      " -- 8.0439 bpw  accuracy: 0.99881030\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.21 (Attention)        |\n",
      "| Duration: 5.93 seconds                       |\n",
      "| Completed step: 43/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 3min 44sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.21 (MLP)\n",
      " -- model.layers.21.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.21.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.21.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.21.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.21.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92338522\n",
      " -- 2.3230 bpw  accuracy: 0.92549450\n",
      " -- 2.5958 bpw  accuracy: 0.93675164\n",
      " -- 2.9120 bpw  accuracy: 0.94034369\n",
      " -- 3.2833 bpw  accuracy: 0.96137861\n",
      " -- 3.3655 bpw  accuracy: 0.96460363\n",
      " -- 3.6186 bpw  accuracy: 0.96927168\n",
      " -- 4.1368 bpw  accuracy: 0.97992670\n",
      " -- 4.1977 bpw  accuracy: 0.98176416\n",
      " -- 4.2662 bpw  accuracy: 0.98042331\n",
      " -- 4.3484 bpw  accuracy: 0.98298128\n",
      " -- 5.2491 bpw  accuracy: 0.99030240\n",
      " -- 5.3313 bpw  accuracy: 0.99166988\n",
      " -- 6.0713 bpw  accuracy: 0.99459203\n",
      " -- 6.3032 bpw  accuracy: 0.99497126\n",
      " -- 6.8687 bpw  accuracy: 0.99587610\n",
      " -- 8.0354 bpw  accuracy: 0.99848250\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.21 (MLP)              |\n",
      "| Duration: 12.71 seconds                      |\n",
      "| Completed step: 44/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 3min 34sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.22 (Attention)\n",
      " -- model.layers.22.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96828344\n",
      " -- 2.1987 bpw  accuracy: 0.96940217\n",
      " -- 2.2831 bpw  accuracy: 0.97272535\n",
      " -- 2.6768 bpw  accuracy: 0.97726661\n",
      " -- 3.1689 bpw  accuracy: 0.97987544\n",
      " -- 3.1705 bpw  accuracy: 0.98277536\n",
      " -- 4.0439 bpw  accuracy: 0.98280170\n",
      " -- 4.0471 bpw  accuracy: 0.98609435\n",
      " -- 4.0816 bpw  accuracy: 0.98801302\n",
      " -- 4.1381 bpw  accuracy: 0.98879946\n",
      " -- 4.1705 bpw  accuracy: 0.99157682\n",
      " -- 4.1902 bpw  accuracy: 0.99233060\n",
      " -- 4.2737 bpw  accuracy: 0.99231493\n",
      " -- 4.3295 bpw  accuracy: 0.99297096\n",
      " -- 5.2564 bpw  accuracy: 0.99496685\n",
      " -- 5.3295 bpw  accuracy: 0.99644080\n",
      " -- 6.0439 bpw  accuracy: 0.99545364\n",
      " -- 6.3381 bpw  accuracy: 0.99831899\n",
      " -- 8.0439 bpw  accuracy: 0.99877837\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.22 (Attention)        |\n",
      "| Duration: 5.95 seconds                       |\n",
      "| Completed step: 45/67                        |\n",
      "| Avg time / step (rolling): 9.34 seconds      |\n",
      "| Estimated remaining time: 3min 25sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.22 (MLP)\n",
      " -- model.layers.22.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.22.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.22.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.22.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.22.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92320130\n",
      " -- 2.3230 bpw  accuracy: 0.92524131\n",
      " -- 2.5958 bpw  accuracy: 0.93626485\n",
      " -- 2.9120 bpw  accuracy: 0.93974567\n",
      " -- 3.2833 bpw  accuracy: 0.96115474\n",
      " -- 3.3655 bpw  accuracy: 0.96435409\n",
      " -- 3.6186 bpw  accuracy: 0.96897017\n",
      " -- 4.1368 bpw  accuracy: 0.97986532\n",
      " -- 4.1977 bpw  accuracy: 0.98170940\n",
      " -- 4.2662 bpw  accuracy: 0.98031920\n",
      " -- 4.3484 bpw  accuracy: 0.98286281\n",
      " -- 5.2491 bpw  accuracy: 0.99027667\n",
      " -- 5.3313 bpw  accuracy: 0.99162637\n",
      " -- 6.0713 bpw  accuracy: 0.99461235\n",
      " -- 6.3032 bpw  accuracy: 0.99496561\n",
      " -- 6.8687 bpw  accuracy: 0.99587270\n",
      " -- 8.0354 bpw  accuracy: 0.99849023\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.22 (MLP)              |\n",
      "| Duration: 12.71 seconds                      |\n",
      "| Completed step: 46/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 3min 15sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.23 (Attention)\n",
      " -- model.layers.23.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96365883\n",
      " -- 2.1987 bpw  accuracy: 0.96512721\n",
      " -- 2.2831 bpw  accuracy: 0.96906087\n",
      " -- 2.6768 bpw  accuracy: 0.97496960\n",
      " -- 3.1689 bpw  accuracy: 0.98008830\n",
      " -- 3.1705 bpw  accuracy: 0.98197244\n",
      " -- 4.0439 bpw  accuracy: 0.98433986\n",
      " -- 4.0471 bpw  accuracy: 0.98688312\n",
      " -- 4.0816 bpw  accuracy: 0.98765753\n",
      " -- 4.1381 bpw  accuracy: 0.98818009\n",
      " -- 4.1705 bpw  accuracy: 0.99092095\n",
      " -- 4.1902 bpw  accuracy: 0.99148912\n",
      " -- 4.2737 bpw  accuracy: 0.99199597\n",
      " -- 4.3295 bpw  accuracy: 0.99267162\n",
      " -- 5.2564 bpw  accuracy: 0.99506176\n",
      " -- 5.3295 bpw  accuracy: 0.99633097\n",
      " -- 6.0439 bpw  accuracy: 0.99578116\n",
      " -- 6.3381 bpw  accuracy: 0.99813308\n",
      " -- 8.0439 bpw  accuracy: 0.99885096\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.23 (Attention)        |\n",
      "| Duration: 5.94 seconds                       |\n",
      "| Completed step: 47/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 3min 6sec          |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.23 (MLP)\n",
      " -- model.layers.23.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.23.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.23.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.23.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.23.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92277405\n",
      " -- 2.3230 bpw  accuracy: 0.92478693\n",
      " -- 2.5958 bpw  accuracy: 0.93556022\n",
      " -- 2.9120 bpw  accuracy: 0.93899771\n",
      " -- 3.2833 bpw  accuracy: 0.96088397\n",
      " -- 3.3655 bpw  accuracy: 0.96408699\n",
      " -- 3.6186 bpw  accuracy: 0.96862327\n",
      " -- 4.1368 bpw  accuracy: 0.97969671\n",
      " -- 4.1977 bpw  accuracy: 0.98156941\n",
      " -- 4.2662 bpw  accuracy: 0.98018749\n",
      " -- 4.3484 bpw  accuracy: 0.98273403\n",
      " -- 5.2491 bpw  accuracy: 0.99020522\n",
      " -- 5.3313 bpw  accuracy: 0.99155922\n",
      " -- 6.0713 bpw  accuracy: 0.99456957\n",
      " -- 6.3032 bpw  accuracy: 0.99493200\n",
      " -- 6.8687 bpw  accuracy: 0.99581199\n",
      " -- 8.0354 bpw  accuracy: 0.99849798\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.23 (MLP)              |\n",
      "| Duration: 12.73 seconds                      |\n",
      "| Completed step: 48/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 2min 57sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.24 (Attention)\n",
      " -- model.layers.24.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96566065\n",
      " -- 2.1987 bpw  accuracy: 0.96688533\n",
      " -- 2.2831 bpw  accuracy: 0.97009895\n",
      " -- 2.6768 bpw  accuracy: 0.97517401\n",
      " -- 3.1689 bpw  accuracy: 0.98004204\n",
      " -- 3.1705 bpw  accuracy: 0.98174276\n",
      " -- 4.0439 bpw  accuracy: 0.98419349\n",
      " -- 4.0471 bpw  accuracy: 0.98633464\n",
      " -- 4.0816 bpw  accuracy: 0.98825639\n",
      " -- 4.1381 bpw  accuracy: 0.98850586\n",
      " -- 4.1705 bpw  accuracy: 0.99126274\n",
      " -- 4.1902 bpw  accuracy: 0.99198523\n",
      " -- 4.2737 bpw  accuracy: 0.99235604\n",
      " -- 4.3295 bpw  accuracy: 0.99298846\n",
      " -- 5.2564 bpw  accuracy: 0.99551423\n",
      " -- 5.3295 bpw  accuracy: 0.99646285\n",
      " -- 6.0439 bpw  accuracy: 0.99619553\n",
      " -- 6.3381 bpw  accuracy: 0.99797723\n",
      " -- 8.0439 bpw  accuracy: 0.99900371\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.24 (Attention)        |\n",
      "| Duration: 5.94 seconds                       |\n",
      "| Completed step: 49/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 2min 48sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.24 (MLP)\n",
      " -- model.layers.24.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.24.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.24.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.24.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.24.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92217779\n",
      " -- 2.3230 bpw  accuracy: 0.92423538\n",
      " -- 2.5958 bpw  accuracy: 0.93496095\n",
      " -- 2.9120 bpw  accuracy: 0.93834296\n",
      " -- 3.2833 bpw  accuracy: 0.96057126\n",
      " -- 3.3655 bpw  accuracy: 0.96385069\n",
      " -- 3.6186 bpw  accuracy: 0.96831788\n",
      " -- 4.1368 bpw  accuracy: 0.97959522\n",
      " -- 4.1977 bpw  accuracy: 0.98145075\n",
      " -- 4.2662 bpw  accuracy: 0.98003451\n",
      " -- 4.3484 bpw  accuracy: 0.98262970\n",
      " -- 5.2491 bpw  accuracy: 0.99014079\n",
      " -- 5.3313 bpw  accuracy: 0.99151304\n",
      " -- 6.0713 bpw  accuracy: 0.99452829\n",
      " -- 6.3032 bpw  accuracy: 0.99490028\n",
      " -- 6.8687 bpw  accuracy: 0.99576118\n",
      " -- 8.0354 bpw  accuracy: 0.99848055\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.24 (MLP)              |\n",
      "| Duration: 12.72 seconds                      |\n",
      "| Completed step: 50/67                        |\n",
      "| Avg time / step (rolling): 9.33 seconds      |\n",
      "| Estimated remaining time: 2min 38sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.25 (Attention)\n",
      " -- model.layers.25.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96269424\n",
      " -- 2.1987 bpw  accuracy: 0.96415859\n",
      " -- 2.2831 bpw  accuracy: 0.96800648\n",
      " -- 2.6768 bpw  accuracy: 0.97368841\n",
      " -- 3.1689 bpw  accuracy: 0.97959948\n",
      " -- 3.1705 bpw  accuracy: 0.98133447\n",
      " -- 4.0439 bpw  accuracy: 0.98437782\n",
      " -- 4.0471 bpw  accuracy: 0.98664284\n",
      " -- 4.0816 bpw  accuracy: 0.98792662\n",
      " -- 4.1381 bpw  accuracy: 0.98849829\n",
      " -- 4.1705 bpw  accuracy: 0.99098692\n",
      " -- 4.1902 bpw  accuracy: 0.99152343\n",
      " -- 4.2737 bpw  accuracy: 0.99203423\n",
      " -- 4.3295 bpw  accuracy: 0.99293438\n",
      " -- 5.2564 bpw  accuracy: 0.99530464\n",
      " -- 5.3295 bpw  accuracy: 0.99637409\n",
      " -- 6.0439 bpw  accuracy: 0.99611438\n",
      " -- 6.3381 bpw  accuracy: 0.99803114\n",
      " -- 8.0439 bpw  accuracy: 0.99892964\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.25 (Attention)        |\n",
      "| Duration: 5.78 seconds                       |\n",
      "| Completed step: 51/67                        |\n",
      "| Avg time / step (rolling): 9.32 seconds      |\n",
      "| Estimated remaining time: 2min 29sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.25 (MLP)\n",
      " -- model.layers.25.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.25.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.25.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.25.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.25.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92111628\n",
      " -- 2.3230 bpw  accuracy: 0.92319796\n",
      " -- 2.5958 bpw  accuracy: 0.93376078\n",
      " -- 2.9120 bpw  accuracy: 0.93715281\n",
      " -- 3.2833 bpw  accuracy: 0.96004989\n",
      " -- 3.3655 bpw  accuracy: 0.96333145\n",
      " -- 3.6186 bpw  accuracy: 0.96777928\n",
      " -- 4.1368 bpw  accuracy: 0.97923880\n",
      " -- 4.1977 bpw  accuracy: 0.98116658\n",
      " -- 4.2662 bpw  accuracy: 0.97979046\n",
      " -- 4.3484 bpw  accuracy: 0.98238016\n",
      " -- 5.2491 bpw  accuracy: 0.99003785\n",
      " -- 5.3313 bpw  accuracy: 0.99139730\n",
      " -- 6.0713 bpw  accuracy: 0.99447108\n",
      " -- 6.3032 bpw  accuracy: 0.99485546\n",
      " -- 6.8687 bpw  accuracy: 0.99572035\n",
      " -- 8.0354 bpw  accuracy: 0.99848606\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.25 (MLP)              |\n",
      "| Duration: 12.04 seconds                      |\n",
      "| Completed step: 52/67                        |\n",
      "| Avg time / step (rolling): 9.24 seconds      |\n",
      "| Estimated remaining time: 2min 18sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.26 (Attention)\n",
      " -- model.layers.26.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96333847\n",
      " -- 2.1987 bpw  accuracy: 0.96426401\n",
      " -- 2.2831 bpw  accuracy: 0.96766436\n",
      " -- 2.6768 bpw  accuracy: 0.97352593\n",
      " -- 3.1689 bpw  accuracy: 0.97986360\n",
      " -- 3.1705 bpw  accuracy: 0.98142599\n",
      " -- 4.0439 bpw  accuracy: 0.98449494\n",
      " -- 4.0471 bpw  accuracy: 0.98672257\n",
      " -- 4.0816 bpw  accuracy: 0.98809792\n",
      " -- 4.1381 bpw  accuracy: 0.98881046\n",
      " -- 4.1705 bpw  accuracy: 0.99087299\n",
      " -- 4.1902 bpw  accuracy: 0.99147596\n",
      " -- 4.2737 bpw  accuracy: 0.99178204\n",
      " -- 4.3295 bpw  accuracy: 0.99277932\n",
      " -- 5.2564 bpw  accuracy: 0.99503712\n",
      " -- 5.3295 bpw  accuracy: 0.99636348\n",
      " -- 6.0439 bpw  accuracy: 0.99584840\n",
      " -- 6.3381 bpw  accuracy: 0.99805904\n",
      " -- 8.0439 bpw  accuracy: 0.99889781\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.26 (Attention)        |\n",
      "| Duration: 5.76 seconds                       |\n",
      "| Completed step: 53/67                        |\n",
      "| Avg time / step (rolling): 9.23 seconds      |\n",
      "| Estimated remaining time: 2min 9sec          |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.26 (MLP)\n",
      " -- model.layers.26.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.26.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.26.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.26.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.26.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92037343\n",
      " -- 2.3230 bpw  accuracy: 0.92244025\n",
      " -- 2.5958 bpw  accuracy: 0.93300834\n",
      " -- 2.9120 bpw  accuracy: 0.93637592\n",
      " -- 3.2833 bpw  accuracy: 0.95957681\n",
      " -- 3.3655 bpw  accuracy: 0.96293124\n",
      " -- 3.6186 bpw  accuracy: 0.96738544\n",
      " -- 4.1368 bpw  accuracy: 0.97904819\n",
      " -- 4.1977 bpw  accuracy: 0.98097499\n",
      " -- 4.2662 bpw  accuracy: 0.97954139\n",
      " -- 4.3484 bpw  accuracy: 0.98218508\n",
      " -- 5.2491 bpw  accuracy: 0.98991082\n",
      " -- 5.3313 bpw  accuracy: 0.99129856\n",
      " -- 6.0713 bpw  accuracy: 0.99439671\n",
      " -- 6.3032 bpw  accuracy: 0.99477318\n",
      " -- 6.8687 bpw  accuracy: 0.99563483\n",
      " -- 8.0354 bpw  accuracy: 0.99843047\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.26 (MLP)              |\n",
      "| Duration: 12.80 seconds                      |\n",
      "| Completed step: 54/67                        |\n",
      "| Avg time / step (rolling): 9.24 seconds      |\n",
      "| Estimated remaining time: 2min 0sec          |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.27 (Attention)\n",
      " -- model.layers.27.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96555536\n",
      " -- 2.1987 bpw  accuracy: 0.96686300\n",
      " -- 2.2831 bpw  accuracy: 0.97114633\n",
      " -- 2.6768 bpw  accuracy: 0.97699022\n",
      " -- 3.1689 bpw  accuracy: 0.98123793\n",
      " -- 3.1705 bpw  accuracy: 0.98212711\n",
      " -- 4.0439 bpw  accuracy: 0.98574868\n",
      " -- 4.0471 bpw  accuracy: 0.98674543\n",
      " -- 4.0816 bpw  accuracy: 0.98840399\n",
      " -- 4.1381 bpw  accuracy: 0.98898638\n",
      " -- 4.1705 bpw  accuracy: 0.99126714\n",
      " -- 4.1902 bpw  accuracy: 0.99198954\n",
      " -- 4.2737 bpw  accuracy: 0.99228035\n",
      " -- 4.3295 bpw  accuracy: 0.99297582\n",
      " -- 5.2564 bpw  accuracy: 0.99564781\n",
      " -- 5.3295 bpw  accuracy: 0.99641485\n",
      " -- 6.0439 bpw  accuracy: 0.99646760\n",
      " -- 6.3381 bpw  accuracy: 0.99803186\n",
      " -- 8.0439 bpw  accuracy: 0.99905271\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.27 (Attention)        |\n",
      "| Duration: 5.92 seconds                       |\n",
      "| Completed step: 55/67                        |\n",
      "| Avg time / step (rolling): 9.23 seconds      |\n",
      "| Estimated remaining time: 1min 50sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.27 (MLP)\n",
      " -- model.layers.27.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.27.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.27.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.27.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.27.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91986988\n",
      " -- 2.3230 bpw  accuracy: 0.92199698\n",
      " -- 2.5958 bpw  accuracy: 0.93245223\n",
      " -- 2.9120 bpw  accuracy: 0.93581743\n",
      " -- 3.2833 bpw  accuracy: 0.95925875\n",
      " -- 3.3655 bpw  accuracy: 0.96265621\n",
      " -- 3.6186 bpw  accuracy: 0.96705215\n",
      " -- 4.1368 bpw  accuracy: 0.97875987\n",
      " -- 4.1977 bpw  accuracy: 0.98074468\n",
      " -- 4.2662 bpw  accuracy: 0.97937268\n",
      " -- 4.3484 bpw  accuracy: 0.98203362\n",
      " -- 5.2491 bpw  accuracy: 0.98982061\n",
      " -- 5.3313 bpw  accuracy: 0.99122185\n",
      " -- 6.0713 bpw  accuracy: 0.99431668\n",
      " -- 6.3032 bpw  accuracy: 0.99473688\n",
      " -- 6.8687 bpw  accuracy: 0.99558895\n",
      " -- 8.0354 bpw  accuracy: 0.99841202\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.27 (MLP)              |\n",
      "| Duration: 12.80 seconds                      |\n",
      "| Completed step: 56/67                        |\n",
      "| Avg time / step (rolling): 9.24 seconds      |\n",
      "| Estimated remaining time: 1min 41sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.28 (Attention)\n",
      " -- model.layers.28.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95972289\n",
      " -- 2.1987 bpw  accuracy: 0.96134492\n",
      " -- 2.2831 bpw  accuracy: 0.96554037\n",
      " -- 2.6768 bpw  accuracy: 0.97319726\n",
      " -- 3.1689 bpw  accuracy: 0.97861891\n",
      " -- 3.1705 bpw  accuracy: 0.98005596\n",
      " -- 4.0439 bpw  accuracy: 0.98447061\n",
      " -- 4.0471 bpw  accuracy: 0.98642111\n",
      " -- 4.0816 bpw  accuracy: 0.98689076\n",
      " -- 4.1381 bpw  accuracy: 0.98726099\n",
      " -- 4.1705 bpw  accuracy: 0.98992688\n",
      " -- 4.1902 bpw  accuracy: 0.99042296\n",
      " -- 4.2737 bpw  accuracy: 0.99107626\n",
      " -- 4.3295 bpw  accuracy: 0.99190097\n",
      " -- 5.2564 bpw  accuracy: 0.99481183\n",
      " -- 5.3295 bpw  accuracy: 0.99591448\n",
      " -- 6.0439 bpw  accuracy: 0.99580114\n",
      " -- 6.3381 bpw  accuracy: 0.99780781\n",
      " -- 8.0439 bpw  accuracy: 0.99884698\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.28 (Attention)        |\n",
      "| Duration: 5.69 seconds                       |\n",
      "| Completed step: 57/67                        |\n",
      "| Avg time / step (rolling): 9.22 seconds      |\n",
      "| Estimated remaining time: 1min 32sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.28 (MLP)\n",
      " -- model.layers.28.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.28.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.28.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.28.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.28.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91845698\n",
      " -- 2.3230 bpw  accuracy: 0.92075707\n",
      " -- 2.5958 bpw  accuracy: 0.93126988\n",
      " -- 2.9120 bpw  accuracy: 0.93475785\n",
      " -- 3.2833 bpw  accuracy: 0.95856050\n",
      " -- 3.3655 bpw  accuracy: 0.96199768\n",
      " -- 3.6186 bpw  accuracy: 0.96649030\n",
      " -- 4.1368 bpw  accuracy: 0.97824584\n",
      " -- 4.1977 bpw  accuracy: 0.98027250\n",
      " -- 4.2662 bpw  accuracy: 0.97898990\n",
      " -- 4.3484 bpw  accuracy: 0.98169746\n",
      " -- 5.2491 bpw  accuracy: 0.98960856\n",
      " -- 5.3313 bpw  accuracy: 0.99104051\n",
      " -- 6.0713 bpw  accuracy: 0.99414085\n",
      " -- 6.3032 bpw  accuracy: 0.99462481\n",
      " -- 6.8687 bpw  accuracy: 0.99550142\n",
      " -- 8.0354 bpw  accuracy: 0.99833155\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.28 (MLP)              |\n",
      "| Duration: 12.70 seconds                      |\n",
      "| Completed step: 58/67                        |\n",
      "| Avg time / step (rolling): 9.22 seconds      |\n",
      "| Estimated remaining time: 1min 22sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.29 (Attention)\n",
      " -- model.layers.29.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.94897620\n",
      " -- 2.1987 bpw  accuracy: 0.95085821\n",
      " -- 2.2831 bpw  accuracy: 0.95756577\n",
      " -- 2.6768 bpw  accuracy: 0.96718951\n",
      " -- 3.1689 bpw  accuracy: 0.97318360\n",
      " -- 3.1705 bpw  accuracy: 0.97437471\n",
      " -- 4.0439 bpw  accuracy: 0.98134695\n",
      " -- 4.0471 bpw  accuracy: 0.98292909\n",
      " -- 4.0816 bpw  accuracy: 0.98415302\n",
      " -- 4.1381 bpw  accuracy: 0.98507702\n",
      " -- 4.1705 bpw  accuracy: 0.98704989\n",
      " -- 4.1902 bpw  accuracy: 0.98793295\n",
      " -- 4.2737 bpw  accuracy: 0.98888242\n",
      " -- 4.3295 bpw  accuracy: 0.98976325\n",
      " -- 5.2564 bpw  accuracy: 0.99377477\n",
      " -- 5.3295 bpw  accuracy: 0.99492875\n",
      " -- 6.0439 bpw  accuracy: 0.99512300\n",
      " -- 6.3381 bpw  accuracy: 0.99731003\n",
      " -- 8.0439 bpw  accuracy: 0.99867193\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.29 (Attention)        |\n",
      "| Duration: 5.93 seconds                       |\n",
      "| Completed step: 59/67                        |\n",
      "| Avg time / step (rolling): 9.21 seconds      |\n",
      "| Estimated remaining time: 1min 13sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.29 (MLP)\n",
      " -- model.layers.29.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.29.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.29.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.29.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.29.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91913785\n",
      " -- 2.3230 bpw  accuracy: 0.92140976\n",
      " -- 2.5958 bpw  accuracy: 0.93213210\n",
      " -- 2.9120 bpw  accuracy: 0.93564346\n",
      " -- 3.2833 bpw  accuracy: 0.95874750\n",
      " -- 3.3655 bpw  accuracy: 0.96214781\n",
      " -- 3.6186 bpw  accuracy: 0.96677834\n",
      " -- 4.1368 bpw  accuracy: 0.97815278\n",
      " -- 4.1977 bpw  accuracy: 0.98018117\n",
      " -- 4.2662 bpw  accuracy: 0.97894381\n",
      " -- 4.3484 bpw  accuracy: 0.98158823\n",
      " -- 5.2491 bpw  accuracy: 0.98955090\n",
      " -- 5.3313 bpw  accuracy: 0.99097047\n",
      " -- 6.0713 bpw  accuracy: 0.99412477\n",
      " -- 6.3032 bpw  accuracy: 0.99458047\n",
      " -- 6.8687 bpw  accuracy: 0.99547688\n",
      " -- 8.0354 bpw  accuracy: 0.99837629\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.29 (MLP)              |\n",
      "| Duration: 12.75 seconds                      |\n",
      "| Completed step: 60/67                        |\n",
      "| Avg time / step (rolling): 9.22 seconds      |\n",
      "| Estimated remaining time: 1min 4sec          |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.30 (Attention)\n",
      " -- model.layers.30.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.94146684\n",
      " -- 2.1987 bpw  accuracy: 0.94419815\n",
      " -- 2.2831 bpw  accuracy: 0.95822222\n",
      " -- 2.6768 bpw  accuracy: 0.96672404\n",
      " -- 3.1689 bpw  accuracy: 0.97465474\n",
      " -- 3.1705 bpw  accuracy: 0.97480124\n",
      " -- 4.0439 bpw  accuracy: 0.98155731\n",
      " -- 4.0471 bpw  accuracy: 0.98170579\n",
      " -- 4.0816 bpw  accuracy: 0.98361136\n",
      " -- 4.1381 bpw  accuracy: 0.98417219\n",
      " -- 4.1705 bpw  accuracy: 0.98683572\n",
      " -- 4.1902 bpw  accuracy: 0.98803740\n",
      " -- 4.2737 bpw  accuracy: 0.98855124\n",
      " -- 4.3295 bpw  accuracy: 0.98941839\n",
      " -- 5.2564 bpw  accuracy: 0.99361893\n",
      " -- 5.3295 bpw  accuracy: 0.99480477\n",
      " -- 6.0439 bpw  accuracy: 0.99473557\n",
      " -- 6.3381 bpw  accuracy: 0.99737068\n",
      " -- 8.0439 bpw  accuracy: 0.99862690\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.30 (Attention)        |\n",
      "| Duration: 5.92 seconds                       |\n",
      "| Completed step: 61/67                        |\n",
      "| Avg time / step (rolling): 9.23 seconds      |\n",
      "| Estimated remaining time: 0min 55sec         |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.30 (MLP)\n",
      " -- model.layers.30.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.30.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.30.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.30.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.30.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91472972\n",
      " -- 2.3230 bpw  accuracy: 0.91711473\n",
      " -- 2.5958 bpw  accuracy: 0.92846391\n",
      " -- 2.9120 bpw  accuracy: 0.93206091\n",
      " -- 3.2833 bpw  accuracy: 0.95626947\n",
      " -- 3.3655 bpw  accuracy: 0.96024659\n",
      " -- 3.6186 bpw  accuracy: 0.96510381\n",
      " -- 4.1368 bpw  accuracy: 0.97638618\n",
      " -- 4.1977 bpw  accuracy: 0.97897346\n",
      " -- 4.2662 bpw  accuracy: 0.97743694\n",
      " -- 4.3484 bpw  accuracy: 0.98048762\n",
      " -- 5.2491 bpw  accuracy: 0.98877867\n",
      " -- 5.3313 bpw  accuracy: 0.99038691\n",
      " -- 6.0713 bpw  accuracy: 0.99360403\n",
      " -- 6.3032 bpw  accuracy: 0.99418150\n",
      " -- 6.8687 bpw  accuracy: 0.99523066\n",
      " -- 8.0354 bpw  accuracy: 0.99820796\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.30 (MLP)              |\n",
      "| Duration: 12.78 seconds                      |\n",
      "| Completed step: 62/67                        |\n",
      "| Avg time / step (rolling): 9.31 seconds      |\n",
      "| Estimated remaining time: 0min 46sec         |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.31 (Attention)\n",
      " -- model.layers.31.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.94782040\n",
      " -- 2.1987 bpw  accuracy: 0.95012182\n",
      " -- 2.2831 bpw  accuracy: 0.95811732\n",
      " -- 2.6768 bpw  accuracy: 0.97078655\n",
      " -- 3.1689 bpw  accuracy: 0.97550684\n",
      " -- 3.1705 bpw  accuracy: 0.97619781\n",
      " -- 4.0439 bpw  accuracy: 0.98470939\n",
      " -- 4.0471 bpw  accuracy: 0.98564224\n",
      " -- 4.0816 bpw  accuracy: 0.98676206\n",
      " -- 4.1381 bpw  accuracy: 0.98750962\n",
      " -- 4.1705 bpw  accuracy: 0.98804094\n",
      " -- 4.1902 bpw  accuracy: 0.98891258\n",
      " -- 4.2737 bpw  accuracy: 0.99003909\n",
      " -- 4.3295 bpw  accuracy: 0.99089276\n",
      " -- 5.2564 bpw  accuracy: 0.99456646\n",
      " -- 5.3295 bpw  accuracy: 0.99536205\n",
      " -- 6.0439 bpw  accuracy: 0.99608141\n",
      " -- 6.3381 bpw  accuracy: 0.99745699\n",
      " -- 8.0439 bpw  accuracy: 0.99884772\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.31 (Attention)        |\n",
      "| Duration: 5.71 seconds                       |\n",
      "| Completed step: 63/67                        |\n",
      "| Avg time / step (rolling): 9.30 seconds      |\n",
      "| Estimated remaining time: 0min 37sec         |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.31 (MLP)\n",
      " -- model.layers.31.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.31.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.31.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.31.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.31.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91001290\n",
      " -- 2.3230 bpw  accuracy: 0.91211988\n",
      " -- 2.5958 bpw  accuracy: 0.92283902\n",
      " -- 2.9120 bpw  accuracy: 0.92625981\n",
      " -- 3.2833 bpw  accuracy: 0.95342890\n",
      " -- 3.3655 bpw  accuracy: 0.95781184\n",
      " -- 3.6186 bpw  accuracy: 0.96245943\n",
      " -- 4.1368 bpw  accuracy: 0.97548390\n",
      " -- 4.1977 bpw  accuracy: 0.97812002\n",
      " -- 4.2662 bpw  accuracy: 0.97617663\n",
      " -- 4.3484 bpw  accuracy: 0.97950618\n",
      " -- 5.2491 bpw  accuracy: 0.98805109\n",
      " -- 5.3313 bpw  accuracy: 0.98988145\n",
      " -- 6.0713 bpw  accuracy: 0.99317782\n",
      " -- 6.3032 bpw  accuracy: 0.99382584\n",
      " -- 6.8687 bpw  accuracy: 0.99486041\n",
      " -- 8.0354 bpw  accuracy: 0.99798540\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.31 (MLP)              |\n",
      "| Duration: 12.74 seconds                      |\n",
      "| Completed step: 64/67                        |\n",
      "| Avg time / step (rolling): 9.30 seconds      |\n",
      "| Estimated remaining time: 0min 27sec         |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.norm (RMSNorm)\n",
      "------------------------------------------------\n",
      "| Measured: model.norm (RMSNorm)               |\n",
      "| Duration: 0.07 seconds                       |\n",
      "| Completed step: 65/67                        |\n",
      "| Avg time / step (rolling): 8.71 seconds      |\n",
      "| Estimated remaining time: 0min 17sec         |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: lm_head (Linear)\n",
      "------------------------------------------------\n",
      "| Measured: lm_head (Linear)                   |\n",
      "| Duration: 1.23 seconds                       |\n",
      "| Completed step: 66/67                        |\n",
      "| Avg time / step (rolling): 7.55 seconds      |\n",
      "| Estimated remaining time: 0min 7sec          |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Optimizing...\n",
      " -- Pruning...\n",
      " -- Solving...\n",
      " -- Score: 0.99995178  bpw: 6.5000\n",
      " -- Score: 0.99995210  bpw: 6.4989\n",
      " -- Score: 0.99995258  bpw: 6.4996\n",
      " -- Score: 0.99995277  bpw: 6.4987\n",
      " -- Score: 0.99995283  bpw: 6.4963\n",
      " -- Score: 0.99995356  bpw: 6.4998\n",
      " -- Score: 0.99995357  bpw: 6.4991\n",
      " -- Score: 0.99995361  bpw: 6.4974\n",
      " -- Score: 0.99995371  bpw: 6.4965\n",
      " -- Score: 0.99995373  bpw: 6.4982\n",
      " -- Score: 0.99995403  bpw: 6.4989\n",
      " -- Score: 0.99995409  bpw: 6.4996\n",
      " -- Quantization strategy:\n",
      " --   model.layers.0.self_attn                           6.3381 bpw - exp. error: 0.00525972\n",
      " --   model.layers.0.mlp                                 6.0713 bpw - exp. error: 0.00491576\n",
      " --   model.layers.1.self_attn                           6.3381 bpw - exp. error: 0.00487221\n",
      " --   model.layers.1.mlp                                 4.3484 bpw - exp. error: 0.00178613\n",
      " --   model.layers.2.self_attn                           4.3295 bpw - exp. error: 0.00136107\n",
      " --   model.layers.2.mlp                                 3.6186 bpw - exp. error: 0.00315161\n",
      " --   model.layers.3.self_attn                           4.1902 bpw - exp. error: 0.00198086\n",
      " --   model.layers.3.mlp                                 4.1977 bpw - exp. error: 0.00278732\n",
      " --   model.layers.4.self_attn                           4.3295 bpw - exp. error: 0.00203113\n",
      " --   model.layers.4.mlp                                 4.3484 bpw - exp. error: 0.00364462\n",
      " --   model.layers.5.self_attn                           4.3295 bpw - exp. error: 0.00261529\n",
      " --   model.layers.5.mlp                                 5.3313 bpw - exp. error: 0.00234796\n",
      " --   model.layers.6.self_attn                           5.3295 bpw - exp. error: 0.00144770\n",
      " --   model.layers.6.mlp                                 5.3313 bpw - exp. error: 0.00278495\n",
      " --   model.layers.7.self_attn                           6.3381 bpw - exp. error: 0.00100471\n",
      " --   model.layers.7.mlp                                 5.3313 bpw - exp. error: 0.00325326\n",
      " --   model.layers.8.self_attn                           6.3381 bpw - exp. error: 0.00107191\n",
      " --   model.layers.8.mlp                                 5.3313 bpw - exp. error: 0.00358449\n",
      " --   model.layers.9.self_attn                           6.3381 bpw - exp. error: 0.00129799\n",
      " --   model.layers.9.mlp                                 5.3313 bpw - exp. error: 0.00395380\n",
      " --   model.layers.10.self_attn                          6.3381 bpw - exp. error: 0.00144923\n",
      " --   model.layers.10.mlp                                6.0713 bpw - exp. error: 0.00271765\n",
      " --   model.layers.11.self_attn                          6.3381 bpw - exp. error: 0.00184081\n",
      " --   model.layers.11.mlp                                6.0713 bpw - exp. error: 0.00292364\n",
      " --   model.layers.12.self_attn                          6.3381 bpw - exp. error: 0.00201051\n",
      " --   model.layers.12.mlp                                6.0713 bpw - exp. error: 0.00325756\n",
      " --   model.layers.13.self_attn                          6.3381 bpw - exp. error: 0.00203525\n",
      " --   model.layers.13.mlp                                6.0713 bpw - exp. error: 0.00357215\n",
      " --   model.layers.14.self_attn                          6.3381 bpw - exp. error: 0.00222897\n",
      " --   model.layers.14.mlp                                6.3032 bpw - exp. error: 0.00358611\n",
      " --   model.layers.15.self_attn                          6.3381 bpw - exp. error: 0.00255073\n",
      " --   model.layers.15.mlp                                6.3032 bpw - exp. error: 0.00385175\n",
      " --   model.layers.16.self_attn                          6.3381 bpw - exp. error: 0.00239822\n",
      " --   model.layers.16.mlp                                6.8687 bpw - exp. error: 0.00337340\n",
      " --   model.layers.17.self_attn                          6.3381 bpw - exp. error: 0.00257269\n",
      " --   model.layers.17.mlp                                6.8687 bpw - exp. error: 0.00375475\n",
      " --   model.layers.18.self_attn                          6.3381 bpw - exp. error: 0.00254800\n",
      " --   model.layers.18.mlp                                8.0354 bpw - exp. error: 0.00154276\n",
      " --   model.layers.19.self_attn                          6.3381 bpw - exp. error: 0.00262827\n",
      " --   model.layers.19.mlp                                8.0354 bpw - exp. error: 0.00162666\n",
      " --   model.layers.20.self_attn                          6.3381 bpw - exp. error: 0.00259297\n",
      " --   model.layers.20.mlp                                8.0354 bpw - exp. error: 0.00155239\n",
      " --   model.layers.21.self_attn                          6.3381 bpw - exp. error: 0.00207743\n",
      " --   model.layers.21.mlp                                8.0354 bpw - exp. error: 0.00151750\n",
      " --   model.layers.22.self_attn                          5.3295 bpw - exp. error: 0.00355920\n",
      " --   model.layers.22.mlp                                8.0354 bpw - exp. error: 0.00150977\n",
      " --   model.layers.23.self_attn                          6.3381 bpw - exp. error: 0.00186692\n",
      " --   model.layers.23.mlp                                8.0354 bpw - exp. error: 0.00150202\n",
      " --   model.layers.24.self_attn                          5.3295 bpw - exp. error: 0.00353715\n",
      " --   model.layers.24.mlp                                8.0354 bpw - exp. error: 0.00151945\n",
      " --   model.layers.25.self_attn                          5.3295 bpw - exp. error: 0.00362591\n",
      " --   model.layers.25.mlp                                8.0354 bpw - exp. error: 0.00151394\n",
      " --   model.layers.26.self_attn                          5.3295 bpw - exp. error: 0.00363652\n",
      " --   model.layers.26.mlp                                8.0354 bpw - exp. error: 0.00156953\n",
      " --   model.layers.27.self_attn                          6.3381 bpw - exp. error: 0.00196814\n",
      " --   model.layers.27.mlp                                8.0354 bpw - exp. error: 0.00158798\n",
      " --   model.layers.28.self_attn                          6.3381 bpw - exp. error: 0.00219219\n",
      " --   model.layers.28.mlp                                8.0354 bpw - exp. error: 0.00166845\n",
      " --   model.layers.29.self_attn                          6.3381 bpw - exp. error: 0.00268997\n",
      " --   model.layers.29.mlp                                8.0354 bpw - exp. error: 0.00162371\n",
      " --   model.layers.30.self_attn                          6.3381 bpw - exp. error: 0.00262932\n",
      " --   model.layers.30.mlp                                8.0354 bpw - exp. error: 0.00179204\n",
      " --   model.layers.31.self_attn                          6.3381 bpw - exp. error: 0.00254301\n",
      " --   model.layers.31.mlp                                8.0354 bpw - exp. error: 0.00201460\n",
      " -- Tokenizing samples...\n",
      " -- First 50 tokens of dataset:\n",
      "    ' = Robert Boulter = \\n  Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed'\n",
      " -- Last 50 tokens of dataset:\n",
      "    '] more meaningful lives \" . The film argues the case against conformity , but does not deny that people need and want it ; even the gay characters just want to fit in . Jim and Jim , the Burnhams \\' other neighbors , are'\n",
      " -- Token embeddings again...\n",
      " -- Quantizing...\n",
      " -- Layer: model.layers.0 (Attention)\n",
      " -- Linear: model.layers.0.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.0.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.0.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.0.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.027653\n",
      " -- Layer: model.layers.0 (MLP)\n",
      " -- Linear: model.layers.0.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.0.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.0.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.006816\n",
      " -- Layer: model.layers.1 (Attention)\n",
      " -- Linear: model.layers.1.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.1.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.1.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.1.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.015008\n",
      " -- Layer: model.layers.1 (MLP)\n",
      " -- Linear: model.layers.1.mlp.gate_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.1.mlp.up_proj -> 0.25:5b_32g/0.75:4b_32g s4, 4.38 bpw\n",
      " -- Linear: model.layers.1.mlp.down_proj -> 0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4, 4.44 bpw\n",
      " -- Module quantized, rfn_error: 0.002743\n",
      " -- Layer: model.layers.2 (Attention)\n",
      " -- Linear: model.layers.2.self_attn.q_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.2.self_attn.k_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.2.self_attn.v_proj -> 1:5b_32g s4, 5.16 bpw\n",
      " -- Linear: model.layers.2.self_attn.o_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Module quantized, rfn_error: 0.001408\n",
      " -- Layer: model.layers.2 (MLP)\n",
      " -- Linear: model.layers.2.mlp.gate_proj -> 0.1:4b_32g/0.9:3b_32g s4, 3.23 bpw\n",
      " -- Linear: model.layers.2.mlp.up_proj -> 0.25:4b_32g/0.75:3b_32g s4, 3.38 bpw\n",
      " -- Linear: model.layers.2.mlp.down_proj -> 0.05:8b_32g/0.95:4b_128g s4, 4.25 bpw\n",
      " -- Module quantized, rfn_error: 0.003677\n",
      " -- Layer: model.layers.3 (Attention)\n",
      " -- Linear: model.layers.3.self_attn.q_proj -> 0.1:5b_64g/0.9:4b_64g s4, 4.18 bpw\n",
      " -- Linear: model.layers.3.self_attn.k_proj -> 0.1:5b_64g/0.9:4b_64g s4, 4.20 bpw\n",
      " -- Linear: model.layers.3.self_attn.v_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.3.self_attn.o_proj -> 0.1:5b_64g/0.9:4b_64g s4, 4.18 bpw\n",
      " -- Module quantized, rfn_error: 0.002096\n",
      " -- Layer: model.layers.3 (MLP)\n",
      " -- Linear: model.layers.3.mlp.gate_proj -> 1:4b_32g s4, 4.13 bpw\n",
      " -- Linear: model.layers.3.mlp.up_proj -> 1:4b_32g s4, 4.13 bpw\n",
      " -- Linear: model.layers.3.mlp.down_proj -> 0.05:8b_32g/0.95:4b_32g s4, 4.34 bpw\n",
      " -- Module quantized, rfn_error: 0.003348\n",
      " -- Layer: model.layers.4 (Attention)\n",
      " -- Linear: model.layers.4.self_attn.q_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.4.self_attn.k_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.4.self_attn.v_proj -> 1:5b_32g s4, 5.16 bpw\n",
      " -- Linear: model.layers.4.self_attn.o_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Module quantized, rfn_error: 0.002220\n",
      " -- Layer: model.layers.4 (MLP)\n",
      " -- Linear: model.layers.4.mlp.gate_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.4.mlp.up_proj -> 0.25:5b_32g/0.75:4b_32g s4, 4.38 bpw\n",
      " -- Linear: model.layers.4.mlp.down_proj -> 0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4, 4.44 bpw\n",
      " -- Module quantized, rfn_error: 0.004273\n",
      " -- Layer: model.layers.5 (Attention)\n",
      " -- Linear: model.layers.5.self_attn.q_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.5.self_attn.k_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.5.self_attn.v_proj -> 1:5b_32g s4, 5.16 bpw\n",
      " -- Linear: model.layers.5.self_attn.o_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Module quantized, rfn_error: 0.002918\n",
      " -- Layer: model.layers.5 (MLP)\n",
      " -- Linear: model.layers.5.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.5.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.5.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.002799\n",
      " -- Layer: model.layers.6 (Attention)\n",
      " -- Linear: model.layers.6.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.6.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.6.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.6.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.001767\n",
      " -- Layer: model.layers.6 (MLP)\n",
      " -- Linear: model.layers.6.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.6.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.6.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.003306\n",
      " -- Layer: model.layers.7 (Attention)\n",
      " -- Linear: model.layers.7.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.7.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.7.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.7.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.002479\n",
      " -- Layer: model.layers.7 (MLP)\n",
      " -- Linear: model.layers.7.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.7.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.7.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.003875\n",
      " -- Layer: model.layers.8 (Attention)\n",
      " -- Linear: model.layers.8.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.8.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.8.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.8.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.001963\n",
      " -- Layer: model.layers.8 (MLP)\n",
      " -- Linear: model.layers.8.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.8.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.8.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.004279\n",
      " -- Layer: model.layers.9 (Attention)\n",
      " -- Linear: model.layers.9.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.9.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.9.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.9.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003370\n",
      " -- Layer: model.layers.9 (MLP)\n",
      " -- Linear: model.layers.9.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.9.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.9.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.004738\n",
      " -- Layer: model.layers.10 (Attention)\n",
      " -- Linear: model.layers.10.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.10.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.10.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.10.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.002826\n",
      " -- Layer: model.layers.10 (MLP)\n",
      " -- Linear: model.layers.10.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.10.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.10.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.003336\n",
      " -- Layer: model.layers.11 (Attention)\n",
      " -- Linear: model.layers.11.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.11.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.11.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.11.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003209\n",
      " -- Layer: model.layers.11 (MLP)\n",
      " -- Linear: model.layers.11.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.11.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.11.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.003559\n",
      " -- Layer: model.layers.12 (Attention)\n",
      " -- Linear: model.layers.12.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.12.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.12.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.12.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004134\n",
      " -- Layer: model.layers.12 (MLP)\n",
      " -- Linear: model.layers.12.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.12.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.12.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.003974\n",
      " -- Layer: model.layers.13 (Attention)\n",
      " -- Linear: model.layers.13.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.13.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.13.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.13.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003934\n",
      " -- Layer: model.layers.13 (MLP)\n",
      " -- Linear: model.layers.13.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.13.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.13.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.004355\n",
      " -- Layer: model.layers.14 (Attention)\n",
      " -- Linear: model.layers.14.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.14.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.14.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.14.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004130\n",
      " -- Layer: model.layers.14 (MLP)\n",
      " -- Linear: model.layers.14.mlp.gate_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.14.mlp.up_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.14.mlp.down_proj -> 0.15:8b_128g/0.85:6b_128g s4, 6.34 bpw\n",
      " -- Module quantized, rfn_error: 0.004400\n",
      " -- Layer: model.layers.15 (Attention)\n",
      " -- Linear: model.layers.15.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.15.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.15.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.15.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004328\n",
      " -- Layer: model.layers.15 (MLP)\n",
      " -- Linear: model.layers.15.mlp.gate_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.15.mlp.up_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.15.mlp.down_proj -> 0.15:8b_128g/0.85:6b_128g s4, 6.34 bpw\n",
      " -- Module quantized, rfn_error: 0.005054\n",
      " -- Layer: model.layers.16 (Attention)\n",
      " -- Linear: model.layers.16.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.16.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.16.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.16.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004939\n",
      " -- Layer: model.layers.16 (MLP)\n",
      " -- Linear: model.layers.16.mlp.gate_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.16.mlp.up_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.16.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.005432\n",
      " -- Layer: model.layers.17 (Attention)\n",
      " -- Linear: model.layers.17.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.17.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.17.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.17.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004799\n",
      " -- Layer: model.layers.17 (MLP)\n",
      " -- Linear: model.layers.17.mlp.gate_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.17.mlp.up_proj -> 0.1:8b_128g/0.9:6b_128g s4, 6.28 bpw\n",
      " -- Linear: model.layers.17.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.005638\n",
      " -- Layer: model.layers.18 (Attention)\n",
      " -- Linear: model.layers.18.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.18.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.18.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.18.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.005148\n",
      " -- Layer: model.layers.18 (MLP)\n",
      " -- Linear: model.layers.18.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.18.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.18.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.006527\n",
      " -- Layer: model.layers.19 (Attention)\n",
      " -- Linear: model.layers.19.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.19.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.19.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.19.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004709\n",
      " -- Layer: model.layers.19 (MLP)\n",
      " -- Linear: model.layers.19.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.19.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.19.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.005822\n",
      " -- Layer: model.layers.20 (Attention)\n",
      " -- Linear: model.layers.20.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.20.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.20.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.20.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004320\n",
      " -- Layer: model.layers.20 (MLP)\n",
      " -- Linear: model.layers.20.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.20.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.20.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.007207\n",
      " -- Layer: model.layers.21 (Attention)\n",
      " -- Linear: model.layers.21.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.21.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.21.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.21.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003842\n",
      " -- Layer: model.layers.21 (MLP)\n",
      " -- Linear: model.layers.21.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.21.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.21.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.007758\n",
      " -- Layer: model.layers.22 (Attention)\n",
      " -- Linear: model.layers.22.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.22.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.22.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.22.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004256\n",
      " -- Layer: model.layers.22 (MLP)\n",
      " -- Linear: model.layers.22.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.22.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.22.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.007699\n",
      " -- Layer: model.layers.23 (Attention)\n",
      " -- Linear: model.layers.23.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.23.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.23.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.23.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003595\n",
      " -- Layer: model.layers.23 (MLP)\n",
      " -- Linear: model.layers.23.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.23.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.23.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.007360\n",
      " -- Layer: model.layers.24 (Attention)\n",
      " -- Linear: model.layers.24.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.24.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.24.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.24.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004098\n",
      " -- Layer: model.layers.24 (MLP)\n",
      " -- Linear: model.layers.24.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.24.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.24.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.007815\n",
      " -- Layer: model.layers.25 (Attention)\n",
      " -- Linear: model.layers.25.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.25.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.25.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.25.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004140\n",
      " -- Layer: model.layers.25 (MLP)\n",
      " -- Linear: model.layers.25.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.25.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.25.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.007796\n",
      " -- Layer: model.layers.26 (Attention)\n",
      " -- Linear: model.layers.26.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.26.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.26.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.26.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004182\n",
      " -- Layer: model.layers.26 (MLP)\n",
      " -- Linear: model.layers.26.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.26.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.26.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.008253\n",
      " -- Layer: model.layers.27 (Attention)\n",
      " -- Linear: model.layers.27.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.27.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.27.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.27.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003275\n",
      " -- Layer: model.layers.27 (MLP)\n",
      " -- Linear: model.layers.27.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.27.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.27.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.007665\n",
      " -- Layer: model.layers.28 (Attention)\n",
      " -- Linear: model.layers.28.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.28.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.28.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.28.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003482\n",
      " -- Layer: model.layers.28 (MLP)\n",
      " -- Linear: model.layers.28.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.28.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.28.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.007698\n",
      " -- Layer: model.layers.29 (Attention)\n",
      " -- Linear: model.layers.29.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.29.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.29.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.29.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004072\n",
      " -- Layer: model.layers.29 (MLP)\n",
      " -- Linear: model.layers.29.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.29.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.29.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.006218\n",
      " -- Layer: model.layers.30 (Attention)\n",
      " -- Linear: model.layers.30.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.30.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.30.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.30.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003857\n",
      " -- Layer: model.layers.30 (MLP)\n",
      " -- Linear: model.layers.30.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.30.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.30.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.004289\n",
      " -- Layer: model.layers.31 (Attention)\n",
      " -- Linear: model.layers.31.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.31.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.31.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.31.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004690\n",
      " -- Layer: model.layers.31 (MLP)\n",
      " -- Linear: model.layers.31.mlp.gate_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.31.mlp.up_proj -> 1:8b_128g s4, 8.03 bpw\n",
      " -- Linear: model.layers.31.mlp.down_proj -> 1:8b_128g s4, 8.04 bpw\n",
      " -- Module quantized, rfn_error: 0.006216\n",
      " -- Layer: model.norm (RMSNorm)\n",
      " -- Module quantized, rfn_error: 0.000000\n",
      " -- Layer: lm_head (Linear)\n",
      " -- Linear: lm_head -> 0.15:8b_128g/0.85:6b_128g s4, 6.34 bpw\n",
      " -- Module quantized, calibration perplexity (quant): 5.6120\n",
      " -- Compiling output file...\n",
      " -- Writing shard 1...\n",
      " --   mistral-7b-alpaca-6.5bpw-exl2/output.safetensors (5,757 MB)\n",
      " -- Finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download dataset\n",
    "!wget https://huggingface.co/datasets/wikitext/resolve/9a9e482b5987f9d25b3a9b2883fc6cc9fd8071b3/wikitext-103-v1/wikitext-test.parquet\n",
    "\n",
    "model_name = str(model_id.value).split('/')\n",
    "new_model_name = str(new_model_id.value).split('/')\n",
    "command = f\"mkdir {new_model_name[1]}-{bpw.value}bpw-exl2\"\n",
    "os.system(command)\n",
    "\n",
    "quant = f\"{new_model_name[1]}-{bpw.value}bpw-exl2\"\n",
    "command = f\"python exllamav2/convert.py -i {model_name[1]} -o {quant} -c wikitext-test.parquet -b {bpw.value}\"\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending incremental file list\n",
      "./\n",
      "README.md\n",
      "config.json\n",
      "generation_config.json\n",
      "model.safetensors.index.json\n",
      "special_tokens_map.json\n",
      "tokenizer.json\n",
      "tokenizer.model\n",
      "tokenizer_config.json\n",
      "\n",
      "sent 2,316,995 bytes  received 171 bytes  4,634,332.00 bytes/sec\n",
      "total size is 2,315,800  speedup is 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup and copy files\n",
    "command = f\"rm -rf {quant}/out_tensor\"\n",
    "os.system(command)\n",
    "\n",
    "command = f\"rsync -av --exclude='*.safetensors' --exclude='.*' ./{model_name[1]}/ ./{quant}/\"\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create HF model card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import ModelCard\n",
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d5aecac2ee4b2ebf5a962f4d110e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='apache-2.0', description='License', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "license = widgets.Text(\n",
    "    value=\"apache-2.0\",\n",
    "    description='License',\n",
    "    disabled=False\n",
    ")\n",
    "license.style.description_width = 'initial'\n",
    "display(license)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the jinja template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_text = \"\"\"\n",
    "---\n",
    "license: {{ license }}\n",
    "---\n",
    "\n",
    "# {{ new_model_id }}\n",
    "\n",
    "An EXL2 {{ bpw }}bpw quantised version of [{{ model_id }}]({{ model_url }}).\n",
    "\n",
    "An incomplete list of clients and libraries that are known to support EXL2:\n",
    "* [text-generation-webui](https://github.com/oobabooga/text-generation-webui), the most widely used web UI, with many features and powerful extensions. Supports GPU acceleration.\n",
    "* [exllamav2](https://github.com/turboderp/exllamav2), an inference library for running local LLMs on modern consumer GPUs.\n",
    "\"\"\"\n",
    "\n",
    "    # Create a Jinja template object\n",
    "jinja_template = Template(template_text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the template\n",
    "content = jinja_template.render(\n",
    "          license = license.value,\n",
    "          new_model_id = new_model_id.value,\n",
    "          bpw = bpw.value,\n",
    "          model_id = model_id.value,\n",
    "          model_url = \"https://huggingface.co/\" + model_id.value,\n",
    "          )\n",
    "\n",
    "# Save the model card\n",
    "card = ModelCard(content)\n",
    "card.save(f\"{quant}/README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205edf81bb8f4a21ae5e35534bb794a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cal_data.safetensors:   0%|          | 0.00/1.64M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92166d21ae64aa78ff59af732114497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfb2c4d2fc8459bbfefae70f4ae8faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hidden_states.safetensors:   0%|          | 0.00/1.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c298602b9bbe4eb8b706edc9a1a995f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "output.safetensors:   0%|          | 0.00/6.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac0f82d541b4e1996fa44cb7484cf68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/CorticalStack/mistral-7b-alpaca-6.5bpw-exl2/commit/490c5284101128057b30ac1cb50e75c7bf2b5722', commit_message='Upload folder using huggingface_hub', commit_description='', oid='490c5284101128057b30ac1cb50e75c7bf2b5722', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty repo\n",
    "api = HfApi()\n",
    "create_repo(\n",
    "    repo_id = f\"CorticalStack/{quant}\",\n",
    "    repo_type=\"model\",\n",
    "    exist_ok=True,\n",
    "    token=HF_TOKEN\n",
    ")\n",
    "\n",
    "# Upload exl2 files\n",
    "api.upload_folder(\n",
    "    folder_path=quant,\n",
    "    repo_id=f\"CorticalStack/{quant}\",\n",
    "    token=HF_TOKEN\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaiplayground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
