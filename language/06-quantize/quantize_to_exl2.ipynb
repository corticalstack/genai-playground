{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from huggingface_hub import HfApi, create_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables like HuggingFace token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # take environment variables from .env.\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify source model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed90592360f442387780d8916385327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='CorticalStack/travel-mistral-7B-16b-base', description='Model ID')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = widgets.Text(\n",
    "    value='CorticalStack/travel-mistral-7B-16b-base',\n",
    "    description='Model ID',\n",
    "    disabled=False\n",
    ")\n",
    "display(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the source model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = str(model_id.value).split('/')\n",
    "if not os.path.isdir(model_name[1]):\n",
    "    !git clone https://huggingface.co/{model_id.value}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set target model name prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f89bfa63fc4478b017f60545c17fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='travel-mistral-7B', description='Model name preix')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_name_prefix = widgets.Text(\n",
    "    value='travel-mistral-7B',\n",
    "    description='Model name preix',\n",
    "    disabled=False\n",
    ")\n",
    "display(model_name_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push to HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7542c6c39207411790d57115bf680e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "travel-mistral-7B.Q4_K_M.gguf:   0%|          | 0.00/4.37G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/CorticalStack/travel-mistral-7B.Q4_K_M.gguf/commit/bb0c76ecffae389fd4b19dccba4e56611dd99955', commit_message='Upload travel-mistral-7B.Q4_K_M.gguf with huggingface_hub', commit_description='', oid='bb0c76ecffae389fd4b19dccba4e56611dd99955', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "api = HfApi()\n",
    "\n",
    "model_id = f\"CorticalStack/{quant_target_name}\"\n",
    "api.create_repo(model_id, exist_ok=True, repo_type=\"model\", token=HF_TOKEN)\n",
    "api.upload_file(\n",
    "    path_or_fileobj=f\"{quant_target_name}\",\n",
    "    path_in_repo=f\"{quant_target_name}\",\n",
    "    repo_id=model_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the EXL2 quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-11 20:29:51--  https://huggingface.co/datasets/wikitext/resolve/9a9e482b5987f9d25b3a9b2883fc6cc9fd8071b3/wikitext-103-v1/wikitext-test.parquet\n",
      "Resolving huggingface.co (huggingface.co)... 108.138.189.57, 108.138.189.96, 108.138.189.70, ...\n",
      "Connecting to huggingface.co (huggingface.co)|108.138.189.57|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 721735 (705K)\n",
      "Saving to: ‘wikitext-test.parquet.26’\n",
      "\n",
      "wikitext-test.parqu 100%[===================>] 704.82K  3.30MB/s    in 0.2s    \n",
      "\n",
      "2024-02-11 20:29:51 (3.30 MB/s) - ‘wikitext-test.parquet.26’ saved [721735/721735]\n",
      "\n",
      " -- Beginning new job\n",
      " -- Input: travel-mistral-7B-16b-base\n",
      " -- Output: travel-mistral-7B-EXL2\n",
      " -- Calibration dataset: wikitext-test.parquet, 100 / 16 rows, 2048 tokens per sample\n",
      " -- Target bits per weight: 5.0 (decoder), 6 (head)\n",
      " -- Max shard size: 8192 MB\n",
      " -- Tokenizing samples (measurement)...\n",
      " -- First 50 tokens of dataset:\n",
      "    ' = Robert Boulter = \\n  Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed'\n",
      " -- Last 50 tokens of dataset:\n",
      "    'Changnyong @-@ Yongsan road and cut the division in two ; the 38th and 23d Infantry Regiments with the bulk of the division artillery in the north were separated from the division headquarters and the'\n",
      " -- Token embeddings (measurement)...\n",
      " -- Measuring quantization impact...\n",
      " -- Layer: model.layers.0 (Attention)\n",
      " -- model.layers.0.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.0.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.0.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.0.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.0.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.90517981\n",
      " -- 2.1987 bpw  accuracy: 0.92251024\n",
      " -- 2.2831 bpw  accuracy: 0.92649829\n",
      " -- 2.6768 bpw  accuracy: 0.95689189\n",
      " -- 3.1689 bpw  accuracy: 0.95743808\n",
      " -- 3.1705 bpw  accuracy: 0.95797798\n",
      " -- 4.0439 bpw  accuracy: 0.96912694\n",
      " -- 4.0471 bpw  accuracy: 0.97036511\n",
      " -- 4.0816 bpw  accuracy: 0.97344733\n",
      " -- 4.1381 bpw  accuracy: 0.97521414\n",
      " -- 4.1705 bpw  accuracy: 0.97887932\n",
      " -- 4.1902 bpw  accuracy: 0.98021192\n",
      " -- 4.2737 bpw  accuracy: 0.98108521\n",
      " -- 4.3295 bpw  accuracy: 0.98285895\n",
      " -- 5.2564 bpw  accuracy: 0.98966865\n",
      " -- 5.3295 bpw  accuracy: 0.99142653\n",
      " -- 6.0439 bpw  accuracy: 0.99196855\n",
      " -- 6.3381 bpw  accuracy: 0.99464616\n",
      " -- 8.0439 bpw  accuracy: 0.99779824\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.0 (Attention)    |\n",
      "| Duration: 6.67 seconds                  |\n",
      "| Completed step: 1/67                    |\n",
      "| Avg time / step (rolling): 6.67 seconds |\n",
      "| Estimated remaining time: 7min 20sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.0 (MLP)\n",
      " -- model.layers.0.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.0.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.0.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.0.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.0.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.0.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.0.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.0.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.90602355\n",
      " -- 2.3230 bpw  accuracy: 0.91395228\n",
      " -- 2.5958 bpw  accuracy: 0.92520089\n",
      " -- 2.9120 bpw  accuracy: 0.92915683\n",
      " -- 3.2833 bpw  accuracy: 0.96408941\n",
      " -- 3.3655 bpw  accuracy: 0.96829897\n",
      " -- 3.6186 bpw  accuracy: 0.97508959\n",
      " -- 4.1368 bpw  accuracy: 0.98145075\n",
      " -- 4.1977 bpw  accuracy: 0.98337845\n",
      " -- 4.2662 bpw  accuracy: 0.98267705\n",
      " -- 4.3484 bpw  accuracy: 0.98474469\n",
      " -- 5.2491 bpw  accuracy: 0.99122415\n",
      " -- 5.3313 bpw  accuracy: 0.99259732\n",
      " -- 6.0713 bpw  accuracy: 0.99508407\n",
      " -- 6.3032 bpw  accuracy: 0.99552202\n",
      " -- 6.8687 bpw  accuracy: 0.99699980\n",
      " -- 8.0354 bpw  accuracy: 0.99856481\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.0 (MLP)          |\n",
      "| Duration: 11.50 seconds                 |\n",
      "| Completed step: 2/67                    |\n",
      "| Avg time / step (rolling): 9.09 seconds |\n",
      "| Estimated remaining time: 9min 50sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.1 (Attention)\n",
      " -- model.layers.1.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.1.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.1.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.1.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.1.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.90063301\n",
      " -- 2.1987 bpw  accuracy: 0.90829953\n",
      " -- 2.2831 bpw  accuracy: 0.92005469\n",
      " -- 2.6768 bpw  accuracy: 0.94162415\n",
      " -- 3.1689 bpw  accuracy: 0.94400990\n",
      " -- 3.1705 bpw  accuracy: 0.94798185\n",
      " -- 4.0439 bpw  accuracy: 0.95253578\n",
      " -- 4.0471 bpw  accuracy: 0.95771818\n",
      " -- 4.0816 bpw  accuracy: 0.96337679\n",
      " -- 4.1381 bpw  accuracy: 0.96391780\n",
      " -- 4.1705 bpw  accuracy: 0.97184103\n",
      " -- 4.1902 bpw  accuracy: 0.97595363\n",
      " -- 4.2737 bpw  accuracy: 0.97320217\n",
      " -- 4.3295 bpw  accuracy: 0.97756007\n",
      " -- 5.2564 bpw  accuracy: 0.98330524\n",
      " -- 5.3295 bpw  accuracy: 0.98954842\n",
      " -- 6.0439 bpw  accuracy: 0.98471126\n",
      " -- 6.3381 bpw  accuracy: 0.99532155\n",
      " -- 8.0439 bpw  accuracy: 0.99641154\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.1 (Attention)    |\n",
      "| Duration: 5.69 seconds                  |\n",
      "| Completed step: 3/67                    |\n",
      "| Avg time / step (rolling): 7.95 seconds |\n",
      "| Estimated remaining time: 8min 29sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.1 (MLP)\n",
      " -- model.layers.1.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.1.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.1.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.1.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.1.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.1.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.1.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.1.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.96116943\n",
      " -- 2.3230 bpw  accuracy: 0.96994278\n",
      " -- 2.5958 bpw  accuracy: 0.96630296\n",
      " -- 2.9120 bpw  accuracy: 0.96638372\n",
      " -- 3.2833 bpw  accuracy: 0.99308975\n",
      " -- 3.3655 bpw  accuracy: 0.99503399\n",
      " -- 3.6186 bpw  accuracy: 0.99542379\n",
      " -- 4.1368 bpw  accuracy: 0.99790493\n",
      " -- 4.1977 bpw  accuracy: 0.99811285\n",
      " -- 4.2662 bpw  accuracy: 0.99789983\n",
      " -- 4.3484 bpw  accuracy: 0.99793594\n",
      " -- 5.2491 bpw  accuracy: 0.99878875\n",
      " -- 5.3313 bpw  accuracy: 0.99900363\n",
      " -- 6.0713 bpw  accuracy: 0.99926768\n",
      " -- 6.3032 bpw  accuracy: 0.99924552\n",
      " -- 6.8687 bpw  accuracy: 0.99932394\n",
      " -- 8.0354 bpw  accuracy: 0.99954750\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.1 (MLP)          |\n",
      "| Duration: 11.54 seconds                 |\n",
      "| Completed step: 4/67                    |\n",
      "| Avg time / step (rolling): 8.85 seconds |\n",
      "| Estimated remaining time: 9min 17sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.2 (Attention)\n",
      " -- model.layers.2.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.2.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.2.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.2.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.2.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.99423372\n",
      " -- 2.1987 bpw  accuracy: 0.99482877\n",
      " -- 2.2831 bpw  accuracy: 0.99533234\n",
      " -- 2.6768 bpw  accuracy: 0.99603142\n",
      " -- 3.1689 bpw  accuracy: 0.99678426\n",
      " -- 3.1705 bpw  accuracy: 0.99679776\n",
      " -- 4.0439 bpw  accuracy: 0.99799587\n",
      " -- 4.0471 bpw  accuracy: 0.99807199\n",
      " -- 4.0816 bpw  accuracy: 0.99826083\n",
      " -- 4.1381 bpw  accuracy: 0.99836039\n",
      " -- 4.1705 bpw  accuracy: 0.99835310\n",
      " -- 4.1902 bpw  accuracy: 0.99854442\n",
      " -- 4.2737 bpw  accuracy: 0.99880082\n",
      " -- 4.3295 bpw  accuracy: 0.99893698\n",
      " -- 5.2564 bpw  accuracy: 0.99925199\n",
      " -- 5.3295 bpw  accuracy: 0.99939183\n",
      " -- 6.0439 bpw  accuracy: 0.99935231\n",
      " -- 6.3381 bpw  accuracy: 0.99975183\n",
      " -- 8.0439 bpw  accuracy: 0.99983129\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.2 (Attention)    |\n",
      "| Duration: 5.69 seconds                  |\n",
      "| Completed step: 5/67                    |\n",
      "| Avg time / step (rolling): 8.22 seconds |\n",
      "| Estimated remaining time: 8min 29sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.2 (MLP)\n",
      " -- model.layers.2.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.2.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.2.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.2.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.2.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.2.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.2.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.2.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.99230576\n",
      " -- 2.3230 bpw  accuracy: 0.99249959\n",
      " -- 2.5958 bpw  accuracy: 0.99366656\n",
      " -- 2.9120 bpw  accuracy: 0.99403711\n",
      " -- 3.2833 bpw  accuracy: 0.99618351\n",
      " -- 3.3655 bpw  accuracy: 0.99649336\n",
      " -- 3.6186 bpw  accuracy: 0.99698788\n",
      " -- 4.1368 bpw  accuracy: 0.99803742\n",
      " -- 4.1977 bpw  accuracy: 0.99822496\n",
      " -- 4.2662 bpw  accuracy: 0.99807278\n",
      " -- 4.3484 bpw  accuracy: 0.99832033\n",
      " -- 5.2491 bpw  accuracy: 0.99904700\n",
      " -- 5.3313 bpw  accuracy: 0.99918050\n",
      " -- 6.0713 bpw  accuracy: 0.99947878\n",
      " -- 6.3032 bpw  accuracy: 0.99950779\n",
      " -- 6.8687 bpw  accuracy: 0.99960538\n",
      " -- 8.0354 bpw  accuracy: 0.99985946\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.2 (MLP)          |\n",
      "| Duration: 11.58 seconds                 |\n",
      "| Completed step: 6/67                    |\n",
      "| Avg time / step (rolling): 8.78 seconds |\n",
      "| Estimated remaining time: 8min 55sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.3 (Attention)\n",
      " -- model.layers.3.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.3.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.3.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.3.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.3.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.99314147\n",
      " -- 2.1987 bpw  accuracy: 0.99340480\n",
      " -- 2.2831 bpw  accuracy: 0.99436938\n",
      " -- 2.6768 bpw  accuracy: 0.99577641\n",
      " -- 3.1689 bpw  accuracy: 0.99620206\n",
      " -- 3.1705 bpw  accuracy: 0.99628717\n",
      " -- 4.0439 bpw  accuracy: 0.99698260\n",
      " -- 4.0471 bpw  accuracy: 0.99705620\n",
      " -- 4.0816 bpw  accuracy: 0.99756682\n",
      " -- 4.1381 bpw  accuracy: 0.99777746\n",
      " -- 4.1705 bpw  accuracy: 0.99810685\n",
      " -- 4.1902 bpw  accuracy: 0.99831728\n",
      " -- 4.2737 bpw  accuracy: 0.99827637\n",
      " -- 4.3295 bpw  accuracy: 0.99850157\n",
      " -- 5.2564 bpw  accuracy: 0.99895765\n",
      " -- 5.3295 bpw  accuracy: 0.99917346\n",
      " -- 6.0439 bpw  accuracy: 0.99907396\n",
      " -- 6.3381 bpw  accuracy: 0.99965574\n",
      " -- 8.0439 bpw  accuracy: 0.99976996\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.3 (Attention)    |\n",
      "| Duration: 5.71 seconds                  |\n",
      "| Completed step: 7/67                    |\n",
      "| Avg time / step (rolling): 8.34 seconds |\n",
      "| Estimated remaining time: 8min 20sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.3 (MLP)\n",
      " -- model.layers.3.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.3.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.3.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.3.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.3.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.3.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.3.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.3.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.98871149\n",
      " -- 2.3230 bpw  accuracy: 0.98898868\n",
      " -- 2.5958 bpw  accuracy: 0.99068556\n",
      " -- 2.9120 bpw  accuracy: 0.99122700\n",
      " -- 3.2833 bpw  accuracy: 0.99432206\n",
      " -- 3.3655 bpw  accuracy: 0.99478906\n",
      " -- 3.6186 bpw  accuracy: 0.99550332\n",
      " -- 4.1368 bpw  accuracy: 0.99708008\n",
      " -- 4.1977 bpw  accuracy: 0.99735763\n",
      " -- 4.2662 bpw  accuracy: 0.99712859\n",
      " -- 4.3484 bpw  accuracy: 0.99749988\n",
      " -- 5.2491 bpw  accuracy: 0.99858252\n",
      " -- 5.3313 bpw  accuracy: 0.99878095\n",
      " -- 6.0713 bpw  accuracy: 0.99922367\n",
      " -- 6.3032 bpw  accuracy: 0.99926746\n",
      " -- 6.8687 bpw  accuracy: 0.99940758\n",
      " -- 8.0354 bpw  accuracy: 0.99979168\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.3 (MLP)          |\n",
      "| Duration: 11.60 seconds                 |\n",
      "| Completed step: 8/67                    |\n",
      "| Avg time / step (rolling): 8.75 seconds |\n",
      "| Estimated remaining time: 8min 36sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.4 (Attention)\n",
      " -- model.layers.4.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.4.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.4.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.4.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.4.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.99097527\n",
      " -- 2.1987 bpw  accuracy: 0.99130944\n",
      " -- 2.2831 bpw  accuracy: 0.99260463\n",
      " -- 2.6768 bpw  accuracy: 0.99424028\n",
      " -- 3.1689 bpw  accuracy: 0.99520344\n",
      " -- 3.1705 bpw  accuracy: 0.99537439\n",
      " -- 4.0439 bpw  accuracy: 0.99621787\n",
      " -- 4.0471 bpw  accuracy: 0.99655833\n",
      " -- 4.0816 bpw  accuracy: 0.99717281\n",
      " -- 4.1381 bpw  accuracy: 0.99733017\n",
      " -- 4.1705 bpw  accuracy: 0.99766978\n",
      " -- 4.1902 bpw  accuracy: 0.99781407\n",
      " -- 4.2737 bpw  accuracy: 0.99791981\n",
      " -- 4.3295 bpw  accuracy: 0.99803480\n",
      " -- 5.2564 bpw  accuracy: 0.99866678\n",
      " -- 5.3295 bpw  accuracy: 0.99894432\n",
      " -- 6.0439 bpw  accuracy: 0.99882616\n",
      " -- 6.3381 bpw  accuracy: 0.99954916\n",
      " -- 8.0439 bpw  accuracy: 0.99969297\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.4 (Attention)    |\n",
      "| Duration: 5.71 seconds                  |\n",
      "| Completed step: 9/67                    |\n",
      "| Avg time / step (rolling): 8.41 seconds |\n",
      "| Estimated remaining time: 8min 7sec     |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.4 (MLP)\n",
      " -- model.layers.4.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.4.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.4.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.4.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.4.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.4.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.4.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.4.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.98411614\n",
      " -- 2.3230 bpw  accuracy: 0.98455854\n",
      " -- 2.5958 bpw  accuracy: 0.98708353\n",
      " -- 2.9120 bpw  accuracy: 0.98786790\n",
      " -- 3.2833 bpw  accuracy: 0.99201187\n",
      " -- 3.3655 bpw  accuracy: 0.99269266\n",
      " -- 3.6186 bpw  accuracy: 0.99372950\n",
      " -- 4.1368 bpw  accuracy: 0.99587568\n",
      " -- 4.1977 bpw  accuracy: 0.99627177\n",
      " -- 4.2662 bpw  accuracy: 0.99595657\n",
      " -- 4.3484 bpw  accuracy: 0.99649148\n",
      " -- 5.2491 bpw  accuracy: 0.99800396\n",
      " -- 5.3313 bpw  accuracy: 0.99828901\n",
      " -- 6.0713 bpw  accuracy: 0.99889855\n",
      " -- 6.3032 bpw  accuracy: 0.99896765\n",
      " -- 6.8687 bpw  accuracy: 0.99917647\n",
      " -- 8.0354 bpw  accuracy: 0.99970340\n",
      "-------------------------------------------\n",
      "| Measured: model.layers.4 (MLP)          |\n",
      "| Duration: 11.62 seconds                 |\n",
      "| Completed step: 10/67                   |\n",
      "| Avg time / step (rolling): 8.73 seconds |\n",
      "| Estimated remaining time: 8min 17sec    |\n",
      "| Last checkpoint layer: None             |\n",
      "-------------------------------------------\n",
      " -- Layer: model.layers.5 (Attention)\n",
      " -- model.layers.5.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.5.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.5.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.5.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.5.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.98813494\n",
      " -- 2.1987 bpw  accuracy: 0.98853563\n",
      " -- 2.2831 bpw  accuracy: 0.98984828\n",
      " -- 2.6768 bpw  accuracy: 0.99241567\n",
      " -- 3.1689 bpw  accuracy: 0.99399618\n",
      " -- 3.1705 bpw  accuracy: 0.99370030\n",
      " -- 4.0439 bpw  accuracy: 0.99592040\n",
      " -- 4.0471 bpw  accuracy: 0.99544175\n",
      " -- 4.0816 bpw  accuracy: 0.99631877\n",
      " -- 4.1381 bpw  accuracy: 0.99634563\n",
      " -- 4.1705 bpw  accuracy: 0.99699968\n",
      " -- 4.1902 bpw  accuracy: 0.99721042\n",
      " -- 4.2737 bpw  accuracy: 0.99734143\n",
      " -- 4.3295 bpw  accuracy: 0.99758715\n",
      " -- 5.2564 bpw  accuracy: 0.99846622\n",
      " -- 5.3295 bpw  accuracy: 0.99877536\n",
      " -- 6.0439 bpw  accuracy: 0.99876442\n",
      " -- 6.3381 bpw  accuracy: 0.99938730\n",
      " -- 8.0439 bpw  accuracy: 0.99964585\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.5 (Attention)        |\n",
      "| Duration: 5.74 seconds                      |\n",
      "| Completed step: 11/67                       |\n",
      "| Avg time / step (rolling): 8.64 seconds     |\n",
      "| Estimated remaining time: 8min 3sec         |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.5 (MLP)\n",
      " -- model.layers.5.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.5.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.5.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.5.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.5.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.5.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.5.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.5.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.97878770\n",
      " -- 2.3230 bpw  accuracy: 0.97937868\n",
      " -- 2.5958 bpw  accuracy: 0.98271760\n",
      " -- 2.9120 bpw  accuracy: 0.98371391\n",
      " -- 3.2833 bpw  accuracy: 0.98935758\n",
      " -- 3.3655 bpw  accuracy: 0.99024767\n",
      " -- 3.6186 bpw  accuracy: 0.99159904\n",
      " -- 4.1368 bpw  accuracy: 0.99453511\n",
      " -- 4.1977 bpw  accuracy: 0.99503490\n",
      " -- 4.2662 bpw  accuracy: 0.99461515\n",
      " -- 4.3484 bpw  accuracy: 0.99532108\n",
      " -- 5.2491 bpw  accuracy: 0.99734983\n",
      " -- 5.3313 bpw  accuracy: 0.99772015\n",
      " -- 6.0713 bpw  accuracy: 0.99854164\n",
      " -- 6.3032 bpw  accuracy: 0.99862844\n",
      " -- 6.8687 bpw  accuracy: 0.99889975\n",
      " -- 8.0354 bpw  accuracy: 0.99960178\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.5 (MLP)              |\n",
      "| Duration: 11.65 seconds                     |\n",
      "| Completed step: 12/67                       |\n",
      "| Avg time / step (rolling): 8.65 seconds     |\n",
      "| Estimated remaining time: 7min 55sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.6 (Attention)\n",
      " -- model.layers.6.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.6.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.6.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.6.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.6.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.98619729\n",
      " -- 2.1987 bpw  accuracy: 0.98686386\n",
      " -- 2.2831 bpw  accuracy: 0.98840211\n",
      " -- 2.6768 bpw  accuracy: 0.99135979\n",
      " -- 3.1689 bpw  accuracy: 0.99300617\n",
      " -- 3.1705 bpw  accuracy: 0.99319333\n",
      " -- 4.0439 bpw  accuracy: 0.99492808\n",
      " -- 4.0471 bpw  accuracy: 0.99527636\n",
      " -- 4.0816 bpw  accuracy: 0.99561156\n",
      " -- 4.1381 bpw  accuracy: 0.99590165\n",
      " -- 4.1705 bpw  accuracy: 0.99649467\n",
      " -- 4.1902 bpw  accuracy: 0.99682409\n",
      " -- 4.2737 bpw  accuracy: 0.99687413\n",
      " -- 4.3295 bpw  accuracy: 0.99721368\n",
      " -- 5.2564 bpw  accuracy: 0.99832128\n",
      " -- 5.3295 bpw  accuracy: 0.99860539\n",
      " -- 6.0439 bpw  accuracy: 0.99867255\n",
      " -- 6.3381 bpw  accuracy: 0.99929558\n",
      " -- 8.0439 bpw  accuracy: 0.99964877\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.6 (Attention)        |\n",
      "| Duration: 5.73 seconds                      |\n",
      "| Completed step: 13/67                       |\n",
      "| Avg time / step (rolling): 8.66 seconds     |\n",
      "| Estimated remaining time: 7min 47sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.6 (MLP)\n",
      " -- model.layers.6.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.6.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.6.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.6.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.6.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.6.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.6.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.6.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.97479188\n",
      " -- 2.3230 bpw  accuracy: 0.97544934\n",
      " -- 2.5958 bpw  accuracy: 0.97963964\n",
      " -- 2.9120 bpw  accuracy: 0.98088637\n",
      " -- 3.2833 bpw  accuracy: 0.98730667\n",
      " -- 3.3655 bpw  accuracy: 0.98839235\n",
      " -- 3.6186 bpw  accuracy: 0.99009262\n",
      " -- 4.1368 bpw  accuracy: 0.99346104\n",
      " -- 4.1977 bpw  accuracy: 0.99409079\n",
      " -- 4.2662 bpw  accuracy: 0.99356371\n",
      " -- 4.3484 bpw  accuracy: 0.99442424\n",
      " -- 5.2491 bpw  accuracy: 0.99682466\n",
      " -- 5.3313 bpw  accuracy: 0.99728057\n",
      " -- 6.0713 bpw  accuracy: 0.99825434\n",
      " -- 6.3032 bpw  accuracy: 0.99835716\n",
      " -- 6.8687 bpw  accuracy: 0.99870656\n",
      " -- 8.0354 bpw  accuracy: 0.99952938\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.6 (MLP)              |\n",
      "| Duration: 11.65 seconds                     |\n",
      "| Completed step: 14/67                       |\n",
      "| Avg time / step (rolling): 8.67 seconds     |\n",
      "| Estimated remaining time: 7min 39sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.7 (Attention)\n",
      " -- model.layers.7.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.7.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.7.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.7.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.7.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.98238375\n",
      " -- 2.1987 bpw  accuracy: 0.98298827\n",
      " -- 2.2831 bpw  accuracy: 0.98491607\n",
      " -- 2.6768 bpw  accuracy: 0.98888860\n",
      " -- 3.1689 bpw  accuracy: 0.99121503\n",
      " -- 3.1705 bpw  accuracy: 0.99136370\n",
      " -- 4.0439 bpw  accuracy: 0.99401281\n",
      " -- 4.0471 bpw  accuracy: 0.99422276\n",
      " -- 4.0816 bpw  accuracy: 0.99465086\n",
      " -- 4.1381 bpw  accuracy: 0.99510425\n",
      " -- 4.1705 bpw  accuracy: 0.99561463\n",
      " -- 4.1902 bpw  accuracy: 0.99589488\n",
      " -- 4.2737 bpw  accuracy: 0.99604019\n",
      " -- 4.3295 bpw  accuracy: 0.99644791\n",
      " -- 5.2564 bpw  accuracy: 0.99785574\n",
      " -- 5.3295 bpw  accuracy: 0.99824525\n",
      " -- 6.0439 bpw  accuracy: 0.99838637\n",
      " -- 6.3381 bpw  accuracy: 0.99904384\n",
      " -- 8.0439 bpw  accuracy: 0.99956045\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.7 (Attention)        |\n",
      "| Duration: 5.72 seconds                      |\n",
      "| Completed step: 15/67                       |\n",
      "| Avg time / step (rolling): 8.67 seconds     |\n",
      "| Estimated remaining time: 7min 30sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.7 (MLP)\n",
      " -- model.layers.7.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.7.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.7.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.7.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.7.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.7.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.7.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.7.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.97056294\n",
      " -- 2.3230 bpw  accuracy: 0.97134254\n",
      " -- 2.5958 bpw  accuracy: 0.97600543\n",
      " -- 2.9120 bpw  accuracy: 0.97737674\n",
      " -- 3.2833 bpw  accuracy: 0.98517742\n",
      " -- 3.3655 bpw  accuracy: 0.98645389\n",
      " -- 3.6186 bpw  accuracy: 0.98832250\n",
      " -- 4.1368 bpw  accuracy: 0.99238340\n",
      " -- 4.1977 bpw  accuracy: 0.99309683\n",
      " -- 4.2662 bpw  accuracy: 0.99247440\n",
      " -- 4.3484 bpw  accuracy: 0.99348184\n",
      " -- 5.2491 bpw  accuracy: 0.99628112\n",
      " -- 5.3313 bpw  accuracy: 0.99682127\n",
      " -- 6.0713 bpw  accuracy: 0.99795578\n",
      " -- 6.3032 bpw  accuracy: 0.99807162\n",
      " -- 6.8687 bpw  accuracy: 0.99844934\n",
      " -- 8.0354 bpw  accuracy: 0.99945000\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.7 (MLP)              |\n",
      "| Duration: 11.71 seconds                     |\n",
      "| Completed step: 16/67                       |\n",
      "| Avg time / step (rolling): 8.68 seconds     |\n",
      "| Estimated remaining time: 7min 22sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.8 (Attention)\n",
      " -- model.layers.8.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.8.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.8.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.8.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.8.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.98118818\n",
      " -- 2.1987 bpw  accuracy: 0.98185193\n",
      " -- 2.2831 bpw  accuracy: 0.98363833\n",
      " -- 2.6768 bpw  accuracy: 0.98806445\n",
      " -- 3.1689 bpw  accuracy: 0.99033253\n",
      " -- 3.1705 bpw  accuracy: 0.99080612\n",
      " -- 4.0439 bpw  accuracy: 0.99327214\n",
      " -- 4.0471 bpw  accuracy: 0.99392002\n",
      " -- 4.0816 bpw  accuracy: 0.99405517\n",
      " -- 4.1381 bpw  accuracy: 0.99469410\n",
      " -- 4.1705 bpw  accuracy: 0.99521616\n",
      " -- 4.1902 bpw  accuracy: 0.99563240\n",
      " -- 4.2737 bpw  accuracy: 0.99585968\n",
      " -- 4.3295 bpw  accuracy: 0.99612980\n",
      " -- 5.2564 bpw  accuracy: 0.99758574\n",
      " -- 5.3295 bpw  accuracy: 0.99808014\n",
      " -- 6.0439 bpw  accuracy: 0.99814355\n",
      " -- 6.3381 bpw  accuracy: 0.99898050\n",
      " -- 8.0439 bpw  accuracy: 0.99949655\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.8 (Attention)        |\n",
      "| Duration: 5.76 seconds                      |\n",
      "| Completed step: 17/67                       |\n",
      "| Avg time / step (rolling): 8.69 seconds     |\n",
      "| Estimated remaining time: 7min 14sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.8 (MLP)\n",
      " -- model.layers.8.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.8.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.8.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.8.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.8.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.8.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.8.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.8.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.96760377\n",
      " -- 2.3230 bpw  accuracy: 0.96845828\n",
      " -- 2.5958 bpw  accuracy: 0.97369222\n",
      " -- 2.9120 bpw  accuracy: 0.97521490\n",
      " -- 3.2833 bpw  accuracy: 0.98369437\n",
      " -- 3.3655 bpw  accuracy: 0.98509516\n",
      " -- 3.6186 bpw  accuracy: 0.98719166\n",
      " -- 4.1368 bpw  accuracy: 0.99162262\n",
      " -- 4.1977 bpw  accuracy: 0.99239968\n",
      " -- 4.2662 bpw  accuracy: 0.99172930\n",
      " -- 4.3484 bpw  accuracy: 0.99283570\n",
      " -- 5.2491 bpw  accuracy: 0.99591268\n",
      " -- 5.3313 bpw  accuracy: 0.99650487\n",
      " -- 6.0713 bpw  accuracy: 0.99775491\n",
      " -- 6.3032 bpw  accuracy: 0.99788270\n",
      " -- 6.8687 bpw  accuracy: 0.99830590\n",
      " -- 8.0354 bpw  accuracy: 0.99939257\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.8 (MLP)              |\n",
      "| Duration: 11.71 seconds                     |\n",
      "| Completed step: 18/67                       |\n",
      "| Avg time / step (rolling): 8.70 seconds     |\n",
      "| Estimated remaining time: 7min 6sec         |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.9 (Attention)\n",
      " -- model.layers.9.self_attn.q_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.9.self_attn.q_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.9.self_attn.k_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.9.self_attn.v_proj                    1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.9.self_attn.o_proj                    1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.97927271\n",
      " -- 2.1987 bpw  accuracy: 0.97993317\n",
      " -- 2.2831 bpw  accuracy: 0.98166589\n",
      " -- 2.6768 bpw  accuracy: 0.98594460\n",
      " -- 3.1689 bpw  accuracy: 0.98949739\n",
      " -- 3.1705 bpw  accuracy: 0.98965183\n",
      " -- 4.0439 bpw  accuracy: 0.99278286\n",
      " -- 4.0471 bpw  accuracy: 0.99292729\n",
      " -- 4.0816 bpw  accuracy: 0.99391495\n",
      " -- 4.1381 bpw  accuracy: 0.99420109\n",
      " -- 4.1705 bpw  accuracy: 0.99495545\n",
      " -- 4.1902 bpw  accuracy: 0.99522292\n",
      " -- 4.2737 bpw  accuracy: 0.99547917\n",
      " -- 4.3295 bpw  accuracy: 0.99584575\n",
      " -- 5.2564 bpw  accuracy: 0.99749130\n",
      " -- 5.3295 bpw  accuracy: 0.99793351\n",
      " -- 6.0439 bpw  accuracy: 0.99815301\n",
      " -- 6.3381 bpw  accuracy: 0.99885405\n",
      " -- 8.0439 bpw  accuracy: 0.99948663\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.9 (Attention)        |\n",
      "| Duration: 5.74 seconds                      |\n",
      "| Completed step: 19/67                       |\n",
      "| Avg time / step (rolling): 8.70 seconds     |\n",
      "| Estimated remaining time: 6min 57sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.9 (MLP)\n",
      " -- model.layers.9.mlp.gate_proj                       0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.9.mlp.gate_proj                       1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.9.mlp.up_proj                         1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.9.mlp.up_proj                         1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.9.mlp.up_proj                         0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.9.mlp.up_proj                         1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.9.mlp.down_proj                       0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.9.mlp.down_proj                       1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.96467819\n",
      " -- 2.3230 bpw  accuracy: 0.96563304\n",
      " -- 2.5958 bpw  accuracy: 0.97135899\n",
      " -- 2.9120 bpw  accuracy: 0.97307692\n",
      " -- 3.2833 bpw  accuracy: 0.98213639\n",
      " -- 3.3655 bpw  accuracy: 0.98366495\n",
      " -- 3.6186 bpw  accuracy: 0.98602632\n",
      " -- 4.1368 bpw  accuracy: 0.99080255\n",
      " -- 4.1977 bpw  accuracy: 0.99163522\n",
      " -- 4.2662 bpw  accuracy: 0.99092808\n",
      " -- 4.3484 bpw  accuracy: 0.99214143\n",
      " -- 5.2491 bpw  accuracy: 0.99551305\n",
      " -- 5.3313 bpw  accuracy: 0.99616238\n",
      " -- 6.0713 bpw  accuracy: 0.99751653\n",
      " -- 6.3032 bpw  accuracy: 0.99767197\n",
      " -- 6.8687 bpw  accuracy: 0.99813680\n",
      " -- 8.0354 bpw  accuracy: 0.99930988\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.9 (MLP)              |\n",
      "| Duration: 11.71 seconds                     |\n",
      "| Completed step: 20/67                       |\n",
      "| Avg time / step (rolling): 8.71 seconds     |\n",
      "| Estimated remaining time: 6min 49sec        |\n",
      "| Last checkpoint layer: model.layers.4 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.10 (Attention)\n",
      " -- model.layers.10.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.10.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.10.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.10.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.10.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.97565431\n",
      " -- 2.1987 bpw  accuracy: 0.97653945\n",
      " -- 2.2831 bpw  accuracy: 0.97863918\n",
      " -- 2.6768 bpw  accuracy: 0.98403696\n",
      " -- 3.1689 bpw  accuracy: 0.98753611\n",
      " -- 3.1705 bpw  accuracy: 0.98779246\n",
      " -- 4.0439 bpw  accuracy: 0.99168839\n",
      " -- 4.0471 bpw  accuracy: 0.99204481\n",
      " -- 4.0816 bpw  accuracy: 0.99275190\n",
      " -- 4.1381 bpw  accuracy: 0.99316636\n",
      " -- 4.1705 bpw  accuracy: 0.99377392\n",
      " -- 4.1902 bpw  accuracy: 0.99424866\n",
      " -- 4.2737 bpw  accuracy: 0.99446969\n",
      " -- 4.3295 bpw  accuracy: 0.99502471\n",
      " -- 5.2564 bpw  accuracy: 0.99694451\n",
      " -- 5.3295 bpw  accuracy: 0.99745925\n",
      " -- 6.0439 bpw  accuracy: 0.99773833\n",
      " -- 6.3381 bpw  accuracy: 0.99857846\n",
      " -- 8.0439 bpw  accuracy: 0.99939171\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.10 (Attention)       |\n",
      "| Duration: 5.77 seconds                      |\n",
      "| Completed step: 21/67                       |\n",
      "| Avg time / step (rolling): 8.72 seconds     |\n",
      "| Estimated remaining time: 6min 40sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.10 (MLP)\n",
      " -- model.layers.10.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.10.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.10.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.10.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.10.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.10.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.10.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.10.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.96219283\n",
      " -- 2.3230 bpw  accuracy: 0.96325442\n",
      " -- 2.5958 bpw  accuracy: 0.96977849\n",
      " -- 2.9120 bpw  accuracy: 0.97173663\n",
      " -- 3.2833 bpw  accuracy: 0.98084992\n",
      " -- 3.3655 bpw  accuracy: 0.98251079\n",
      " -- 3.6186 bpw  accuracy: 0.98519443\n",
      " -- 4.1368 bpw  accuracy: 0.99004257\n",
      " -- 4.1977 bpw  accuracy: 0.99103740\n",
      " -- 4.2662 bpw  accuracy: 0.99027596\n",
      " -- 4.3484 bpw  accuracy: 0.99158431\n",
      " -- 5.2491 bpw  accuracy: 0.99520073\n",
      " -- 5.3313 bpw  accuracy: 0.99589364\n",
      " -- 6.0713 bpw  accuracy: 0.99734728\n",
      " -- 6.3032 bpw  accuracy: 0.99751820\n",
      " -- 6.8687 bpw  accuracy: 0.99807083\n",
      " -- 8.0354 bpw  accuracy: 0.99928456\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.10 (MLP)             |\n",
      "| Duration: 11.73 seconds                     |\n",
      "| Completed step: 22/67                       |\n",
      "| Avg time / step (rolling): 8.72 seconds     |\n",
      "| Estimated remaining time: 6min 32sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.11 (Attention)\n",
      " -- model.layers.11.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.11.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.11.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.11.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.11.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.97117961\n",
      " -- 2.1987 bpw  accuracy: 0.97228383\n",
      " -- 2.2831 bpw  accuracy: 0.97464897\n",
      " -- 2.6768 bpw  accuracy: 0.98099005\n",
      " -- 3.1689 bpw  accuracy: 0.98483817\n",
      " -- 3.1705 bpw  accuracy: 0.98524277\n",
      " -- 4.0439 bpw  accuracy: 0.98943006\n",
      " -- 4.0471 bpw  accuracy: 0.98989340\n",
      " -- 4.0816 bpw  accuracy: 0.99085533\n",
      " -- 4.1381 bpw  accuracy: 0.99164975\n",
      " -- 4.1705 bpw  accuracy: 0.99252216\n",
      " -- 4.1902 bpw  accuracy: 0.99313520\n",
      " -- 4.2737 bpw  accuracy: 0.99352299\n",
      " -- 4.3295 bpw  accuracy: 0.99398830\n",
      " -- 5.2564 bpw  accuracy: 0.99619706\n",
      " -- 5.3295 bpw  accuracy: 0.99702787\n",
      " -- 6.0439 bpw  accuracy: 0.99703964\n",
      " -- 6.3381 bpw  accuracy: 0.99828428\n",
      " -- 8.0439 bpw  accuracy: 0.99923403\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.11 (Attention)       |\n",
      "| Duration: 5.76 seconds                      |\n",
      "| Completed step: 23/67                       |\n",
      "| Avg time / step (rolling): 8.73 seconds     |\n",
      "| Estimated remaining time: 6min 23sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.11 (MLP)\n",
      " -- model.layers.11.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.11.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.11.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.11.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.11.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.11.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.11.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.11.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.95932789\n",
      " -- 2.3230 bpw  accuracy: 0.96051364\n",
      " -- 2.5958 bpw  accuracy: 0.96755651\n",
      " -- 2.9120 bpw  accuracy: 0.96968193\n",
      " -- 3.2833 bpw  accuracy: 0.97938442\n",
      " -- 3.3655 bpw  accuracy: 0.98116917\n",
      " -- 3.6186 bpw  accuracy: 0.98408250\n",
      " -- 4.1368 bpw  accuracy: 0.98925677\n",
      " -- 4.1977 bpw  accuracy: 0.99032796\n",
      " -- 4.2662 bpw  accuracy: 0.98953268\n",
      " -- 4.3484 bpw  accuracy: 0.99092974\n",
      " -- 5.2491 bpw  accuracy: 0.99483815\n",
      " -- 5.3313 bpw  accuracy: 0.99557609\n",
      " -- 6.0713 bpw  accuracy: 0.99713515\n",
      " -- 6.3032 bpw  accuracy: 0.99733517\n",
      " -- 6.8687 bpw  accuracy: 0.99793737\n",
      " -- 8.0354 bpw  accuracy: 0.99922971\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.11 (MLP)             |\n",
      "| Duration: 11.74 seconds                     |\n",
      "| Completed step: 24/67                       |\n",
      "| Avg time / step (rolling): 8.73 seconds     |\n",
      "| Estimated remaining time: 6min 15sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.12 (Attention)\n",
      " -- model.layers.12.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.12.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.12.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.12.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.12.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96495493\n",
      " -- 2.1987 bpw  accuracy: 0.96613708\n",
      " -- 2.2831 bpw  accuracy: 0.97012997\n",
      " -- 2.6768 bpw  accuracy: 0.97676598\n",
      " -- 3.1689 bpw  accuracy: 0.98228885\n",
      " -- 3.1705 bpw  accuracy: 0.98263854\n",
      " -- 4.0439 bpw  accuracy: 0.98758233\n",
      " -- 4.0471 bpw  accuracy: 0.98794841\n",
      " -- 4.0816 bpw  accuracy: 0.98935442\n",
      " -- 4.1381 bpw  accuracy: 0.98999154\n",
      " -- 4.1705 bpw  accuracy: 0.99097389\n",
      " -- 4.1902 bpw  accuracy: 0.99165745\n",
      " -- 4.2737 bpw  accuracy: 0.99178474\n",
      " -- 4.3295 bpw  accuracy: 0.99259274\n",
      " -- 5.2564 bpw  accuracy: 0.99535201\n",
      " -- 5.3295 bpw  accuracy: 0.99625339\n",
      " -- 6.0439 bpw  accuracy: 0.99631340\n",
      " -- 6.3381 bpw  accuracy: 0.99808647\n",
      " -- 8.0439 bpw  accuracy: 0.99894124\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.12 (Attention)       |\n",
      "| Duration: 5.74 seconds                      |\n",
      "| Completed step: 25/67                       |\n",
      "| Avg time / step (rolling): 8.74 seconds     |\n",
      "| Estimated remaining time: 6min 6sec         |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.12 (MLP)\n",
      " -- model.layers.12.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.12.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.12.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.12.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.12.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.12.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.12.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.12.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.95502363\n",
      " -- 2.3230 bpw  accuracy: 0.95641802\n",
      " -- 2.5958 bpw  accuracy: 0.96380103\n",
      " -- 2.9120 bpw  accuracy: 0.96603708\n",
      " -- 3.2833 bpw  accuracy: 0.97719298\n",
      " -- 3.3655 bpw  accuracy: 0.97922174\n",
      " -- 3.6186 bpw  accuracy: 0.98227149\n",
      " -- 4.1368 bpw  accuracy: 0.98813703\n",
      " -- 4.1977 bpw  accuracy: 0.98930695\n",
      " -- 4.2662 bpw  accuracy: 0.98842268\n",
      " -- 4.3484 bpw  accuracy: 0.98999054\n",
      " -- 5.2491 bpw  accuracy: 0.99427915\n",
      " -- 5.3313 bpw  accuracy: 0.99511102\n",
      " -- 6.0713 bpw  accuracy: 0.99681403\n",
      " -- 6.3032 bpw  accuracy: 0.99703472\n",
      " -- 6.8687 bpw  accuracy: 0.99764365\n",
      " -- 8.0354 bpw  accuracy: 0.99912725\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.12 (MLP)             |\n",
      "| Duration: 11.75 seconds                     |\n",
      "| Completed step: 26/67                       |\n",
      "| Avg time / step (rolling): 8.74 seconds     |\n",
      "| Estimated remaining time: 5min 58sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.13 (Attention)\n",
      " -- model.layers.13.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.13.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.13.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.13.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.13.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96566063\n",
      " -- 2.1987 bpw  accuracy: 0.96692534\n",
      " -- 2.2831 bpw  accuracy: 0.96979764\n",
      " -- 2.6768 bpw  accuracy: 0.97797101\n",
      " -- 3.1689 bpw  accuracy: 0.98180391\n",
      " -- 3.1705 bpw  accuracy: 0.98228380\n",
      " -- 4.0439 bpw  accuracy: 0.98817052\n",
      " -- 4.0471 bpw  accuracy: 0.98883122\n",
      " -- 4.0816 bpw  accuracy: 0.99046743\n",
      " -- 4.1381 bpw  accuracy: 0.99090889\n",
      " -- 4.1705 bpw  accuracy: 0.99129196\n",
      " -- 4.1902 bpw  accuracy: 0.99184927\n",
      " -- 4.2737 bpw  accuracy: 0.99238007\n",
      " -- 4.3295 bpw  accuracy: 0.99299503\n",
      " -- 5.2564 bpw  accuracy: 0.99574761\n",
      " -- 5.3295 bpw  accuracy: 0.99654462\n",
      " -- 6.0439 bpw  accuracy: 0.99698982\n",
      " -- 6.3381 bpw  accuracy: 0.99805615\n",
      " -- 8.0439 bpw  accuracy: 0.99918267\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.13 (Attention)       |\n",
      "| Duration: 5.54 seconds                      |\n",
      "| Completed step: 27/67                       |\n",
      "| Avg time / step (rolling): 8.72 seconds     |\n",
      "| Estimated remaining time: 5min 48sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.13 (MLP)\n",
      " -- model.layers.13.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.13.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.13.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.13.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.13.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.13.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.13.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.13.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.95074211\n",
      " -- 2.3230 bpw  accuracy: 0.95220953\n",
      " -- 2.5958 bpw  accuracy: 0.96046698\n",
      " -- 2.9120 bpw  accuracy: 0.96301495\n",
      " -- 3.2833 bpw  accuracy: 0.97492939\n",
      " -- 3.3655 bpw  accuracy: 0.97714075\n",
      " -- 3.6186 bpw  accuracy: 0.98056678\n",
      " -- 4.1368 bpw  accuracy: 0.98691559\n",
      " -- 4.1977 bpw  accuracy: 0.98821078\n",
      " -- 4.2662 bpw  accuracy: 0.98725992\n",
      " -- 4.3484 bpw  accuracy: 0.98898072\n",
      " -- 5.2491 bpw  accuracy: 0.99371503\n",
      " -- 5.3313 bpw  accuracy: 0.99462668\n",
      " -- 6.0713 bpw  accuracy: 0.99650283\n",
      " -- 6.3032 bpw  accuracy: 0.99674914\n",
      " -- 6.8687 bpw  accuracy: 0.99745423\n",
      " -- 8.0354 bpw  accuracy: 0.99905354\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.13 (MLP)             |\n",
      "| Duration: 11.75 seconds                     |\n",
      "| Completed step: 28/67                       |\n",
      "| Avg time / step (rolling): 8.72 seconds     |\n",
      "| Estimated remaining time: 5min 40sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.14 (Attention)\n",
      " -- model.layers.14.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.14.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.14.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.14.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.14.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96029158\n",
      " -- 2.1987 bpw  accuracy: 0.96210955\n",
      " -- 2.2831 bpw  accuracy: 0.96584817\n",
      " -- 2.6768 bpw  accuracy: 0.97496349\n",
      " -- 3.1689 bpw  accuracy: 0.97935728\n",
      " -- 3.1705 bpw  accuracy: 0.97996668\n",
      " -- 4.0439 bpw  accuracy: 0.98675351\n",
      " -- 4.0471 bpw  accuracy: 0.98756108\n",
      " -- 4.0816 bpw  accuracy: 0.98865751\n",
      " -- 4.1381 bpw  accuracy: 0.98937864\n",
      " -- 4.1705 bpw  accuracy: 0.98980806\n",
      " -- 4.1902 bpw  accuracy: 0.99033709\n",
      " -- 4.2737 bpw  accuracy: 0.99099753\n",
      " -- 4.3295 bpw  accuracy: 0.99194626\n",
      " -- 5.2564 bpw  accuracy: 0.99499589\n",
      " -- 5.3295 bpw  accuracy: 0.99598436\n",
      " -- 6.0439 bpw  accuracy: 0.99631255\n",
      " -- 6.3381 bpw  accuracy: 0.99775193\n",
      " -- 8.0439 bpw  accuracy: 0.99898891\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.14 (Attention)       |\n",
      "| Duration: 5.56 seconds                      |\n",
      "| Completed step: 29/67                       |\n",
      "| Avg time / step (rolling): 8.70 seconds     |\n",
      "| Estimated remaining time: 5min 30sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.14 (MLP)\n",
      " -- model.layers.14.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.14.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.14.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.14.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.14.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.14.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.14.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.14.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.94662535\n",
      " -- 2.3230 bpw  accuracy: 0.94817807\n",
      " -- 2.5958 bpw  accuracy: 0.95688214\n",
      " -- 2.9120 bpw  accuracy: 0.95953626\n",
      " -- 3.2833 bpw  accuracy: 0.97291279\n",
      " -- 3.3655 bpw  accuracy: 0.97537392\n",
      " -- 3.6186 bpw  accuracy: 0.97892671\n",
      " -- 4.1368 bpw  accuracy: 0.98579460\n",
      " -- 4.1977 bpw  accuracy: 0.98714336\n",
      " -- 4.2662 bpw  accuracy: 0.98626863\n",
      " -- 4.3484 bpw  accuracy: 0.98811815\n",
      " -- 5.2491 bpw  accuracy: 0.99318165\n",
      " -- 5.3313 bpw  accuracy: 0.99419222\n",
      " -- 6.0713 bpw  accuracy: 0.99610924\n",
      " -- 6.3032 bpw  accuracy: 0.99648320\n",
      " -- 6.8687 bpw  accuracy: 0.99721572\n",
      " -- 8.0354 bpw  accuracy: 0.99889234\n",
      "-----------------------------------------------\n",
      "| Measured: model.layers.14 (MLP)             |\n",
      "| Duration: 11.76 seconds                     |\n",
      "| Completed step: 30/67                       |\n",
      "| Avg time / step (rolling): 8.71 seconds     |\n",
      "| Estimated remaining time: 5min 22sec        |\n",
      "| Last checkpoint layer: model.layers.9 (MLP) |\n",
      "-----------------------------------------------\n",
      " -- Layer: model.layers.15 (Attention)\n",
      " -- model.layers.15.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.15.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.15.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.15.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.15.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95626386\n",
      " -- 2.1987 bpw  accuracy: 0.95751792\n",
      " -- 2.2831 bpw  accuracy: 0.96172875\n",
      " -- 2.6768 bpw  accuracy: 0.96983413\n",
      " -- 3.1689 bpw  accuracy: 0.97728240\n",
      " -- 3.1705 bpw  accuracy: 0.97794465\n",
      " -- 4.0439 bpw  accuracy: 0.98457708\n",
      " -- 4.0471 bpw  accuracy: 0.98533395\n",
      " -- 4.0816 bpw  accuracy: 0.98681639\n",
      " -- 4.1381 bpw  accuracy: 0.98739989\n",
      " -- 4.1705 bpw  accuracy: 0.98887353\n",
      " -- 4.1902 bpw  accuracy: 0.98949779\n",
      " -- 4.2737 bpw  accuracy: 0.99013095\n",
      " -- 4.3295 bpw  accuracy: 0.99107960\n",
      " -- 5.2564 bpw  accuracy: 0.99404720\n",
      " -- 5.3295 bpw  accuracy: 0.99531776\n",
      " -- 6.0439 bpw  accuracy: 0.99520294\n",
      " -- 6.3381 bpw  accuracy: 0.99750200\n",
      " -- 8.0439 bpw  accuracy: 0.99868953\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.15 (Attention)        |\n",
      "| Duration: 5.55 seconds                       |\n",
      "| Completed step: 31/67                        |\n",
      "| Avg time / step (rolling): 8.69 seconds      |\n",
      "| Estimated remaining time: 5min 12sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.15 (MLP)\n",
      " -- model.layers.15.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.15.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.15.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.15.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.15.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.15.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.15.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.15.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.94262213\n",
      " -- 2.3230 bpw  accuracy: 0.94427331\n",
      " -- 2.5958 bpw  accuracy: 0.95352032\n",
      " -- 2.9120 bpw  accuracy: 0.95636337\n",
      " -- 3.2833 bpw  accuracy: 0.97094977\n",
      " -- 3.3655 bpw  accuracy: 0.97345572\n",
      " -- 3.6186 bpw  accuracy: 0.97723379\n",
      " -- 4.1368 bpw  accuracy: 0.98485082\n",
      " -- 4.1977 bpw  accuracy: 0.98628904\n",
      " -- 4.2662 bpw  accuracy: 0.98524349\n",
      " -- 4.3484 bpw  accuracy: 0.98721448\n",
      " -- 5.2491 bpw  accuracy: 0.99271602\n",
      " -- 5.3313 bpw  accuracy: 0.99375907\n",
      " -- 6.0713 bpw  accuracy: 0.99593683\n",
      " -- 6.3032 bpw  accuracy: 0.99623156\n",
      " -- 6.8687 bpw  accuracy: 0.99699676\n",
      " -- 8.0354 bpw  accuracy: 0.99888885\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.15 (MLP)              |\n",
      "| Duration: 11.77 seconds                      |\n",
      "| Completed step: 32/67                        |\n",
      "| Avg time / step (rolling): 8.69 seconds      |\n",
      "| Estimated remaining time: 5min 4sec          |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.16 (Attention)\n",
      " -- model.layers.16.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.16.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.16.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.16.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.16.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95775146\n",
      " -- 2.1987 bpw  accuracy: 0.95917234\n",
      " -- 2.2831 bpw  accuracy: 0.96334156\n",
      " -- 2.6768 bpw  accuracy: 0.97234084\n",
      " -- 3.1689 bpw  accuracy: 0.97828432\n",
      " -- 3.1705 bpw  accuracy: 0.97879367\n",
      " -- 4.0439 bpw  accuracy: 0.98602911\n",
      " -- 4.0471 bpw  accuracy: 0.98667578\n",
      " -- 4.0816 bpw  accuracy: 0.98685119\n",
      " -- 4.1381 bpw  accuracy: 0.98852150\n",
      " -- 4.1705 bpw  accuracy: 0.98918701\n",
      " -- 4.1902 bpw  accuracy: 0.98984279\n",
      " -- 4.2737 bpw  accuracy: 0.99055380\n",
      " -- 4.3295 bpw  accuracy: 0.99128540\n",
      " -- 5.2564 bpw  accuracy: 0.99471234\n",
      " -- 5.3295 bpw  accuracy: 0.99567838\n",
      " -- 6.0439 bpw  accuracy: 0.99607136\n",
      " -- 6.3381 bpw  accuracy: 0.99748814\n",
      " -- 8.0439 bpw  accuracy: 0.99891597\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.16 (Attention)        |\n",
      "| Duration: 5.76 seconds                       |\n",
      "| Completed step: 33/67                        |\n",
      "| Avg time / step (rolling): 8.69 seconds      |\n",
      "| Estimated remaining time: 4min 55sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.16 (MLP)\n",
      " -- model.layers.16.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.16.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.16.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.16.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.16.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.16.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.16.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.16.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.93628140\n",
      " -- 2.3230 bpw  accuracy: 0.93813161\n",
      " -- 2.5958 bpw  accuracy: 0.94832013\n",
      " -- 2.9120 bpw  accuracy: 0.95152429\n",
      " -- 3.2833 bpw  accuracy: 0.96776257\n",
      " -- 3.3655 bpw  accuracy: 0.97055127\n",
      " -- 3.6186 bpw  accuracy: 0.97475289\n",
      " -- 4.1368 bpw  accuracy: 0.98313145\n",
      " -- 4.1977 bpw  accuracy: 0.98474157\n",
      " -- 4.2662 bpw  accuracy: 0.98365237\n",
      " -- 4.3484 bpw  accuracy: 0.98583136\n",
      " -- 5.2491 bpw  accuracy: 0.99193052\n",
      " -- 5.3313 bpw  accuracy: 0.99308362\n",
      " -- 6.0713 bpw  accuracy: 0.99547105\n",
      " -- 6.3032 bpw  accuracy: 0.99584107\n",
      " -- 6.8687 bpw  accuracy: 0.99668594\n",
      " -- 8.0354 bpw  accuracy: 0.99875368\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.16 (MLP)              |\n",
      "| Duration: 11.78 seconds                      |\n",
      "| Completed step: 34/67                        |\n",
      "| Avg time / step (rolling): 8.70 seconds      |\n",
      "| Estimated remaining time: 4min 46sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.17 (Attention)\n",
      " -- model.layers.17.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.17.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.17.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.17.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.17.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95481503\n",
      " -- 2.1987 bpw  accuracy: 0.95651202\n",
      " -- 2.2831 bpw  accuracy: 0.96012862\n",
      " -- 2.6768 bpw  accuracy: 0.97026963\n",
      " -- 3.1689 bpw  accuracy: 0.97654320\n",
      " -- 3.1705 bpw  accuracy: 0.97751161\n",
      " -- 4.0439 bpw  accuracy: 0.98426057\n",
      " -- 4.0471 bpw  accuracy: 0.98556748\n",
      " -- 4.0816 bpw  accuracy: 0.98674443\n",
      " -- 4.1381 bpw  accuracy: 0.98735944\n",
      " -- 4.1705 bpw  accuracy: 0.98831394\n",
      " -- 4.1902 bpw  accuracy: 0.98907267\n",
      " -- 4.2737 bpw  accuracy: 0.98962384\n",
      " -- 4.3295 bpw  accuracy: 0.99058313\n",
      " -- 5.2564 bpw  accuracy: 0.99409452\n",
      " -- 5.3295 bpw  accuracy: 0.99533699\n",
      " -- 6.0439 bpw  accuracy: 0.99548246\n",
      " -- 6.3381 bpw  accuracy: 0.99748359\n",
      " -- 8.0439 bpw  accuracy: 0.99872417\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.17 (Attention)        |\n",
      "| Duration: 5.77 seconds                       |\n",
      "| Completed step: 35/67                        |\n",
      "| Avg time / step (rolling): 8.70 seconds      |\n",
      "| Estimated remaining time: 4min 38sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.17 (MLP)\n",
      " -- model.layers.17.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.17.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.17.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.17.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.17.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.17.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.17.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.17.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92912220\n",
      " -- 2.3230 bpw  accuracy: 0.93115803\n",
      " -- 2.5958 bpw  accuracy: 0.94274392\n",
      " -- 2.9120 bpw  accuracy: 0.94648848\n",
      " -- 3.2833 bpw  accuracy: 0.96405168\n",
      " -- 3.3655 bpw  accuracy: 0.96716090\n",
      " -- 3.6186 bpw  accuracy: 0.97199072\n",
      " -- 4.1368 bpw  accuracy: 0.98110595\n",
      " -- 4.1977 bpw  accuracy: 0.98295531\n",
      " -- 4.2662 bpw  accuracy: 0.98174607\n",
      " -- 4.3484 bpw  accuracy: 0.98418078\n",
      " -- 5.2491 bpw  accuracy: 0.99097332\n",
      " -- 5.3313 bpw  accuracy: 0.99227073\n",
      " -- 6.0713 bpw  accuracy: 0.99493469\n",
      " -- 6.3032 bpw  accuracy: 0.99534089\n",
      " -- 6.8687 bpw  accuracy: 0.99633435\n",
      " -- 8.0354 bpw  accuracy: 0.99860302\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.17 (MLP)              |\n",
      "| Duration: 11.81 seconds                      |\n",
      "| Completed step: 36/67                        |\n",
      "| Avg time / step (rolling): 8.70 seconds      |\n",
      "| Estimated remaining time: 4min 29sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.18 (Attention)\n",
      " -- model.layers.18.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.18.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.18.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.18.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.18.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95445145\n",
      " -- 2.1987 bpw  accuracy: 0.95601107\n",
      " -- 2.2831 bpw  accuracy: 0.95951205\n",
      " -- 2.6768 bpw  accuracy: 0.96771590\n",
      " -- 3.1689 bpw  accuracy: 0.97494992\n",
      " -- 3.1705 bpw  accuracy: 0.97674620\n",
      " -- 4.0439 bpw  accuracy: 0.98151711\n",
      " -- 4.0471 bpw  accuracy: 0.98380830\n",
      " -- 4.0816 bpw  accuracy: 0.98504727\n",
      " -- 4.1381 bpw  accuracy: 0.98518002\n",
      " -- 4.1705 bpw  accuracy: 0.98750606\n",
      " -- 4.1902 bpw  accuracy: 0.98889123\n",
      " -- 4.2737 bpw  accuracy: 0.98869731\n",
      " -- 4.3295 bpw  accuracy: 0.99063376\n",
      " -- 5.2564 bpw  accuracy: 0.99239386\n",
      " -- 5.3295 bpw  accuracy: 0.99511627\n",
      " -- 6.0439 bpw  accuracy: 0.99331147\n",
      " -- 6.3381 bpw  accuracy: 0.99696634\n",
      " -- 8.0439 bpw  accuracy: 0.99809707\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.18 (Attention)        |\n",
      "| Duration: 5.78 seconds                       |\n",
      "| Completed step: 37/67                        |\n",
      "| Avg time / step (rolling): 8.73 seconds      |\n",
      "| Estimated remaining time: 4min 21sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.18 (MLP)\n",
      " -- model.layers.18.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.18.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.18.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.18.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.18.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.18.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.18.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.18.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92456973\n",
      " -- 2.3230 bpw  accuracy: 0.92673217\n",
      " -- 2.5958 bpw  accuracy: 0.93906502\n",
      " -- 2.9120 bpw  accuracy: 0.94310747\n",
      " -- 3.2833 bpw  accuracy: 0.96180997\n",
      " -- 3.3655 bpw  accuracy: 0.96507187\n",
      " -- 3.6186 bpw  accuracy: 0.97022627\n",
      " -- 4.1368 bpw  accuracy: 0.97983615\n",
      " -- 4.1977 bpw  accuracy: 0.98179624\n",
      " -- 4.2662 bpw  accuracy: 0.98063030\n",
      " -- 4.3484 bpw  accuracy: 0.98317850\n",
      " -- 5.2491 bpw  accuracy: 0.99042166\n",
      " -- 5.3313 bpw  accuracy: 0.99177420\n",
      " -- 6.0713 bpw  accuracy: 0.99459838\n",
      " -- 6.3032 bpw  accuracy: 0.99506276\n",
      " -- 6.8687 bpw  accuracy: 0.99613629\n",
      " -- 8.0354 bpw  accuracy: 0.99849214\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.18 (MLP)              |\n",
      "| Duration: 11.83 seconds                      |\n",
      "| Completed step: 38/67                        |\n",
      "| Avg time / step (rolling): 8.74 seconds      |\n",
      "| Estimated remaining time: 4min 13sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.19 (Attention)\n",
      " -- model.layers.19.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.19.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.19.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.19.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.19.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95422680\n",
      " -- 2.1987 bpw  accuracy: 0.95544862\n",
      " -- 2.2831 bpw  accuracy: 0.95966820\n",
      " -- 2.6768 bpw  accuracy: 0.96883502\n",
      " -- 3.1689 bpw  accuracy: 0.97590440\n",
      " -- 3.1705 bpw  accuracy: 0.97687315\n",
      " -- 4.0439 bpw  accuracy: 0.98321555\n",
      " -- 4.0471 bpw  accuracy: 0.98449830\n",
      " -- 4.0816 bpw  accuracy: 0.98544102\n",
      " -- 4.1381 bpw  accuracy: 0.98688027\n",
      " -- 4.1705 bpw  accuracy: 0.98829356\n",
      " -- 4.1902 bpw  accuracy: 0.98911099\n",
      " -- 4.2737 bpw  accuracy: 0.98965117\n",
      " -- 4.3295 bpw  accuracy: 0.99036761\n",
      " -- 5.2564 bpw  accuracy: 0.99405158\n",
      " -- 5.3295 bpw  accuracy: 0.99511587\n",
      " -- 6.0439 bpw  accuracy: 0.99541043\n",
      " -- 6.3381 bpw  accuracy: 0.99705652\n",
      " -- 8.0439 bpw  accuracy: 0.99868465\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.19 (Attention)        |\n",
      "| Duration: 5.77 seconds                       |\n",
      "| Completed step: 39/67                        |\n",
      "| Avg time / step (rolling): 8.76 seconds      |\n",
      "| Estimated remaining time: 4min 5sec          |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.19 (MLP)\n",
      " -- model.layers.19.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.19.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.19.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.19.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.19.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.19.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.19.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.19.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92249113\n",
      " -- 2.3230 bpw  accuracy: 0.92473021\n",
      " -- 2.5958 bpw  accuracy: 0.93718146\n",
      " -- 2.9120 bpw  accuracy: 0.94130757\n",
      " -- 3.2833 bpw  accuracy: 0.96071592\n",
      " -- 3.3655 bpw  accuracy: 0.96418699\n",
      " -- 3.6186 bpw  accuracy: 0.96940790\n",
      " -- 4.1368 bpw  accuracy: 0.97923801\n",
      " -- 4.1977 bpw  accuracy: 0.98129558\n",
      " -- 4.2662 bpw  accuracy: 0.98000722\n",
      " -- 4.3484 bpw  accuracy: 0.98273522\n",
      " -- 5.2491 bpw  accuracy: 0.99007172\n",
      " -- 5.3313 bpw  accuracy: 0.99153566\n",
      " -- 6.0713 bpw  accuracy: 0.99437803\n",
      " -- 6.3032 bpw  accuracy: 0.99488149\n",
      " -- 6.8687 bpw  accuracy: 0.99595643\n",
      " -- 8.0354 bpw  accuracy: 0.99840883\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.19 (MLP)              |\n",
      "| Duration: 11.80 seconds                      |\n",
      "| Completed step: 40/67                        |\n",
      "| Avg time / step (rolling): 8.76 seconds      |\n",
      "| Estimated remaining time: 3min 56sec         |\n",
      "| Last checkpoint layer: model.layers.14 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.20 (Attention)\n",
      " -- model.layers.20.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.20.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.20.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.20.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.20.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.95915629\n",
      " -- 2.1987 bpw  accuracy: 0.96054151\n",
      " -- 2.2831 bpw  accuracy: 0.96385840\n",
      " -- 2.6768 bpw  accuracy: 0.97170895\n",
      " -- 3.1689 bpw  accuracy: 0.97790187\n",
      " -- 3.1705 bpw  accuracy: 0.97991031\n",
      " -- 4.0439 bpw  accuracy: 0.98352898\n",
      " -- 4.0471 bpw  accuracy: 0.98613274\n",
      " -- 4.0816 bpw  accuracy: 0.98624768\n",
      " -- 4.1381 bpw  accuracy: 0.98804064\n",
      " -- 4.1705 bpw  accuracy: 0.98972820\n",
      " -- 4.1902 bpw  accuracy: 0.99058154\n",
      " -- 4.2737 bpw  accuracy: 0.99082347\n",
      " -- 4.3295 bpw  accuracy: 0.99176372\n",
      " -- 5.2564 bpw  accuracy: 0.99428112\n",
      " -- 5.3295 bpw  accuracy: 0.99579929\n",
      " -- 6.0439 bpw  accuracy: 0.99524883\n",
      " -- 6.3381 bpw  accuracy: 0.99764993\n",
      " -- 8.0439 bpw  accuracy: 0.99870489\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.20 (Attention)        |\n",
      "| Duration: 5.79 seconds                       |\n",
      "| Completed step: 41/67                        |\n",
      "| Avg time / step (rolling): 8.79 seconds      |\n",
      "| Estimated remaining time: 3min 48sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.20 (MLP)\n",
      " -- model.layers.20.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.20.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.20.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.20.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.20.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.20.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.20.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.20.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92327149\n",
      " -- 2.3230 bpw  accuracy: 0.92541377\n",
      " -- 2.5958 bpw  accuracy: 0.93722323\n",
      " -- 2.9120 bpw  accuracy: 0.94102794\n",
      " -- 3.2833 bpw  accuracy: 0.96128100\n",
      " -- 3.3655 bpw  accuracy: 0.96450213\n",
      " -- 3.6186 bpw  accuracy: 0.96946278\n",
      " -- 4.1368 bpw  accuracy: 0.97976164\n",
      " -- 4.1977 bpw  accuracy: 0.98165472\n",
      " -- 4.2662 bpw  accuracy: 0.98038954\n",
      " -- 4.3484 bpw  accuracy: 0.98295043\n",
      " -- 5.2491 bpw  accuracy: 0.99032682\n",
      " -- 5.3313 bpw  accuracy: 0.99167013\n",
      " -- 6.0713 bpw  accuracy: 0.99459127\n",
      " -- 6.3032 bpw  accuracy: 0.99500313\n",
      " -- 6.8687 bpw  accuracy: 0.99599972\n",
      " -- 8.0354 bpw  accuracy: 0.99848528\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.20 (MLP)              |\n",
      "| Duration: 11.81 seconds                      |\n",
      "| Completed step: 42/67                        |\n",
      "| Avg time / step (rolling): 8.79 seconds      |\n",
      "| Estimated remaining time: 3min 39sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.21 (Attention)\n",
      " -- model.layers.21.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.21.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.21.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.21.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.21.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96356912\n",
      " -- 2.1987 bpw  accuracy: 0.96493664\n",
      " -- 2.2831 bpw  accuracy: 0.96766072\n",
      " -- 2.6768 bpw  accuracy: 0.97499635\n",
      " -- 3.1689 bpw  accuracy: 0.98065279\n",
      " -- 3.1705 bpw  accuracy: 0.98182971\n",
      " -- 4.0439 bpw  accuracy: 0.98590589\n",
      " -- 4.0471 bpw  accuracy: 0.98752731\n",
      " -- 4.0816 bpw  accuracy: 0.98880385\n",
      " -- 4.1381 bpw  accuracy: 0.98943436\n",
      " -- 4.1705 bpw  accuracy: 0.99056505\n",
      " -- 4.1902 bpw  accuracy: 0.99133943\n",
      " -- 4.2737 bpw  accuracy: 0.99169669\n",
      " -- 4.3295 bpw  accuracy: 0.99241745\n",
      " -- 5.2564 bpw  accuracy: 0.99512669\n",
      " -- 5.3295 bpw  accuracy: 0.99619747\n",
      " -- 6.0439 bpw  accuracy: 0.99601840\n",
      " -- 6.3381 bpw  accuracy: 0.99791808\n",
      " -- 8.0439 bpw  accuracy: 0.99875218\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.21 (Attention)        |\n",
      "| Duration: 5.77 seconds                       |\n",
      "| Completed step: 43/67                        |\n",
      "| Avg time / step (rolling): 8.79 seconds      |\n",
      "| Estimated remaining time: 3min 30sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.21 (MLP)\n",
      " -- model.layers.21.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.21.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.21.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.21.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.21.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.21.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.21.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.21.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92470686\n",
      " -- 2.3230 bpw  accuracy: 0.92675758\n",
      " -- 2.5958 bpw  accuracy: 0.93779153\n",
      " -- 2.9120 bpw  accuracy: 0.94132583\n",
      " -- 3.2833 bpw  accuracy: 0.96205283\n",
      " -- 3.3655 bpw  accuracy: 0.96519862\n",
      " -- 3.6186 bpw  accuracy: 0.96977405\n",
      " -- 4.1368 bpw  accuracy: 0.98027060\n",
      " -- 4.1977 bpw  accuracy: 0.98206982\n",
      " -- 4.2662 bpw  accuracy: 0.98077391\n",
      " -- 4.3484 bpw  accuracy: 0.98328466\n",
      " -- 5.2491 bpw  accuracy: 0.99050914\n",
      " -- 5.3313 bpw  accuracy: 0.99183884\n",
      " -- 6.0713 bpw  accuracy: 0.99470734\n",
      " -- 6.3032 bpw  accuracy: 0.99509390\n",
      " -- 6.8687 bpw  accuracy: 0.99598776\n",
      " -- 8.0354 bpw  accuracy: 0.99851162\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.21 (MLP)              |\n",
      "| Duration: 11.82 seconds                      |\n",
      "| Completed step: 44/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 3min 22sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.22 (Attention)\n",
      " -- model.layers.22.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.22.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.22.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.22.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.22.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96981807\n",
      " -- 2.1987 bpw  accuracy: 0.97141285\n",
      " -- 2.2831 bpw  accuracy: 0.97446786\n",
      " -- 2.6768 bpw  accuracy: 0.97942787\n",
      " -- 3.1689 bpw  accuracy: 0.98276877\n",
      " -- 3.1705 bpw  accuracy: 0.98511980\n",
      " -- 4.0439 bpw  accuracy: 0.98607745\n",
      " -- 4.0471 bpw  accuracy: 0.98904100\n",
      " -- 4.0816 bpw  accuracy: 0.99003503\n",
      " -- 4.1381 bpw  accuracy: 0.99083114\n",
      " -- 4.1705 bpw  accuracy: 0.99202634\n",
      " -- 4.1902 bpw  accuracy: 0.99286727\n",
      " -- 4.2737 bpw  accuracy: 0.99289318\n",
      " -- 4.3295 bpw  accuracy: 0.99361151\n",
      " -- 5.2564 bpw  accuracy: 0.99533732\n",
      " -- 5.3295 bpw  accuracy: 0.99650853\n",
      " -- 6.0439 bpw  accuracy: 0.99586010\n",
      " -- 6.3381 bpw  accuracy: 0.99822505\n",
      " -- 8.0439 bpw  accuracy: 0.99871359\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.22 (Attention)        |\n",
      "| Duration: 5.75 seconds                       |\n",
      "| Completed step: 45/67                        |\n",
      "| Avg time / step (rolling): 8.79 seconds      |\n",
      "| Estimated remaining time: 3min 13sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.22 (MLP)\n",
      " -- model.layers.22.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.22.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.22.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.22.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.22.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.22.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.22.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.22.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92446141\n",
      " -- 2.3230 bpw  accuracy: 0.92646836\n",
      " -- 2.5958 bpw  accuracy: 0.93729662\n",
      " -- 2.9120 bpw  accuracy: 0.94070604\n",
      " -- 3.2833 bpw  accuracy: 0.96179135\n",
      " -- 3.3655 bpw  accuracy: 0.96494809\n",
      " -- 3.6186 bpw  accuracy: 0.96946940\n",
      " -- 4.1368 bpw  accuracy: 0.98019204\n",
      " -- 4.1977 bpw  accuracy: 0.98200259\n",
      " -- 4.2662 bpw  accuracy: 0.98063633\n",
      " -- 4.3484 bpw  accuracy: 0.98314922\n",
      " -- 5.2491 bpw  accuracy: 0.99044702\n",
      " -- 5.3313 bpw  accuracy: 0.99178386\n",
      " -- 6.0713 bpw  accuracy: 0.99470706\n",
      " -- 6.3032 bpw  accuracy: 0.99506424\n",
      " -- 6.8687 bpw  accuracy: 0.99595143\n",
      " -- 8.0354 bpw  accuracy: 0.99851377\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.22 (MLP)              |\n",
      "| Duration: 11.85 seconds                      |\n",
      "| Completed step: 46/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 3min 4sec          |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.23 (Attention)\n",
      " -- model.layers.23.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.23.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.23.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.23.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.23.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96574134\n",
      " -- 2.1987 bpw  accuracy: 0.96709330\n",
      " -- 2.2831 bpw  accuracy: 0.97034607\n",
      " -- 2.6768 bpw  accuracy: 0.97623631\n",
      " -- 3.1689 bpw  accuracy: 0.98124894\n",
      " -- 3.1705 bpw  accuracy: 0.98219476\n",
      " -- 4.0439 bpw  accuracy: 0.98542375\n",
      " -- 4.0471 bpw  accuracy: 0.98689171\n",
      " -- 4.0816 bpw  accuracy: 0.98907569\n",
      " -- 4.1381 bpw  accuracy: 0.98918809\n",
      " -- 4.1705 bpw  accuracy: 0.99134758\n",
      " -- 4.1902 bpw  accuracy: 0.99201284\n",
      " -- 4.2737 bpw  accuracy: 0.99241693\n",
      " -- 4.3295 bpw  accuracy: 0.99316308\n",
      " -- 5.2564 bpw  accuracy: 0.99542204\n",
      " -- 5.3295 bpw  accuracy: 0.99641980\n",
      " -- 6.0439 bpw  accuracy: 0.99614928\n",
      " -- 6.3381 bpw  accuracy: 0.99813274\n",
      " -- 8.0439 bpw  accuracy: 0.99888288\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.23 (Attention)        |\n",
      "| Duration: 5.77 seconds                       |\n",
      "| Completed step: 47/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 2min 55sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.23 (MLP)\n",
      " -- model.layers.23.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.23.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.23.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.23.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.23.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.23.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.23.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.23.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92388403\n",
      " -- 2.3230 bpw  accuracy: 0.92587719\n",
      " -- 2.5958 bpw  accuracy: 0.93648405\n",
      " -- 2.9120 bpw  accuracy: 0.93985926\n",
      " -- 3.2833 bpw  accuracy: 0.96144546\n",
      " -- 3.3655 bpw  accuracy: 0.96462432\n",
      " -- 3.6186 bpw  accuracy: 0.96907901\n",
      " -- 4.1368 bpw  accuracy: 0.97999720\n",
      " -- 4.1977 bpw  accuracy: 0.98183386\n",
      " -- 4.2662 bpw  accuracy: 0.98048625\n",
      " -- 4.3484 bpw  accuracy: 0.98299471\n",
      " -- 5.2491 bpw  accuracy: 0.99037223\n",
      " -- 5.3313 bpw  accuracy: 0.99170432\n",
      " -- 6.0713 bpw  accuracy: 0.99466634\n",
      " -- 6.3032 bpw  accuracy: 0.99502822\n",
      " -- 6.8687 bpw  accuracy: 0.99589369\n",
      " -- 8.0354 bpw  accuracy: 0.99852232\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.23 (MLP)              |\n",
      "| Duration: 11.83 seconds                      |\n",
      "| Completed step: 48/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 2min 47sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.24 (Attention)\n",
      " -- model.layers.24.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.24.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.24.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.24.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.24.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96717225\n",
      " -- 2.1987 bpw  accuracy: 0.96809172\n",
      " -- 2.2831 bpw  accuracy: 0.97066257\n",
      " -- 2.6768 bpw  accuracy: 0.97582636\n",
      " -- 3.1689 bpw  accuracy: 0.98126119\n",
      " -- 3.1705 bpw  accuracy: 0.98264929\n",
      " -- 4.0439 bpw  accuracy: 0.98576114\n",
      " -- 4.0471 bpw  accuracy: 0.98733645\n",
      " -- 4.0816 bpw  accuracy: 0.98903113\n",
      " -- 4.1381 bpw  accuracy: 0.98955210\n",
      " -- 4.1705 bpw  accuracy: 0.99169184\n",
      " -- 4.1902 bpw  accuracy: 0.99225594\n",
      " -- 4.2737 bpw  accuracy: 0.99262687\n",
      " -- 4.3295 bpw  accuracy: 0.99332604\n",
      " -- 5.2564 bpw  accuracy: 0.99557911\n",
      " -- 5.3295 bpw  accuracy: 0.99645773\n",
      " -- 6.0439 bpw  accuracy: 0.99626227\n",
      " -- 6.3381 bpw  accuracy: 0.99804444\n",
      " -- 8.0439 bpw  accuracy: 0.99891021\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.24 (Attention)        |\n",
      "| Duration: 5.76 seconds                       |\n",
      "| Completed step: 49/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 2min 38sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.24 (MLP)\n",
      " -- model.layers.24.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.24.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.24.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.24.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.24.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.24.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.24.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.24.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92323120\n",
      " -- 2.3230 bpw  accuracy: 0.92524314\n",
      " -- 2.5958 bpw  accuracy: 0.93581481\n",
      " -- 2.9120 bpw  accuracy: 0.93914769\n",
      " -- 3.2833 bpw  accuracy: 0.96114032\n",
      " -- 3.3655 bpw  accuracy: 0.96436342\n",
      " -- 3.6186 bpw  accuracy: 0.96876573\n",
      " -- 4.1368 bpw  accuracy: 0.97988887\n",
      " -- 4.1977 bpw  accuracy: 0.98171307\n",
      " -- 4.2662 bpw  accuracy: 0.98032892\n",
      " -- 4.3484 bpw  accuracy: 0.98288732\n",
      " -- 5.2491 bpw  accuracy: 0.99031313\n",
      " -- 5.3313 bpw  accuracy: 0.99165451\n",
      " -- 6.0713 bpw  accuracy: 0.99462464\n",
      " -- 6.3032 bpw  accuracy: 0.99499656\n",
      " -- 6.8687 bpw  accuracy: 0.99584201\n",
      " -- 8.0354 bpw  accuracy: 0.99850420\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.24 (MLP)              |\n",
      "| Duration: 11.80 seconds                      |\n",
      "| Completed step: 50/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 2min 29sec         |\n",
      "| Last checkpoint layer: model.layers.19 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.25 (Attention)\n",
      " -- model.layers.25.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.25.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.25.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.25.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.25.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96436763\n",
      " -- 2.1987 bpw  accuracy: 0.96558903\n",
      " -- 2.2831 bpw  accuracy: 0.96930521\n",
      " -- 2.6768 bpw  accuracy: 0.97547690\n",
      " -- 3.1689 bpw  accuracy: 0.98188278\n",
      " -- 3.1705 bpw  accuracy: 0.98294663\n",
      " -- 4.0439 bpw  accuracy: 0.98730450\n",
      " -- 4.0471 bpw  accuracy: 0.98870545\n",
      " -- 4.0816 bpw  accuracy: 0.98993762\n",
      " -- 4.1381 bpw  accuracy: 0.99019095\n",
      " -- 4.1705 bpw  accuracy: 0.99134702\n",
      " -- 4.1902 bpw  accuracy: 0.99155283\n",
      " -- 4.2737 bpw  accuracy: 0.99210043\n",
      " -- 4.3295 bpw  accuracy: 0.99314964\n",
      " -- 5.2564 bpw  accuracy: 0.99536042\n",
      " -- 5.3295 bpw  accuracy: 0.99641401\n",
      " -- 6.0439 bpw  accuracy: 0.99618841\n",
      " -- 6.3381 bpw  accuracy: 0.99797924\n",
      " -- 8.0439 bpw  accuracy: 0.99888721\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.25 (Attention)        |\n",
      "| Duration: 5.80 seconds                       |\n",
      "| Completed step: 51/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 2min 20sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.25 (MLP)\n",
      " -- model.layers.25.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.25.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.25.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.25.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.25.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.25.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.25.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.25.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92193390\n",
      " -- 2.3230 bpw  accuracy: 0.92397678\n",
      " -- 2.5958 bpw  accuracy: 0.93450121\n",
      " -- 2.9120 bpw  accuracy: 0.93785056\n",
      " -- 3.2833 bpw  accuracy: 0.96050274\n",
      " -- 3.3655 bpw  accuracy: 0.96371103\n",
      " -- 3.6186 bpw  accuracy: 0.96810153\n",
      " -- 4.1368 bpw  accuracy: 0.97947544\n",
      " -- 4.1977 bpw  accuracy: 0.98136431\n",
      " -- 4.2662 bpw  accuracy: 0.98002776\n",
      " -- 4.3484 bpw  accuracy: 0.98257111\n",
      " -- 5.2491 bpw  accuracy: 0.99017498\n",
      " -- 5.3313 bpw  accuracy: 0.99150538\n",
      " -- 6.0713 bpw  accuracy: 0.99455121\n",
      " -- 6.3032 bpw  accuracy: 0.99493374\n",
      " -- 6.8687 bpw  accuracy: 0.99578864\n",
      " -- 8.0354 bpw  accuracy: 0.99850406\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.25 (MLP)              |\n",
      "| Duration: 11.81 seconds                      |\n",
      "| Completed step: 52/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 2min 11sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.26 (Attention)\n",
      " -- model.layers.26.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.26.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.26.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.26.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.26.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96416207\n",
      " -- 2.1987 bpw  accuracy: 0.96536678\n",
      " -- 2.2831 bpw  accuracy: 0.96821668\n",
      " -- 2.6768 bpw  accuracy: 0.97422619\n",
      " -- 3.1689 bpw  accuracy: 0.98107373\n",
      " -- 3.1705 bpw  accuracy: 0.98201594\n",
      " -- 4.0439 bpw  accuracy: 0.98594789\n",
      " -- 4.0471 bpw  accuracy: 0.98724644\n",
      " -- 4.0816 bpw  accuracy: 0.98896909\n",
      " -- 4.1381 bpw  accuracy: 0.98982135\n",
      " -- 4.1705 bpw  accuracy: 0.99120278\n",
      " -- 4.1902 bpw  accuracy: 0.99171277\n",
      " -- 4.2737 bpw  accuracy: 0.99220360\n",
      " -- 4.3295 bpw  accuracy: 0.99298233\n",
      " -- 5.2564 bpw  accuracy: 0.99552957\n",
      " -- 5.3295 bpw  accuracy: 0.99638867\n",
      " -- 6.0439 bpw  accuracy: 0.99642305\n",
      " -- 6.3381 bpw  accuracy: 0.99802327\n",
      " -- 8.0439 bpw  accuracy: 0.99892531\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.26 (Attention)        |\n",
      "| Duration: 5.81 seconds                       |\n",
      "| Completed step: 53/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 2min 3sec          |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.26 (MLP)\n",
      " -- model.layers.26.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.26.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.26.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.26.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.26.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.26.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.26.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.26.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92122028\n",
      " -- 2.3230 bpw  accuracy: 0.92327458\n",
      " -- 2.5958 bpw  accuracy: 0.93373189\n",
      " -- 2.9120 bpw  accuracy: 0.93705913\n",
      " -- 3.2833 bpw  accuracy: 0.96005287\n",
      " -- 3.3655 bpw  accuracy: 0.96334137\n",
      " -- 3.6186 bpw  accuracy: 0.96773241\n",
      " -- 4.1368 bpw  accuracy: 0.97927783\n",
      " -- 4.1977 bpw  accuracy: 0.98119188\n",
      " -- 4.2662 bpw  accuracy: 0.97978926\n",
      " -- 4.3484 bpw  accuracy: 0.98238886\n",
      " -- 5.2491 bpw  accuracy: 0.99005875\n",
      " -- 5.3313 bpw  accuracy: 0.99141671\n",
      " -- 6.0713 bpw  accuracy: 0.99448127\n",
      " -- 6.3032 bpw  accuracy: 0.99486428\n",
      " -- 6.8687 bpw  accuracy: 0.99571300\n",
      " -- 8.0354 bpw  accuracy: 0.99845167\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.26 (MLP)              |\n",
      "| Duration: 11.82 seconds                      |\n",
      "| Completed step: 54/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 1min 54sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.27 (Attention)\n",
      " -- model.layers.27.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.27.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.27.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.27.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.27.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96642375\n",
      " -- 2.1987 bpw  accuracy: 0.96763761\n",
      " -- 2.2831 bpw  accuracy: 0.97169567\n",
      " -- 2.6768 bpw  accuracy: 0.97781559\n",
      " -- 3.1689 bpw  accuracy: 0.98213640\n",
      " -- 3.1705 bpw  accuracy: 0.98291815\n",
      " -- 4.0439 bpw  accuracy: 0.98701463\n",
      " -- 4.0471 bpw  accuracy: 0.98792689\n",
      " -- 4.0816 bpw  accuracy: 0.98888358\n",
      " -- 4.1381 bpw  accuracy: 0.98994559\n",
      " -- 4.1705 bpw  accuracy: 0.99134892\n",
      " -- 4.1902 bpw  accuracy: 0.99194008\n",
      " -- 4.2737 bpw  accuracy: 0.99231383\n",
      " -- 4.3295 bpw  accuracy: 0.99288951\n",
      " -- 5.2564 bpw  accuracy: 0.99541352\n",
      " -- 5.3295 bpw  accuracy: 0.99644663\n",
      " -- 6.0439 bpw  accuracy: 0.99619161\n",
      " -- 6.3381 bpw  accuracy: 0.99816542\n",
      " -- 8.0439 bpw  accuracy: 0.99900933\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.27 (Attention)        |\n",
      "| Duration: 5.76 seconds                       |\n",
      "| Completed step: 55/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 1min 45sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.27 (MLP)\n",
      " -- model.layers.27.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.27.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.27.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.27.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.27.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.27.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.27.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.27.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.92047388\n",
      " -- 2.3230 bpw  accuracy: 0.92262016\n",
      " -- 2.5958 bpw  accuracy: 0.93292905\n",
      " -- 2.9120 bpw  accuracy: 0.93625732\n",
      " -- 3.2833 bpw  accuracy: 0.95964169\n",
      " -- 3.3655 bpw  accuracy: 0.96296161\n",
      " -- 3.6186 bpw  accuracy: 0.96729059\n",
      " -- 4.1368 bpw  accuracy: 0.97893252\n",
      " -- 4.1977 bpw  accuracy: 0.98090346\n",
      " -- 4.2662 bpw  accuracy: 0.97956124\n",
      " -- 4.3484 bpw  accuracy: 0.98219910\n",
      " -- 5.2491 bpw  accuracy: 0.98994084\n",
      " -- 5.3313 bpw  accuracy: 0.99131786\n",
      " -- 6.0713 bpw  accuracy: 0.99438726\n",
      " -- 6.3032 bpw  accuracy: 0.99481146\n",
      " -- 6.8687 bpw  accuracy: 0.99565239\n",
      " -- 8.0354 bpw  accuracy: 0.99842661\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.27 (MLP)              |\n",
      "| Duration: 11.84 seconds                      |\n",
      "| Completed step: 56/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 1min 36sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.28 (Attention)\n",
      " -- model.layers.28.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.28.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.28.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.28.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.28.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.96013237\n",
      " -- 2.1987 bpw  accuracy: 0.96162738\n",
      " -- 2.2831 bpw  accuracy: 0.96579101\n",
      " -- 2.6768 bpw  accuracy: 0.97367572\n",
      " -- 3.1689 bpw  accuracy: 0.97913630\n",
      " -- 3.1705 bpw  accuracy: 0.97996507\n",
      " -- 4.0439 bpw  accuracy: 0.98527417\n",
      " -- 4.0471 bpw  accuracy: 0.98643902\n",
      " -- 4.0816 bpw  accuracy: 0.98786318\n",
      " -- 4.1381 bpw  accuracy: 0.98873022\n",
      " -- 4.1705 bpw  accuracy: 0.98983945\n",
      " -- 4.1902 bpw  accuracy: 0.99067572\n",
      " -- 4.2737 bpw  accuracy: 0.99101114\n",
      " -- 4.3295 bpw  accuracy: 0.99200758\n",
      " -- 5.2564 bpw  accuracy: 0.99483661\n",
      " -- 5.3295 bpw  accuracy: 0.99603565\n",
      " -- 6.0439 bpw  accuracy: 0.99583949\n",
      " -- 6.3381 bpw  accuracy: 0.99765329\n",
      " -- 8.0439 bpw  accuracy: 0.99885412\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.28 (Attention)        |\n",
      "| Duration: 5.74 seconds                       |\n",
      "| Completed step: 57/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 1min 27sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.28 (MLP)\n",
      " -- model.layers.28.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.28.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.28.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.28.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.28.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.28.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.28.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.28.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91849856\n",
      " -- 2.3230 bpw  accuracy: 0.92080791\n",
      " -- 2.5958 bpw  accuracy: 0.93128741\n",
      " -- 2.9120 bpw  accuracy: 0.93476188\n",
      " -- 3.2833 bpw  accuracy: 0.95859436\n",
      " -- 3.3655 bpw  accuracy: 0.96201804\n",
      " -- 3.6186 bpw  accuracy: 0.96650023\n",
      " -- 4.1368 bpw  accuracy: 0.97825909\n",
      " -- 4.1977 bpw  accuracy: 0.98028612\n",
      " -- 4.2662 bpw  accuracy: 0.97900665\n",
      " -- 4.3484 bpw  accuracy: 0.98172821\n",
      " -- 5.2491 bpw  accuracy: 0.98964854\n",
      " -- 5.3313 bpw  accuracy: 0.99107212\n",
      " -- 6.0713 bpw  accuracy: 0.99417185\n",
      " -- 6.3032 bpw  accuracy: 0.99465196\n",
      " -- 6.8687 bpw  accuracy: 0.99552641\n",
      " -- 8.0354 bpw  accuracy: 0.99833402\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.28 (MLP)              |\n",
      "| Duration: 11.81 seconds                      |\n",
      "| Completed step: 58/67                        |\n",
      "| Avg time / step (rolling): 8.79 seconds      |\n",
      "| Estimated remaining time: 1min 19sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.29 (Attention)\n",
      " -- model.layers.29.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.29.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.29.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.29.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.29.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.94959478\n",
      " -- 2.1987 bpw  accuracy: 0.95175679\n",
      " -- 2.2831 bpw  accuracy: 0.95819673\n",
      " -- 2.6768 bpw  accuracy: 0.96785375\n",
      " -- 3.1689 bpw  accuracy: 0.97389325\n",
      " -- 3.1705 bpw  accuracy: 0.97492779\n",
      " -- 4.0439 bpw  accuracy: 0.98223547\n",
      " -- 4.0471 bpw  accuracy: 0.98353805\n",
      " -- 4.0816 bpw  accuracy: 0.98465463\n",
      " -- 4.1381 bpw  accuracy: 0.98569523\n",
      " -- 4.1705 bpw  accuracy: 0.98720729\n",
      " -- 4.1902 bpw  accuracy: 0.98811169\n",
      " -- 4.2737 bpw  accuracy: 0.98904489\n",
      " -- 4.3295 bpw  accuracy: 0.98982535\n",
      " -- 5.2564 bpw  accuracy: 0.99378787\n",
      " -- 5.3295 bpw  accuracy: 0.99492121\n",
      " -- 6.0439 bpw  accuracy: 0.99512474\n",
      " -- 6.3381 bpw  accuracy: 0.99735534\n",
      " -- 8.0439 bpw  accuracy: 0.99861763\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.29 (Attention)        |\n",
      "| Duration: 5.79 seconds                       |\n",
      "| Completed step: 59/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 1min 10sec         |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.29 (MLP)\n",
      " -- model.layers.29.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.29.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.29.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.29.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.29.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.29.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.29.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.29.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91885528\n",
      " -- 2.3230 bpw  accuracy: 0.92112119\n",
      " -- 2.5958 bpw  accuracy: 0.93184428\n",
      " -- 2.9120 bpw  accuracy: 0.93536482\n",
      " -- 3.2833 bpw  accuracy: 0.95858204\n",
      " -- 3.3655 bpw  accuracy: 0.96198166\n",
      " -- 3.6186 bpw  accuracy: 0.96661857\n",
      " -- 4.1368 bpw  accuracy: 0.97809536\n",
      " -- 4.1977 bpw  accuracy: 0.98011727\n",
      " -- 4.2662 bpw  accuracy: 0.97889575\n",
      " -- 4.3484 bpw  accuracy: 0.98151706\n",
      " -- 5.2491 bpw  accuracy: 0.98954992\n",
      " -- 5.3313 bpw  accuracy: 0.99096136\n",
      " -- 6.0713 bpw  accuracy: 0.99413197\n",
      " -- 6.3032 bpw  accuracy: 0.99458717\n",
      " -- 6.8687 bpw  accuracy: 0.99548390\n",
      " -- 8.0354 bpw  accuracy: 0.99837365\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.29 (MLP)              |\n",
      "| Duration: 11.84 seconds                      |\n",
      "| Completed step: 60/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 1min 1sec          |\n",
      "| Last checkpoint layer: model.layers.24 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.30 (Attention)\n",
      " -- model.layers.30.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.30.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.30.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.30.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.30.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.94122264\n",
      " -- 2.1987 bpw  accuracy: 0.94367477\n",
      " -- 2.2831 bpw  accuracy: 0.95780836\n",
      " -- 2.6768 bpw  accuracy: 0.96607957\n",
      " -- 3.1689 bpw  accuracy: 0.97520926\n",
      " -- 3.1705 bpw  accuracy: 0.97540871\n",
      " -- 4.0439 bpw  accuracy: 0.98283140\n",
      " -- 4.0471 bpw  accuracy: 0.98319591\n",
      " -- 4.0816 bpw  accuracy: 0.98439303\n",
      " -- 4.1381 bpw  accuracy: 0.98516998\n",
      " -- 4.1705 bpw  accuracy: 0.98798353\n",
      " -- 4.1902 bpw  accuracy: 0.98867575\n",
      " -- 4.2737 bpw  accuracy: 0.98933353\n",
      " -- 4.3295 bpw  accuracy: 0.99045359\n",
      " -- 5.2564 bpw  accuracy: 0.99399293\n",
      " -- 5.3295 bpw  accuracy: 0.99509797\n",
      " -- 6.0439 bpw  accuracy: 0.99518547\n",
      " -- 6.3381 bpw  accuracy: 0.99731839\n",
      " -- 8.0439 bpw  accuracy: 0.99859387\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.30 (Attention)        |\n",
      "| Duration: 5.77 seconds                       |\n",
      "| Completed step: 61/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 0min 52sec         |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.30 (MLP)\n",
      " -- model.layers.30.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.30.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.30.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.30.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.30.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.30.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.30.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.30.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91390099\n",
      " -- 2.3230 bpw  accuracy: 0.91606910\n",
      " -- 2.5958 bpw  accuracy: 0.92756022\n",
      " -- 2.9120 bpw  accuracy: 0.93117497\n",
      " -- 3.2833 bpw  accuracy: 0.95576383\n",
      " -- 3.3655 bpw  accuracy: 0.95965666\n",
      " -- 3.6186 bpw  accuracy: 0.96452072\n",
      " -- 4.1368 bpw  accuracy: 0.97629518\n",
      " -- 4.1977 bpw  accuracy: 0.97824412\n",
      " -- 4.2662 bpw  accuracy: 0.97727983\n",
      " -- 4.3484 bpw  accuracy: 0.98020843\n",
      " -- 5.2491 bpw  accuracy: 0.98868594\n",
      " -- 5.3313 bpw  accuracy: 0.99026386\n",
      " -- 6.0713 bpw  accuracy: 0.99354478\n",
      " -- 6.3032 bpw  accuracy: 0.99413166\n",
      " -- 6.8687 bpw  accuracy: 0.99518166\n",
      " -- 8.0354 bpw  accuracy: 0.99819983\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.30 (MLP)              |\n",
      "| Duration: 11.85 seconds                      |\n",
      "| Completed step: 62/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 0min 44sec         |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.31 (Attention)\n",
      " -- model.layers.31.self_attn.q_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.31.self_attn.q_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.20 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.19 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.19 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.26 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.31.self_attn.k_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.16 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.25:3b_64g/0.75:2b_64g s4                         2.34 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.19 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.1:4b_64g/0.9:3b_64g s4                           3.20 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:4b_128g s4                                       4.06 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:4b_64g s4                                        4.09 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:4b_32g s4                                        4.16 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.20 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.26 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:5b_64g s4                                        5.09 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:5b_32g s4                                        5.16 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:6b_128g s4                                       6.06 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:6b_32g s4                                        6.16 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:8b_32g s4                                        8.16 bpw\n",
      " -- model.layers.31.self_attn.v_proj                   1:8b_128g s4                                       8.06 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:3b_64g/0.9:2b_64g s4                           2.18 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:4b_128g s4                                       4.04 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:4b_64g s4                                        4.07 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:5b_64g/0.9:4b_64g s4                           4.18 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:6b_128g s4                                       6.04 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:6b_32g s4                                        6.13 bpw\n",
      " -- model.layers.31.self_attn.o_proj                   1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.1378 bpw  accuracy: 0.94742727\n",
      " -- 2.1987 bpw  accuracy: 0.94975009\n",
      " -- 2.2831 bpw  accuracy: 0.95827092\n",
      " -- 2.6768 bpw  accuracy: 0.97054087\n",
      " -- 3.1689 bpw  accuracy: 0.97516700\n",
      " -- 3.1705 bpw  accuracy: 0.97573714\n",
      " -- 4.0439 bpw  accuracy: 0.98439334\n",
      " -- 4.0471 bpw  accuracy: 0.98519255\n",
      " -- 4.0816 bpw  accuracy: 0.98652559\n",
      " -- 4.1381 bpw  accuracy: 0.98733894\n",
      " -- 4.1705 bpw  accuracy: 0.98803896\n",
      " -- 4.1902 bpw  accuracy: 0.98887441\n",
      " -- 4.2737 bpw  accuracy: 0.99000956\n",
      " -- 4.3295 bpw  accuracy: 0.99076590\n",
      " -- 5.2564 bpw  accuracy: 0.99445354\n",
      " -- 5.3295 bpw  accuracy: 0.99533156\n",
      " -- 6.0439 bpw  accuracy: 0.99593421\n",
      " -- 6.3381 bpw  accuracy: 0.99742901\n",
      " -- 8.0439 bpw  accuracy: 0.99879987\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.31 (Attention)        |\n",
      "| Duration: 5.78 seconds                       |\n",
      "| Completed step: 63/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 0min 35sec         |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.layers.31 (MLP)\n",
      " -- model.layers.31.mlp.gate_proj                      0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:3b_64g/0.9:2b_64g s4                           2.17 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:4b_128g/0.9:3b_128g s4                         3.16 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:4b_32g/0.9:3b_32g s4                           3.23 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      1:4b_128g s4                                       4.03 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:5b_128g/0.9:4b_128g s4                         4.16 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:5b_32g/0.9:4b_32g s4                           4.23 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:6b_128g/0.9:5b_128g s4                         5.16 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:6b_32g/0.9:5b_32g s4                           5.23 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.31.mlp.gate_proj                      1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.05:3b_64g/0.95:2b_64g s4                         2.13 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:3b_64g/0.75:2b_64g s4                         2.31 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.3:3b_64g/0.7:2b_64g s4                           2.38 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:4b_128g/0.75:3b_128g s4                       3.28 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:4b_32g/0.75:3b_32g s4                         3.38 bpw\n",
      " -- model.layers.31.mlp.up_proj                        1:4b_32g s4                                        4.13 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:5b_128g/0.75:4b_128g s4                       4.28 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:5b_32g/0.75:4b_32g s4                         4.38 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:6b_128g/0.75:5b_128g s4                       5.28 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.25:6b_32g/0.75:5b_32g s4                         5.38 bpw\n",
      " -- model.layers.31.mlp.up_proj                        1:6b_128g s4                                       6.03 bpw\n",
      " -- model.layers.31.mlp.up_proj                        0.1:8b_128g/0.9:6b_128g s4                         6.28 bpw\n",
      " -- model.layers.31.mlp.up_proj                        1:8b_128g s4                                       8.03 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4              2.48 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:5b_32g/0.95:3b_32g s4                         3.24 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:5b_32g/0.95:4b_32g s4                         4.18 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:4b_128g/0.85:3b_128g s4            3.41 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4              3.49 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.95:4b_128g s4                        4.25 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.95:4b_32g s4                         4.34 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:5b_128g/0.85:4b_128g s4            4.36 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4              4.44 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:6b_128g/0.85:5b_128g s4            5.31 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4              5.39 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.05:8b_32g/0.95:6b_128g s4                        6.15 bpw\n",
      " -- model.layers.31.mlp.down_proj                      0.15:8b_128g/0.85:6b_128g s4                       6.34 bpw\n",
      " -- model.layers.31.mlp.down_proj                      1:8b_128g s4                                       8.04 bpw\n",
      " -- 2.2449 bpw  accuracy: 0.91062684\n",
      " -- 2.3230 bpw  accuracy: 0.91272474\n",
      " -- 2.5958 bpw  accuracy: 0.92333052\n",
      " -- 2.9120 bpw  accuracy: 0.92674106\n",
      " -- 3.2833 bpw  accuracy: 0.95385124\n",
      " -- 3.3655 bpw  accuracy: 0.95811058\n",
      " -- 3.6186 bpw  accuracy: 0.96270552\n",
      " -- 4.1368 bpw  accuracy: 0.97569443\n",
      " -- 4.1977 bpw  accuracy: 0.97831722\n",
      " -- 4.2662 bpw  accuracy: 0.97640000\n",
      " -- 4.3484 bpw  accuracy: 0.97966857\n",
      " -- 5.2491 bpw  accuracy: 0.98821317\n",
      " -- 5.3313 bpw  accuracy: 0.98999600\n",
      " -- 6.0713 bpw  accuracy: 0.99327633\n",
      " -- 6.3032 bpw  accuracy: 0.99390698\n",
      " -- 6.8687 bpw  accuracy: 0.99492521\n",
      " -- 8.0354 bpw  accuracy: 0.99799955\n",
      "------------------------------------------------\n",
      "| Measured: model.layers.31 (MLP)              |\n",
      "| Duration: 11.84 seconds                      |\n",
      "| Completed step: 64/67                        |\n",
      "| Avg time / step (rolling): 8.80 seconds      |\n",
      "| Estimated remaining time: 0min 26sec         |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: model.norm (RMSNorm)\n",
      "------------------------------------------------\n",
      "| Measured: model.norm (RMSNorm)               |\n",
      "| Duration: 0.06 seconds                       |\n",
      "| Completed step: 65/67                        |\n",
      "| Avg time / step (rolling): 8.23 seconds      |\n",
      "| Estimated remaining time: 0min 16sec         |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Layer: lm_head (Linear)\n",
      "------------------------------------------------\n",
      "| Measured: lm_head (Linear)                   |\n",
      "| Duration: 0.79 seconds                       |\n",
      "| Completed step: 66/67                        |\n",
      "| Avg time / step (rolling): 7.13 seconds      |\n",
      "| Estimated remaining time: 0min 7sec          |\n",
      "| Last checkpoint layer: model.layers.29 (MLP) |\n",
      "------------------------------------------------\n",
      " -- Optimizing...\n",
      " -- Pruning...\n",
      " -- Solving...\n",
      " -- Score: 0.99961572  bpw: 5.0000\n",
      " -- Score: 0.99962570  bpw: 4.9999\n",
      " -- Score: 0.99964065  bpw: 4.9985\n",
      " -- Score: 0.99964469  bpw: 4.9988\n",
      " -- Score: 0.99964701  bpw: 4.9977\n",
      " -- Score: 0.99964937  bpw: 4.9973\n",
      " -- Score: 0.99965000  bpw: 4.9978\n",
      " -- Score: 0.99965037  bpw: 4.9972\n",
      " -- Score: 0.99965067  bpw: 4.9999\n",
      " -- Score: 0.99965077  bpw: 4.9998\n",
      " -- Score: 0.99965183  bpw: 4.9994\n",
      " -- Score: 0.99965243  bpw: 4.9992\n",
      " -- Score: 0.99965244  bpw: 4.9997\n",
      " -- Score: 0.99965328  bpw: 4.9994\n",
      " -- Score: 0.99965335  bpw: 4.9985\n",
      " -- Score: 0.99965346  bpw: 4.9977\n",
      " -- Score: 0.99965387  bpw: 4.9996\n",
      " -- Score: 0.99965407  bpw: 4.9950\n",
      " -- Score: 0.99965568  bpw: 4.9997\n",
      " -- Score: 0.99966079  bpw: 4.9999\n",
      " -- Score: 0.99966115  bpw: 4.9971\n",
      " -- Score: 0.99966143  bpw: 4.9997\n",
      " -- Score: 0.99966829  bpw: 4.9965\n",
      " -- Score: 0.99966991  bpw: 5.0000\n",
      " -- Score: 0.99966996  bpw: 4.9978\n",
      " -- Score: 0.99967151  bpw: 4.9970\n",
      " -- Score: 0.99967361  bpw: 4.9967\n",
      " -- Score: 0.99967405  bpw: 4.9978\n",
      " -- Score: 0.99967406  bpw: 4.9983\n",
      " -- Score: 0.99967419  bpw: 4.9959\n",
      " -- Score: 0.99967461  bpw: 5.0000\n",
      " -- Score: 0.99967461  bpw: 5.0000\n",
      " -- Score: 0.99967472  bpw: 4.9981\n",
      " -- Score: 0.99967903  bpw: 4.9996\n",
      " -- Score: 0.99967955  bpw: 4.9994\n",
      " -- Score: 0.99967955  bpw: 4.9994\n",
      " -- Score: 0.99967966  bpw: 4.9975\n",
      " -- Score: 0.99968278  bpw: 4.9947\n",
      " -- Score: 0.99968390  bpw: 4.9986\n",
      " -- Score: 0.99968697  bpw: 4.9987\n",
      " -- Score: 0.99968697  bpw: 4.9987\n",
      " -- Score: 0.99968742  bpw: 4.9998\n",
      " -- Score: 0.99968853  bpw: 4.9986\n",
      " -- Score: 0.99968871  bpw: 4.9999\n",
      " -- Score: 0.99968876  bpw: 4.9977\n",
      " -- Score: 0.99968903  bpw: 4.9973\n",
      " -- Score: 0.99968903  bpw: 4.9978\n",
      " -- Score: 0.99968919  bpw: 4.9973\n",
      " -- Score: 0.99968963  bpw: 4.9984\n",
      " -- Score: 0.99968965  bpw: 5.0000\n",
      " -- Quantization strategy:\n",
      " --   model.layers.0.self_attn                           6.3381 bpw - exp. error: 0.00535384\n",
      " --   model.layers.0.mlp                                 4.3484 bpw - exp. error: 0.01525531\n",
      " --   model.layers.1.self_attn                           6.3381 bpw - exp. error: 0.00467845\n",
      " --   model.layers.1.mlp                                 3.3655 bpw - exp. error: 0.00496601\n",
      " --   model.layers.2.self_attn                           3.1705 bpw - exp. error: 0.00320224\n",
      " --   model.layers.2.mlp                                 2.3230 bpw - exp. error: 0.00750041\n",
      " --   model.layers.3.self_attn                           4.3295 bpw - exp. error: 0.00149843\n",
      " --   model.layers.3.mlp                                 3.3655 bpw - exp. error: 0.00521094\n",
      " --   model.layers.4.self_attn                           4.1902 bpw - exp. error: 0.00218593\n",
      " --   model.layers.4.mlp                                 3.3655 bpw - exp. error: 0.00730734\n",
      " --   model.layers.5.self_attn                           4.3295 bpw - exp. error: 0.00241285\n",
      " --   model.layers.5.mlp                                 4.3484 bpw - exp. error: 0.00467892\n",
      " --   model.layers.6.self_attn                           4.3295 bpw - exp. error: 0.00278632\n",
      " --   model.layers.6.mlp                                 4.3484 bpw - exp. error: 0.00557576\n",
      " --   model.layers.7.self_attn                           4.3295 bpw - exp. error: 0.00355209\n",
      " --   model.layers.7.mlp                                 4.3484 bpw - exp. error: 0.00651816\n",
      " --   model.layers.8.self_attn                           4.3295 bpw - exp. error: 0.00387020\n",
      " --   model.layers.8.mlp                                 4.3484 bpw - exp. error: 0.00716430\n",
      " --   model.layers.9.self_attn                           4.3295 bpw - exp. error: 0.00415425\n",
      " --   model.layers.9.mlp                                 4.3484 bpw - exp. error: 0.00785857\n",
      " --   model.layers.10.self_attn                          4.3295 bpw - exp. error: 0.00497529\n",
      " --   model.layers.10.mlp                                4.3484 bpw - exp. error: 0.00841569\n",
      " --   model.layers.11.self_attn                          4.3295 bpw - exp. error: 0.00601170\n",
      " --   model.layers.11.mlp                                5.3313 bpw - exp. error: 0.00442391\n",
      " --   model.layers.12.self_attn                          6.3381 bpw - exp. error: 0.00191353\n",
      " --   model.layers.12.mlp                                5.3313 bpw - exp. error: 0.00488898\n",
      " --   model.layers.13.self_attn                          5.3295 bpw - exp. error: 0.00345538\n",
      " --   model.layers.13.mlp                                5.3313 bpw - exp. error: 0.00537332\n",
      " --   model.layers.14.self_attn                          6.3381 bpw - exp. error: 0.00224807\n",
      " --   model.layers.14.mlp                                5.3313 bpw - exp. error: 0.00580778\n",
      " --   model.layers.15.self_attn                          5.3295 bpw - exp. error: 0.00468224\n",
      " --   model.layers.15.mlp                                5.3313 bpw - exp. error: 0.00624093\n",
      " --   model.layers.16.self_attn                          6.3381 bpw - exp. error: 0.00251186\n",
      " --   model.layers.16.mlp                                5.3313 bpw - exp. error: 0.00691638\n",
      " --   model.layers.17.self_attn                          6.3381 bpw - exp. error: 0.00251641\n",
      " --   model.layers.17.mlp                                5.3313 bpw - exp. error: 0.00772927\n",
      " --   model.layers.18.self_attn                          5.3295 bpw - exp. error: 0.00488373\n",
      " --   model.layers.18.mlp                                5.3313 bpw - exp. error: 0.00822580\n",
      " --   model.layers.19.self_attn                          6.3381 bpw - exp. error: 0.00294348\n",
      " --   model.layers.19.mlp                                5.3313 bpw - exp. error: 0.00846434\n",
      " --   model.layers.20.self_attn                          5.3295 bpw - exp. error: 0.00420071\n",
      " --   model.layers.20.mlp                                5.3313 bpw - exp. error: 0.00832987\n",
      " --   model.layers.21.self_attn                          5.3295 bpw - exp. error: 0.00380253\n",
      " --   model.layers.21.mlp                                5.3313 bpw - exp. error: 0.00816116\n",
      " --   model.layers.22.self_attn                          4.3295 bpw - exp. error: 0.00638849\n",
      " --   model.layers.22.mlp                                5.3313 bpw - exp. error: 0.00821614\n",
      " --   model.layers.23.self_attn                          5.3295 bpw - exp. error: 0.00358020\n",
      " --   model.layers.23.mlp                                5.3313 bpw - exp. error: 0.00829568\n",
      " --   model.layers.24.self_attn                          5.3295 bpw - exp. error: 0.00354227\n",
      " --   model.layers.24.mlp                                5.3313 bpw - exp. error: 0.00834549\n",
      " --   model.layers.25.self_attn                          5.3295 bpw - exp. error: 0.00358599\n",
      " --   model.layers.25.mlp                                5.3313 bpw - exp. error: 0.00849462\n",
      " --   model.layers.26.self_attn                          6.3381 bpw - exp. error: 0.00197673\n",
      " --   model.layers.26.mlp                                5.3313 bpw - exp. error: 0.00858329\n",
      " --   model.layers.27.self_attn                          5.3295 bpw - exp. error: 0.00355337\n",
      " --   model.layers.27.mlp                                5.3313 bpw - exp. error: 0.00868214\n",
      " --   model.layers.28.self_attn                          5.3295 bpw - exp. error: 0.00396435\n",
      " --   model.layers.28.mlp                                6.0713 bpw - exp. error: 0.00582815\n",
      " --   model.layers.29.self_attn                          6.3381 bpw - exp. error: 0.00264466\n",
      " --   model.layers.29.mlp                                6.0713 bpw - exp. error: 0.00586803\n",
      " --   model.layers.30.self_attn                          6.3381 bpw - exp. error: 0.00268161\n",
      " --   model.layers.30.mlp                                6.0713 bpw - exp. error: 0.00645522\n",
      " --   model.layers.31.self_attn                          6.3381 bpw - exp. error: 0.00257099\n",
      " --   model.layers.31.mlp                                6.0713 bpw - exp. error: 0.00672367\n",
      " -- Tokenizing samples...\n",
      " -- First 50 tokens of dataset:\n",
      "    ' = Robert Boulter = \\n  Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed'\n",
      " -- Last 50 tokens of dataset:\n",
      "    '] more meaningful lives \" . The film argues the case against conformity , but does not deny that people need and want it ; even the gay characters just want to fit in . Jim and Jim , the Burnhams \\' other neighbors , are'\n",
      " -- Token embeddings again...\n",
      " -- Quantizing...\n",
      " -- Layer: model.layers.0 (Attention)\n",
      " -- Linear: model.layers.0.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.0.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.0.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.0.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.025166\n",
      " -- Layer: model.layers.0 (MLP)\n",
      " -- Linear: model.layers.0.mlp.gate_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.0.mlp.up_proj -> 0.25:5b_32g/0.75:4b_32g s4, 4.38 bpw\n",
      " -- Linear: model.layers.0.mlp.down_proj -> 0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4, 4.44 bpw\n",
      " -- Module quantized, rfn_error: 0.019661\n",
      " -- Layer: model.layers.1 (Attention)\n",
      " -- Linear: model.layers.1.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.1.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.1.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.1.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.013964\n",
      " -- Layer: model.layers.1 (MLP)\n",
      " -- Linear: model.layers.1.mlp.gate_proj -> 0.1:4b_32g/0.9:3b_32g s4, 3.23 bpw\n",
      " -- Linear: model.layers.1.mlp.up_proj -> 0.25:4b_32g/0.75:3b_32g s4, 3.38 bpw\n",
      " -- Linear: model.layers.1.mlp.down_proj -> 0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4, 3.49 bpw\n",
      " -- Module quantized, rfn_error: 0.004159\n",
      " -- Layer: model.layers.2 (Attention)\n",
      " -- Linear: model.layers.2.self_attn.q_proj -> 0.1:4b_128g/0.9:3b_128g s4, 3.16 bpw\n",
      " -- Linear: model.layers.2.self_attn.k_proj -> 0.1:4b_128g/0.9:3b_128g s4, 3.19 bpw\n",
      " -- Linear: model.layers.2.self_attn.v_proj -> 0.1:4b_64g/0.9:3b_64g s4, 3.20 bpw\n",
      " -- Linear: model.layers.2.self_attn.o_proj -> 0.1:4b_128g/0.9:3b_128g s4, 3.16 bpw\n",
      " -- Module quantized, rfn_error: 0.003279\n",
      " -- Layer: model.layers.2 (MLP)\n",
      " -- Linear: model.layers.2.mlp.gate_proj -> 0.1:3b_64g/0.9:2b_64g s4, 2.17 bpw\n",
      " -- Linear: model.layers.2.mlp.up_proj -> 0.25:3b_64g/0.75:2b_64g s4, 2.31 bpw\n",
      " -- Linear: model.layers.2.mlp.down_proj -> 0.05:6b_32g/0.2:3b_64g/0.75:2b_64g s4, 2.48 bpw\n",
      " -- Module quantized, rfn_error: 0.008683\n",
      " -- Layer: model.layers.3 (Attention)\n",
      " -- Linear: model.layers.3.self_attn.q_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.3.self_attn.k_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.3.self_attn.v_proj -> 1:5b_32g s4, 5.16 bpw\n",
      " -- Linear: model.layers.3.self_attn.o_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Module quantized, rfn_error: 0.001631\n",
      " -- Layer: model.layers.3 (MLP)\n",
      " -- Linear: model.layers.3.mlp.gate_proj -> 0.1:4b_32g/0.9:3b_32g s4, 3.23 bpw\n",
      " -- Linear: model.layers.3.mlp.up_proj -> 0.25:4b_32g/0.75:3b_32g s4, 3.38 bpw\n",
      " -- Linear: model.layers.3.mlp.down_proj -> 0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4, 3.49 bpw\n",
      " -- Module quantized, rfn_error: 0.006114\n",
      " -- Layer: model.layers.4 (Attention)\n",
      " -- Linear: model.layers.4.self_attn.q_proj -> 0.1:5b_64g/0.9:4b_64g s4, 4.18 bpw\n",
      " -- Linear: model.layers.4.self_attn.k_proj -> 0.1:5b_64g/0.9:4b_64g s4, 4.20 bpw\n",
      " -- Linear: model.layers.4.self_attn.v_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.4.self_attn.o_proj -> 0.1:5b_64g/0.9:4b_64g s4, 4.18 bpw\n",
      " -- Module quantized, rfn_error: 0.002337\n",
      " -- Layer: model.layers.4 (MLP)\n",
      " -- Linear: model.layers.4.mlp.gate_proj -> 0.1:4b_32g/0.9:3b_32g s4, 3.23 bpw\n",
      " -- Linear: model.layers.4.mlp.up_proj -> 0.25:4b_32g/0.75:3b_32g s4, 3.38 bpw\n",
      " -- Linear: model.layers.4.mlp.down_proj -> 0.05:8b_32g/0.1:4b_32g/0.85:3b_32g s4, 3.49 bpw\n",
      " -- Module quantized, rfn_error: 0.008483\n",
      " -- Layer: model.layers.5 (Attention)\n",
      " -- Linear: model.layers.5.self_attn.q_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.5.self_attn.k_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.5.self_attn.v_proj -> 1:5b_32g s4, 5.16 bpw\n",
      " -- Linear: model.layers.5.self_attn.o_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Module quantized, rfn_error: 0.002707\n",
      " -- Layer: model.layers.5 (MLP)\n",
      " -- Linear: model.layers.5.mlp.gate_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.5.mlp.up_proj -> 0.25:5b_32g/0.75:4b_32g s4, 4.38 bpw\n",
      " -- Linear: model.layers.5.mlp.down_proj -> 0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4, 4.44 bpw\n",
      " -- Module quantized, rfn_error: 0.005500\n",
      " -- Layer: model.layers.6 (Attention)\n",
      " -- Linear: model.layers.6.self_attn.q_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.6.self_attn.k_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.6.self_attn.v_proj -> 1:5b_32g s4, 5.16 bpw\n",
      " -- Linear: model.layers.6.self_attn.o_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Module quantized, rfn_error: 0.003105\n",
      " -- Layer: model.layers.6 (MLP)\n",
      " -- Linear: model.layers.6.mlp.gate_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.6.mlp.up_proj -> 0.25:5b_32g/0.75:4b_32g s4, 4.38 bpw\n",
      " -- Linear: model.layers.6.mlp.down_proj -> 0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4, 4.44 bpw\n",
      " -- Module quantized, rfn_error: 0.006574\n",
      " -- Layer: model.layers.7 (Attention)\n",
      " -- Linear: model.layers.7.self_attn.q_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.7.self_attn.k_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.7.self_attn.v_proj -> 1:5b_32g s4, 5.16 bpw\n",
      " -- Linear: model.layers.7.self_attn.o_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004047\n",
      " -- Layer: model.layers.7 (MLP)\n",
      " -- Linear: model.layers.7.mlp.gate_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.7.mlp.up_proj -> 0.25:5b_32g/0.75:4b_32g s4, 4.38 bpw\n",
      " -- Linear: model.layers.7.mlp.down_proj -> 0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4, 4.44 bpw\n",
      " -- Module quantized, rfn_error: 0.007730\n",
      " -- Layer: model.layers.8 (Attention)\n",
      " -- Linear: model.layers.8.self_attn.q_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.8.self_attn.k_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.8.self_attn.v_proj -> 1:5b_32g s4, 5.16 bpw\n",
      " -- Linear: model.layers.8.self_attn.o_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004433\n",
      " -- Layer: model.layers.8 (MLP)\n",
      " -- Linear: model.layers.8.mlp.gate_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.8.mlp.up_proj -> 0.25:5b_32g/0.75:4b_32g s4, 4.38 bpw\n",
      " -- Linear: model.layers.8.mlp.down_proj -> 0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4, 4.44 bpw\n",
      " -- Module quantized, rfn_error: 0.008535\n",
      " -- Layer: model.layers.9 (Attention)\n",
      " -- Linear: model.layers.9.self_attn.q_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.9.self_attn.k_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.9.self_attn.v_proj -> 1:5b_32g s4, 5.16 bpw\n",
      " -- Linear: model.layers.9.self_attn.o_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004868\n",
      " -- Layer: model.layers.9 (MLP)\n",
      " -- Linear: model.layers.9.mlp.gate_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.9.mlp.up_proj -> 0.25:5b_32g/0.75:4b_32g s4, 4.38 bpw\n",
      " -- Linear: model.layers.9.mlp.down_proj -> 0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4, 4.44 bpw\n",
      " -- Module quantized, rfn_error: 0.009332\n",
      " -- Layer: model.layers.10 (Attention)\n",
      " -- Linear: model.layers.10.self_attn.q_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.10.self_attn.k_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.10.self_attn.v_proj -> 1:5b_32g s4, 5.16 bpw\n",
      " -- Linear: model.layers.10.self_attn.o_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Module quantized, rfn_error: 0.005748\n",
      " -- Layer: model.layers.10 (MLP)\n",
      " -- Linear: model.layers.10.mlp.gate_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.10.mlp.up_proj -> 0.25:5b_32g/0.75:4b_32g s4, 4.38 bpw\n",
      " -- Linear: model.layers.10.mlp.down_proj -> 0.05:8b_32g/0.1:5b_32g/0.85:4b_32g s4, 4.44 bpw\n",
      " -- Module quantized, rfn_error: 0.009913\n",
      " -- Layer: model.layers.11 (Attention)\n",
      " -- Linear: model.layers.11.self_attn.q_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.11.self_attn.k_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.11.self_attn.v_proj -> 1:5b_32g s4, 5.16 bpw\n",
      " -- Linear: model.layers.11.self_attn.o_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Module quantized, rfn_error: 0.006887\n",
      " -- Layer: model.layers.11 (MLP)\n",
      " -- Linear: model.layers.11.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.11.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.11.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.005202\n",
      " -- Layer: model.layers.12 (Attention)\n",
      " -- Linear: model.layers.12.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.12.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.12.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.12.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003965\n",
      " -- Layer: model.layers.12 (MLP)\n",
      " -- Linear: model.layers.12.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.12.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.12.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.005758\n",
      " -- Layer: model.layers.13 (Attention)\n",
      " -- Linear: model.layers.13.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.13.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.13.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.13.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004080\n",
      " -- Layer: model.layers.13 (MLP)\n",
      " -- Linear: model.layers.13.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.13.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.13.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.006321\n",
      " -- Layer: model.layers.14 (Attention)\n",
      " -- Linear: model.layers.14.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.14.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.14.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.14.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003816\n",
      " -- Layer: model.layers.14 (MLP)\n",
      " -- Linear: model.layers.14.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.14.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.14.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.006856\n",
      " -- Layer: model.layers.15 (Attention)\n",
      " -- Linear: model.layers.15.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.15.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.15.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.15.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.005753\n",
      " -- Layer: model.layers.15 (MLP)\n",
      " -- Linear: model.layers.15.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.15.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.15.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.007468\n",
      " -- Layer: model.layers.16 (Attention)\n",
      " -- Linear: model.layers.16.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.16.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.16.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.16.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004690\n",
      " -- Layer: model.layers.16 (MLP)\n",
      " -- Linear: model.layers.16.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.16.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.16.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.008314\n",
      " -- Layer: model.layers.17 (Attention)\n",
      " -- Linear: model.layers.17.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.17.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.17.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.17.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004438\n",
      " -- Layer: model.layers.17 (MLP)\n",
      " -- Linear: model.layers.17.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.17.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.17.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.009238\n",
      " -- Layer: model.layers.18 (Attention)\n",
      " -- Linear: model.layers.18.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.18.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.18.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.18.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.005756\n",
      " -- Layer: model.layers.18 (MLP)\n",
      " -- Linear: model.layers.18.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.18.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.18.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.009866\n",
      " -- Layer: model.layers.19 (Attention)\n",
      " -- Linear: model.layers.19.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.19.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.19.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.19.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004624\n",
      " -- Layer: model.layers.19 (MLP)\n",
      " -- Linear: model.layers.19.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.19.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.19.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.010208\n",
      " -- Layer: model.layers.20 (Attention)\n",
      " -- Linear: model.layers.20.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.20.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.20.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.20.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.005089\n",
      " -- Layer: model.layers.20 (MLP)\n",
      " -- Linear: model.layers.20.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.20.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.20.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.010106\n",
      " -- Layer: model.layers.21 (Attention)\n",
      " -- Linear: model.layers.21.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.21.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.21.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.21.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004462\n",
      " -- Layer: model.layers.21 (MLP)\n",
      " -- Linear: model.layers.21.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.21.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.21.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.009982\n",
      " -- Layer: model.layers.22 (Attention)\n",
      " -- Linear: model.layers.22.self_attn.q_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Linear: model.layers.22.self_attn.k_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.26 bpw\n",
      " -- Linear: model.layers.22.self_attn.v_proj -> 1:5b_32g s4, 5.16 bpw\n",
      " -- Linear: model.layers.22.self_attn.o_proj -> 0.1:5b_32g/0.9:4b_32g s4, 4.23 bpw\n",
      " -- Module quantized, rfn_error: 0.007587\n",
      " -- Layer: model.layers.22 (MLP)\n",
      " -- Linear: model.layers.22.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.22.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.22.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.010004\n",
      " -- Layer: model.layers.23 (Attention)\n",
      " -- Linear: model.layers.23.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.23.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.23.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.23.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004108\n",
      " -- Layer: model.layers.23 (MLP)\n",
      " -- Linear: model.layers.23.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.23.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.23.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.010068\n",
      " -- Layer: model.layers.24 (Attention)\n",
      " -- Linear: model.layers.24.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.24.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.24.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.24.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004244\n",
      " -- Layer: model.layers.24 (MLP)\n",
      " -- Linear: model.layers.24.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.24.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.24.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.010089\n",
      " -- Layer: model.layers.25 (Attention)\n",
      " -- Linear: model.layers.25.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.25.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.25.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.25.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004060\n",
      " -- Layer: model.layers.25 (MLP)\n",
      " -- Linear: model.layers.25.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.25.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.25.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.010217\n",
      " -- Layer: model.layers.26 (Attention)\n",
      " -- Linear: model.layers.26.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.26.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.26.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.26.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003367\n",
      " -- Layer: model.layers.26 (MLP)\n",
      " -- Linear: model.layers.26.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.26.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.26.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.010271\n",
      " -- Layer: model.layers.27 (Attention)\n",
      " -- Linear: model.layers.27.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.27.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.27.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.27.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004066\n",
      " -- Layer: model.layers.27 (MLP)\n",
      " -- Linear: model.layers.27.mlp.gate_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.27.mlp.up_proj -> 0.25:6b_32g/0.75:5b_32g s4, 5.38 bpw\n",
      " -- Linear: model.layers.27.mlp.down_proj -> 0.05:8b_32g/0.1:6b_32g/0.85:5b_32g s4, 5.39 bpw\n",
      " -- Module quantized, rfn_error: 0.010422\n",
      " -- Layer: model.layers.28 (Attention)\n",
      " -- Linear: model.layers.28.self_attn.q_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Linear: model.layers.28.self_attn.k_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.26 bpw\n",
      " -- Linear: model.layers.28.self_attn.v_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.28.self_attn.o_proj -> 0.1:6b_32g/0.9:5b_32g s4, 5.23 bpw\n",
      " -- Module quantized, rfn_error: 0.004579\n",
      " -- Layer: model.layers.28 (MLP)\n",
      " -- Linear: model.layers.28.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.28.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.28.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.007363\n",
      " -- Layer: model.layers.29 (Attention)\n",
      " -- Linear: model.layers.29.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.29.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.29.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.29.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004065\n",
      " -- Layer: model.layers.29 (MLP)\n",
      " -- Linear: model.layers.29.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.29.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.29.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.007215\n",
      " -- Layer: model.layers.30 (Attention)\n",
      " -- Linear: model.layers.30.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.30.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.30.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.30.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.003894\n",
      " -- Layer: model.layers.30 (MLP)\n",
      " -- Linear: model.layers.30.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.30.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.30.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.007707\n",
      " -- Layer: model.layers.31 (Attention)\n",
      " -- Linear: model.layers.31.self_attn.q_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Linear: model.layers.31.self_attn.k_proj -> 1:6b_32g s4, 6.16 bpw\n",
      " -- Linear: model.layers.31.self_attn.v_proj -> 1:8b_32g s4, 8.16 bpw\n",
      " -- Linear: model.layers.31.self_attn.o_proj -> 1:6b_32g s4, 6.13 bpw\n",
      " -- Module quantized, rfn_error: 0.004033\n",
      " -- Layer: model.layers.31 (MLP)\n",
      " -- Linear: model.layers.31.mlp.gate_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.31.mlp.up_proj -> 1:6b_128g s4, 6.03 bpw\n",
      " -- Linear: model.layers.31.mlp.down_proj -> 0.05:8b_32g/0.95:6b_128g s4, 6.15 bpw\n",
      " -- Module quantized, rfn_error: 0.008230\n",
      " -- Layer: model.norm (RMSNorm)\n",
      " -- Module quantized, rfn_error: 0.000000\n",
      " -- Layer: lm_head (Linear)\n",
      " -- Linear: lm_head -> 0.15:8b_128g/0.85:6b_128g s4, 6.34 bpw\n",
      " -- Module quantized, calibration perplexity (quant): 5.5621\n",
      " -- Compiling output file...\n",
      " -- Writing shard 1...\n",
      " --   travel-mistral-7B-EXL2/output.safetensors (4,509 MB)\n",
      " -- Finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download dataset\n",
    "!wget https://huggingface.co/datasets/wikitext/resolve/9a9e482b5987f9d25b3a9b2883fc6cc9fd8071b3/wikitext-103-v1/wikitext-test.parquet\n",
    "\n",
    "BPW = 5.0\n",
    "quant = f\"{model_name_prefix.value}-{BPW}bpw-exl2\"\n",
    "\n",
    "# Quantize model\n",
    "command = f\"python exllamav2/convert.py -i {model_name[1]} -o {quant} -c wikitext-test.parquet -b {BPW}\"\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending incremental file list\n",
      "./\n",
      "README.md\n",
      "config.json\n",
      "generation_config.json\n",
      "model.safetensors.index.json\n",
      "special_tokens_map.json\n",
      "tokenizer.json\n",
      "tokenizer.model\n",
      "tokenizer_config.json\n",
      "\n",
      "sent 2,316,888 bytes  received 171 bytes  4,634,118.00 bytes/sec\n",
      "total size is 2,315,709  speedup is 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy files\n",
    "command = f\"rm -rf {quant}/out_tensor\"\n",
    "os.system(command)\n",
    "\n",
    "command = f\"rsync -av --exclude='*.safetensors' --exclude='.*' ./{model_name[1]}/ ./{quant}/\"\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788c356813a5427c89d1dac536fd1548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hidden_states.safetensors:   0%|          | 0.00/1.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a244f3cdfb33440292e626f10e685eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "output.safetensors:   0%|          | 0.00/4.73G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71cda059ccc4072b149d53243cd8d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cal_data.safetensors:   0%|          | 0.00/1.64M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb4d65a2b324b339f3876f2604f91fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f66b6debf34407807a794620e63b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/CorticalStack/travel-mistral-7B-5.0bpw-exl2/commit/c3fbf6addcb0cd78706faeb08e49e0b5031b38aa', commit_message='Upload folder using huggingface_hub', commit_description='', oid='c3fbf6addcb0cd78706faeb08e49e0b5031b38aa', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty repo\n",
    "api = HfApi()\n",
    "create_repo(\n",
    "    repo_id = f\"CorticalStack/{quant}\",\n",
    "    repo_type=\"model\",\n",
    "    exist_ok=True,\n",
    "    token=HF_TOKEN\n",
    ")\n",
    "\n",
    "# Upload exl2 files\n",
    "api.upload_folder(\n",
    "    folder_path=quant,\n",
    "    repo_id=f\"CorticalStack/{quant}\",\n",
    "    token=HF_TOKEN\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaiplayground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
